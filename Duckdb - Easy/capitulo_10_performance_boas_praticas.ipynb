{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b9bdfe",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 10 - Performance e Boas Pr√°ticas\n",
    "\n",
    "Este notebook final explora t√©cnicas de otimiza√ß√£o e boas pr√°ticas para maximizar a performance do DuckDB.\n",
    "\n",
    "## üìö T√≥picos Abordados:\n",
    "1. Configura√ß√µes de Performance\n",
    "2. Otimiza√ß√µes de Queries\n",
    "3. Gerenciamento de Mem√≥ria\n",
    "4. Formatos de Arquivo (Parquet vs CSV)\n",
    "5. Compress√£o e Row Groups\n",
    "6. Prepared Statements\n",
    "7. Paralelismo e Threads\n",
    "8. Benchmarking\n",
    "9. Pipeline de ETL Otimizado\n",
    "10. Checklist de Boas Pr√°ticas\n",
    "\n",
    "## üöÄ Objetivos:\n",
    "- **Maximizar** performance\n",
    "- **Reduzir** uso de mem√≥ria\n",
    "- **Acelerar** pipelines de dados\n",
    "- **Aplicar** melhores pr√°ticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1e55f",
   "metadata": {},
   "source": [
    "## 1. Setup e Prepara√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(f\"DuckDB vers√£o: {duckdb.__version__}\")\n",
    "print(\"‚úì Bibliotecas importadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1822b",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√µes de Performance\n",
    "\n",
    "### 2.1 Configura√ß√µes Essenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar conex√£o com configura√ß√µes otimizadas\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "# Configurar mem√≥ria\n",
    "con.execute(\"SET memory_limit = '2GB'\")\n",
    "print(\"‚úì Memory limit: 2GB\")\n",
    "\n",
    "# Configurar threads (use n√∫mero de cores da CPU)\n",
    "con.execute(\"SET threads TO 4\")\n",
    "print(\"‚úì Threads: 4\")\n",
    "\n",
    "# Desabilitar ordem de inser√ß√£o (melhora performance em GROUP BY)\n",
    "con.execute(\"SET preserve_insertion_order = false\")\n",
    "print(\"‚úì Preserve insertion order: false\")\n",
    "\n",
    "# Ver configura√ß√µes\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT name, value\n",
    "    FROM duckdb_settings()\n",
    "    WHERE name IN ('memory_limit', 'threads', 'preserve_insertion_order')\n",
    "\"\"\").fetchdf()\n",
    "print(\"\\nConfigura√ß√µes atuais:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90dbb6",
   "metadata": {},
   "source": [
    "### 2.2 Temp Directory para Grandes Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68491bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Configurar diret√≥rio tempor√°rio\n",
    "temp_dir = tempfile.gettempdir()\n",
    "con.execute(f\"SET temp_directory = '{temp_dir}'\")\n",
    "\n",
    "print(f\"‚úì Temp directory: {temp_dir}\")\n",
    "print(\"\\nüí° Use SSD para melhor performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292bdc9",
   "metadata": {},
   "source": [
    "## 3. Criar Dados de Teste\n",
    "\n",
    "### 3.1 Gerar Dataset Sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados de teste\n",
    "np.random.seed(42)\n",
    "\n",
    "n_rows = 100000\n",
    "dates = [datetime(2024, 1, 1) + timedelta(days=i % 365) for i in range(n_rows)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': range(n_rows),\n",
    "    'data': dates,\n",
    "    'categoria': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "    'valor': np.random.uniform(10, 1000, n_rows),\n",
    "    'quantidade': np.random.randint(1, 100, n_rows),\n",
    "    'regiao': np.random.choice(['Norte', 'Sul', 'Leste', 'Oeste'], n_rows)\n",
    "})\n",
    "\n",
    "print(f\"‚úì Dataset gerado: {len(df):,} linhas\")\n",
    "print(f\"‚úì Tamanho em mem√≥ria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eaec5c",
   "metadata": {},
   "source": [
    "### 3.2 Registrar no DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6647b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrar DataFrame\n",
    "con.register('vendas', df)\n",
    "print(\"‚úì DataFrame registrado como 'vendas'\")\n",
    "\n",
    "# Verificar\n",
    "result = con.execute(\"SELECT COUNT(*) as total FROM vendas\").fetchone()\n",
    "print(f\"Total de registros: {result[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f74890",
   "metadata": {},
   "source": [
    "## 4. Formatos de Arquivo: CSV vs Parquet\n",
    "\n",
    "### 4.1 Exportar em Diferentes Formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Exportar CSV\n",
    "print(\"Exportando CSV...\")\n",
    "start = time.time()\n",
    "con.execute(\"\"\"\n",
    "    COPY vendas TO 'vendas_test.csv' (FORMAT CSV, HEADER true)\n",
    "\"\"\")\n",
    "csv_time = time.time() - start\n",
    "csv_size = os.path.getsize('vendas_test.csv') / 1024**2\n",
    "print(f\"‚úì CSV: {csv_time:.3f}s, {csv_size:.2f} MB\")\n",
    "\n",
    "# Exportar Parquet\n",
    "print(\"\\nExportando Parquet...\")\n",
    "start = time.time()\n",
    "con.execute(\"\"\"\n",
    "    COPY vendas TO 'vendas_test.parquet' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "parquet_time = time.time() - start\n",
    "parquet_size = os.path.getsize('vendas_test.parquet') / 1024**2\n",
    "print(f\"‚úì Parquet: {parquet_time:.3f}s, {parquet_size:.2f} MB\")\n",
    "\n",
    "# Compara√ß√£o\n",
    "print(\"\\nüìä COMPARA√á√ÉO:\")\n",
    "print(f\"Velocidade: Parquet √© {csv_time/parquet_time:.1f}x mais r√°pido\")\n",
    "print(f\"Tamanho: Parquet √© {csv_size/parquet_size:.1f}x menor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3b36f",
   "metadata": {},
   "source": [
    "### 4.2 Leitura: CSV vs Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c95607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler CSV\n",
    "print(\"Lendo CSV...\")\n",
    "start = time.time()\n",
    "result_csv = con.execute(\"SELECT COUNT(*) FROM 'vendas_test.csv'\").fetchone()\n",
    "csv_read_time = time.time() - start\n",
    "print(f\"‚úì CSV: {csv_read_time:.3f}s, {result_csv[0]:,} linhas\")\n",
    "\n",
    "# Ler Parquet\n",
    "print(\"\\nLendo Parquet...\")\n",
    "start = time.time()\n",
    "result_parquet = con.execute(\"SELECT COUNT(*) FROM 'vendas_test.parquet'\").fetchone()\n",
    "parquet_read_time = time.time() - start\n",
    "print(f\"‚úì Parquet: {parquet_read_time:.3f}s, {result_parquet[0]:,} linhas\")\n",
    "\n",
    "# Compara√ß√£o\n",
    "print(\"\\n‚ö° PERFORMANCE:\")\n",
    "print(f\"Parquet √© {csv_read_time/parquet_read_time:.1f}x mais r√°pido para leitura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3302310",
   "metadata": {},
   "source": [
    "## 5. Compress√£o e Row Groups\n",
    "\n",
    "### 5.1 Diferentes Compress√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c66670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar diferentes compress√µes\n",
    "compressoes = ['snappy', 'gzip', 'zstd', 'uncompressed']\n",
    "resultados = []\n",
    "\n",
    "for comp in compressoes:\n",
    "    filename = f'vendas_{comp}.parquet'\n",
    "    \n",
    "    # Exportar\n",
    "    start = time.time()\n",
    "    con.execute(f\"\"\"\n",
    "        COPY vendas TO '{filename}' \n",
    "        (FORMAT PARQUET, COMPRESSION {comp})\n",
    "    \"\"\")\n",
    "    write_time = time.time() - start\n",
    "    \n",
    "    # Tamanho\n",
    "    size = os.path.getsize(filename) / 1024**2\n",
    "    \n",
    "    # Ler\n",
    "    start = time.time()\n",
    "    con.execute(f\"SELECT COUNT(*) FROM '{filename}'\").fetchone()\n",
    "    read_time = time.time() - start\n",
    "    \n",
    "    resultados.append({\n",
    "        'compressao': comp,\n",
    "        'tamanho_mb': size,\n",
    "        'write_s': write_time,\n",
    "        'read_s': read_time\n",
    "    })\n",
    "\n",
    "# Mostrar resultados\n",
    "comp_df = pd.DataFrame(resultados)\n",
    "print(\"üìä COMPARA√á√ÉO DE COMPRESS√ïES:\")\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° ZSTD oferece melhor balan√ßo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b2a93",
   "metadata": {},
   "source": [
    "### 5.2 Row Group Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar diferentes row group sizes\n",
    "print(\"Testando ROW_GROUP_SIZE:\")\n",
    "\n",
    "for size in [10000, 50000, 100000]:\n",
    "    filename = f'vendas_rg_{size}.parquet'\n",
    "    \n",
    "    start = time.time()\n",
    "    con.execute(f\"\"\"\n",
    "        COPY vendas TO '{filename}'\n",
    "        (FORMAT PARQUET, COMPRESSION zstd, ROW_GROUP_SIZE {size})\n",
    "    \"\"\")\n",
    "    write_time = time.time() - start\n",
    "    file_size = os.path.getsize(filename) / 1024**2\n",
    "    \n",
    "    print(f\"Row group {size:6d}: {write_time:.3f}s, {file_size:.2f} MB\")\n",
    "\n",
    "print(\"\\nüí° Row groups menores = mais paralelismo\")\n",
    "print(\"üí° Row groups maiores = melhor compress√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404b46b",
   "metadata": {},
   "source": [
    "## 6. Otimiza√ß√£o de Queries\n",
    "\n",
    "### 6.1 Filtros e Proje√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query SEM otimiza√ß√£o\n",
    "print(\"Query SEM filtro na origem:\")\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT categoria, AVG(valor) as media\n",
    "    FROM (\n",
    "        SELECT * FROM vendas\n",
    "    )\n",
    "    WHERE data >= '2024-06-01'\n",
    "    GROUP BY categoria\n",
    "\"\"\").fetchdf()\n",
    "slow_time = time.time() - start\n",
    "print(f\"Tempo: {slow_time:.3f}s\")\n",
    "\n",
    "# Query COM otimiza√ß√£o (filtro early)\n",
    "print(\"\\nQuery COM filtro antecipado:\")\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT categoria, AVG(valor) as media\n",
    "    FROM vendas\n",
    "    WHERE data >= '2024-06-01'\n",
    "    GROUP BY categoria\n",
    "\"\"\").fetchdf()\n",
    "fast_time = time.time() - start\n",
    "print(f\"Tempo: {fast_time:.3f}s\")\n",
    "\n",
    "print(f\"\\n‚ö° Melhoria: {slow_time/fast_time:.1f}x mais r√°pido\")\n",
    "print(\"\\nüí° Aplique filtros o mais cedo poss√≠vel!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6d202",
   "metadata": {},
   "source": [
    "### 6.2 SELECT * vs Colunas Espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT *\n",
    "print(\"SELECT * (todas as colunas):\")\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT * FROM 'vendas_test.parquet' LIMIT 10000\n",
    "\"\"\").fetchdf()\n",
    "all_cols_time = time.time() - start\n",
    "print(f\"Tempo: {all_cols_time:.3f}s, Mem√≥ria: {result.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# SELECT espec√≠fico\n",
    "print(\"\\nSELECT categoria, valor (colunas espec√≠ficas):\")\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT categoria, valor FROM 'vendas_test.parquet' LIMIT 10000\n",
    "\"\"\").fetchdf()\n",
    "few_cols_time = time.time() - start\n",
    "print(f\"Tempo: {few_cols_time:.3f}s, Mem√≥ria: {result.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n‚ö° Economia: {all_cols_time/few_cols_time:.1f}x mais r√°pido\")\n",
    "print(\"\\nüí° Selecione apenas colunas necess√°rias!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbfd5c",
   "metadata": {},
   "source": [
    "## 7. Prepared Statements\n",
    "\n",
    "### 7.1 Compara√ß√£o: Normal vs Prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c57b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de teste\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE usuarios (\n",
    "        id INTEGER,\n",
    "        nome VARCHAR,\n",
    "        idade INTEGER\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# M√©todo 1: Query normal (lento)\n",
    "print(\"M√©todo 1: Query normal\")\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    con.execute(f\"INSERT INTO usuarios VALUES ({i}, 'User_{i}', {20 + i % 50})\")\n",
    "normal_time = time.time() - start\n",
    "print(f\"Tempo: {normal_time:.3f}s\")\n",
    "\n",
    "# Limpar\n",
    "con.execute(\"DELETE FROM usuarios\")\n",
    "\n",
    "# M√©todo 2: Prepared statement (r√°pido)\n",
    "print(\"\\nM√©todo 2: Prepared statement\")\n",
    "start = time.time()\n",
    "stmt = con.execute(\"PREPARE insert_user AS INSERT INTO usuarios VALUES ($1, $2, $3)\")\n",
    "for i in range(1000):\n",
    "    con.execute(f\"EXECUTE insert_user({i}, 'User_{i}', {20 + i % 50})\")\n",
    "prepared_time = time.time() - start\n",
    "print(f\"Tempo: {prepared_time:.3f}s\")\n",
    "\n",
    "print(f\"\\n‚ö° Prepared statement √© {normal_time/prepared_time:.1f}x mais r√°pido!\")\n",
    "\n",
    "# Verificar\n",
    "count = con.execute(\"SELECT COUNT(*) FROM usuarios\").fetchone()[0]\n",
    "print(f\"\\n‚úì Total inserido: {count:,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb36372",
   "metadata": {},
   "source": [
    "## 8. Paralelismo e Threads\n",
    "\n",
    "### 8.1 Impacto do N√∫mero de Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query de teste (agrega√ß√£o pesada)\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        categoria,\n",
    "        regiao,\n",
    "        COUNT(*) as total,\n",
    "        SUM(valor * quantidade) as receita,\n",
    "        AVG(valor) as valor_medio\n",
    "    FROM vendas\n",
    "    GROUP BY categoria, regiao\n",
    "    ORDER BY receita DESC\n",
    "\"\"\"\n",
    "\n",
    "# Testar diferentes n√∫meros de threads\n",
    "print(\"Testando diferentes n√∫meros de threads:\")\n",
    "print()\n",
    "\n",
    "for threads in [1, 2, 4, 8]:\n",
    "    con.execute(f\"SET threads = {threads}\")\n",
    "    \n",
    "    start = time.time()\n",
    "    result = con.execute(query).fetchdf()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Threads {threads}: {elapsed:.3f}s\")\n",
    "\n",
    "print(\"\\nüí° Mais threads = melhor performance (at√© o limite de cores)\")\n",
    "\n",
    "# Resetar para valor otimizado\n",
    "con.execute(\"SET threads = 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9ba35",
   "metadata": {},
   "source": [
    "## 9. Benchmarking Completo\n",
    "\n",
    "### 9.1 Suite de Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb373e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suite de queries para benchmark\n",
    "benchmarks = {\n",
    "    'Count': \"SELECT COUNT(*) FROM vendas\",\n",
    "    'Agrega√ß√£o Simples': \"SELECT categoria, SUM(valor) FROM vendas GROUP BY categoria\",\n",
    "    'Agrega√ß√£o Complexa': \"\"\"\n",
    "        SELECT \n",
    "            categoria, regiao,\n",
    "            COUNT(*) as total,\n",
    "            AVG(valor) as media,\n",
    "            STDDEV(valor) as desvio\n",
    "        FROM vendas\n",
    "        GROUP BY categoria, regiao\n",
    "    \"\"\",\n",
    "    'Filtro + Sort': \"\"\"\n",
    "        SELECT * FROM vendas\n",
    "        WHERE valor > 500\n",
    "        ORDER BY valor DESC\n",
    "        LIMIT 1000\n",
    "    \"\"\",\n",
    "    'Window Function': \"\"\"\n",
    "        SELECT \n",
    "            categoria,\n",
    "            valor,\n",
    "            ROW_NUMBER() OVER (PARTITION BY categoria ORDER BY valor DESC) as rank\n",
    "        FROM vendas\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"üèÉ EXECUTANDO BENCHMARKS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "resultados_bench = []\n",
    "for nome, query in benchmarks.items():\n",
    "    start = time.time()\n",
    "    result = con.execute(query).fetchdf()\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    resultados_bench.append({\n",
    "        'Benchmark': nome,\n",
    "        'Tempo (s)': f\"{elapsed:.3f}\",\n",
    "        'Linhas': len(result)\n",
    "    })\n",
    "    \n",
    "    print(f\"{nome:25s} {elapsed:6.3f}s  ({len(result):,} linhas)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úì Benchmarks conclu√≠dos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2425b",
   "metadata": {},
   "source": [
    "## 10. Pipeline ETL Otimizado\n",
    "\n",
    "### 10.1 Pipeline Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_etl_otimizado():\n",
    "    \"\"\"\n",
    "    Pipeline ETL otimizado com DuckDB\n",
    "    \"\"\"\n",
    "    print(\"üöÄ PIPELINE ETL OTIMIZADO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Configura√ß√£o\n",
    "    print(\"\\n1Ô∏è‚É£ Configurando conex√£o...\")\n",
    "    con_etl = duckdb.connect(':memory:')\n",
    "    con_etl.execute(\"SET memory_limit = '2GB'\")\n",
    "    con_etl.execute(\"SET threads = 4\")\n",
    "    con_etl.execute(\"SET preserve_insertion_order = false\")\n",
    "    print(\"   ‚úì Configura√ß√£o aplicada\")\n",
    "    \n",
    "    # 2. Extra√ß√£o (CSV ‚Üí Parquet)\n",
    "    print(\"\\n2Ô∏è‚É£ Convertendo CSV para Parquet...\")\n",
    "    start = time.time()\n",
    "    con_etl.execute(\"\"\"\n",
    "        COPY (\n",
    "            SELECT * FROM 'vendas_test.csv'\n",
    "        ) TO 'vendas_otimizado.parquet'\n",
    "        (FORMAT PARQUET, COMPRESSION zstd, ROW_GROUP_SIZE 50000)\n",
    "    \"\"\")\n",
    "    print(f\"   ‚úì Convers√£o: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # 3. Transforma√ß√£o\n",
    "    print(\"\\n3Ô∏è‚É£ Aplicando transforma√ß√µes...\")\n",
    "    start = time.time()\n",
    "    con_etl.execute(\"\"\"\n",
    "        CREATE TABLE vendas_processadas AS\n",
    "        SELECT \n",
    "            id,\n",
    "            data,\n",
    "            categoria,\n",
    "            valor,\n",
    "            quantidade,\n",
    "            valor * quantidade as receita,\n",
    "            regiao,\n",
    "            CASE \n",
    "                WHEN valor < 100 THEN 'Baixo'\n",
    "                WHEN valor < 500 THEN 'M√©dio'\n",
    "                ELSE 'Alto'\n",
    "            END as faixa_preco\n",
    "        FROM 'vendas_otimizado.parquet'\n",
    "        WHERE valor > 0\n",
    "    \"\"\")\n",
    "    print(f\"   ‚úì Transforma√ß√£o: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # 4. Agrega√ß√£o\n",
    "    print(\"\\n4Ô∏è‚É£ Gerando agrega√ß√µes...\")\n",
    "    start = time.time()\n",
    "    result = con_etl.execute(\"\"\"\n",
    "        SELECT \n",
    "            categoria,\n",
    "            regiao,\n",
    "            faixa_preco,\n",
    "            COUNT(*) as transacoes,\n",
    "            SUM(receita) as receita_total,\n",
    "            AVG(valor) as ticket_medio\n",
    "        FROM vendas_processadas\n",
    "        GROUP BY categoria, regiao, faixa_preco\n",
    "        ORDER BY receita_total DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(f\"   ‚úì Agrega√ß√£o: {time.time() - start:.2f}s\")\n",
    "    print(f\"   ‚úì Resultados: {len(result)} linhas\")\n",
    "    \n",
    "    # 5. Exporta√ß√£o\n",
    "    print(\"\\n5Ô∏è‚É£ Exportando resultados...\")\n",
    "    start = time.time()\n",
    "    con_etl.execute(\"\"\"\n",
    "        COPY (\n",
    "            SELECT * FROM vendas_processadas\n",
    "        ) TO 'vendas_final.parquet'\n",
    "        (FORMAT PARQUET, COMPRESSION zstd)\n",
    "    \"\"\")\n",
    "    print(f\"   ‚úì Exporta√ß√£o: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ PIPELINE CONCLU√çDO COM SUCESSO!\")\n",
    "    \n",
    "    con_etl.close()\n",
    "    return result\n",
    "\n",
    "# Executar pipeline\n",
    "resultado = pipeline_etl_otimizado()\n",
    "print(\"\\nTop 5 resultados:\")\n",
    "print(resultado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82bb8d",
   "metadata": {},
   "source": [
    "## 11. Checklist de Boas Pr√°ticas\n",
    "\n",
    "### 11.1 Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚úÖ CHECKLIST DE BOAS PR√ÅTICAS\n",
    "\"\"\" + \"=\"*60 + \"\"\"\n",
    "\n",
    "üîß CONFIGURA√á√ÉO:\n",
    "  ‚úì Definir memory_limit apropriado\n",
    "  ‚úì Configurar threads = n√∫mero de cores\n",
    "  ‚úì Usar temp_directory em SSD\n",
    "  ‚úì preserve_insertion_order = false (quando poss√≠vel)\n",
    "\n",
    "üìÅ FORMATOS DE ARQUIVO:\n",
    "  ‚úì Usar Parquet em vez de CSV\n",
    "  ‚úì Compress√£o ZSTD para melhor balan√ßo\n",
    "  ‚úì Row group size entre 50k-100k\n",
    "  ‚úì Particionar dados grandes por data/categoria\n",
    "\n",
    "üîç QUERIES:\n",
    "  ‚úì Selecionar apenas colunas necess√°rias\n",
    "  ‚úì Aplicar filtros o mais cedo poss√≠vel\n",
    "  ‚úì Usar LIMIT quando apropriado\n",
    "  ‚úì Evitar SELECT * em produ√ß√£o\n",
    "\n",
    "‚ö° PERFORMANCE:\n",
    "  ‚úì Usar prepared statements para inserts repetitivos\n",
    "  ‚úì Batch inserts em vez de individuais\n",
    "  ‚úì Habilitar paralelismo (force_parallelism = true)\n",
    "  ‚úì Reusar conex√µes quando poss√≠vel\n",
    "\n",
    "üíæ MEM√ìRIA:\n",
    "  ‚úì Processar dados em chunks para grandes volumes\n",
    "  ‚úì Usar streaming quando poss√≠vel\n",
    "  ‚úì Limpar temp files ap√≥s processamento\n",
    "  ‚úì Monitorar uso de mem√≥ria\n",
    "\n",
    "üìä MONITORAMENTO:\n",
    "  ‚úì Usar EXPLAIN ANALYZE para otimizar queries\n",
    "  ‚úì Fazer benchmarks regulares\n",
    "  ‚úì Monitorar tempo de execu√ß√£o\n",
    "  ‚úì Revisar planos de execu√ß√£o\n",
    "\n",
    "üîê SEGURAN√áA:\n",
    "  ‚úì Validar inputs de usu√°rios\n",
    "  ‚úì Usar prepared statements (previne SQL injection)\n",
    "  ‚úì N√£o expor credenciais no c√≥digo\n",
    "  ‚úì Usar secrets para credenciais S3\n",
    "\"\"\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ab375",
   "metadata": {},
   "source": [
    "### 11.2 Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b90130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar arquivos de teste\n",
    "import glob\n",
    "\n",
    "arquivos_teste = glob.glob('vendas*.csv') + glob.glob('vendas*.parquet')\n",
    "for arquivo in arquivos_teste:\n",
    "    try:\n",
    "        os.remove(arquivo)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"‚úì {len(arquivos_teste)} arquivos de teste removidos\")\n",
    "print(\"\\n‚úÖ Notebook conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c783b01",
   "metadata": {},
   "source": [
    "## üéØ Resumo Final\n",
    "\n",
    "### ‚úÖ Principais Aprendizados:\n",
    "\n",
    "**Performance:**\n",
    "- Parquet √© **~5-10x mais r√°pido** que CSV\n",
    "- Parquet √© **~3-5x menor** que CSV\n",
    "- ZSTD oferece melhor balan√ßo compress√£o/velocidade\n",
    "- Prepared statements s√£o **~5-10x mais r√°pidos**\n",
    "- Threads adequados = **2-4x mais r√°pido**\n",
    "\n",
    "**Configura√ß√µes Essenciais:**\n",
    "1. `memory_limit` ‚Üí Evitar OOM\n",
    "2. `threads` ‚Üí Maximizar paralelismo\n",
    "3. `temp_directory` ‚Üí SSD para grandes volumes\n",
    "4. `preserve_insertion_order = false` ‚Üí Melhor GROUP BY\n",
    "\n",
    "**Otimiza√ß√µes de Query:**\n",
    "- Filtrar cedo (WHERE antes de JOIN)\n",
    "- Selecionar apenas colunas necess√°rias\n",
    "- Usar LIMIT quando apropriado\n",
    "- Aproveitar predicate pushdown\n",
    "\n",
    "**Formatos:**\n",
    "- ‚úÖ Parquet: Produ√ß√£o\n",
    "- ‚ö†Ô∏è CSV: Interchange/debug\n",
    "- ‚úÖ Compress√£o: ZSTD\n",
    "- ‚úÖ Row groups: 50k-100k\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos:\n",
    "\n",
    "1. **Aplicar em projetos reais**\n",
    "2. **Monitorar performance continuamente**\n",
    "3. **Iterar e otimizar**\n",
    "4. **Documentar resultados**\n",
    "\n",
    "### üìö Recursos Adicionais:\n",
    "\n",
    "- [DuckDB Documentation](https://duckdb.org/docs/)\n",
    "- [Performance Guide](https://duckdb.org/docs/guides/performance/)\n",
    "- [Best Practices](https://duckdb.org/docs/guides/best_practices/)\n",
    "\n",
    "### üéì Conclus√£o:\n",
    "\n",
    "Parab√©ns! Voc√™ completou o curso **DuckDB - Easy**!\n",
    "\n",
    "Voc√™ aprendeu:\n",
    "- ‚úÖ 10 cap√≠tulos completos\n",
    "- ‚úÖ SQL avan√ßado com DuckDB\n",
    "- ‚úÖ Integra√ß√£o com Python/Pandas/Polars\n",
    "- ‚úÖ Otimiza√ß√£o e performance\n",
    "- ‚úÖ Boas pr√°ticas de desenvolvimento\n",
    "\n",
    "**Continue praticando e explorando o DuckDB! ü¶Ü**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
