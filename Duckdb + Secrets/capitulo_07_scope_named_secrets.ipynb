{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Secrets-07-scope-named-secrets\n",
        "\"\"\"\n",
        "\n",
        "# Secrets-07-scope-named-secrets\n",
        "import duckdb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 1\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "print(\"\"\"\n",
        "SCOPE em DuckDB Secrets:\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "O que é:\n",
        "────────\n",
        "SCOPE define para quais URLs/paths um secret se aplica.\n",
        "É um pattern matching de prefixo de URL.\n",
        "\n",
        "Funcionamento:\n",
        "──────────────\n",
        "Quando você faz uma query para 's3://bucket1/file.parquet',\n",
        "DuckDB procura o secret com SCOPE que melhor casa com a URL.\n",
        "\n",
        "Matching:\n",
        "─────────\n",
        "1. Procura exact match\n",
        "2. Procura longest prefix match\n",
        "3. Usa secret sem SCOPE como fallback\n",
        "\n",
        "Exemplos:\n",
        "─────────\n",
        "\"\"\")\n",
        "\n",
        "# Secret sem SCOPE (aplica a todos os S3)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_default (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'default_key',\n",
        "        SECRET 'default_secret'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Secret com SCOPE específico\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_bucket1 (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'bucket1_key',\n",
        "        SECRET 'bucket1_secret',\n",
        "        SCOPE 's3://bucket1/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_bucket2 (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'bucket2_key',\n",
        "        SECRET 'bucket2_secret',\n",
        "        SCOPE 's3://bucket2/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Verificar SCOPEs\n",
        "secrets = con.execute(\"\"\"\n",
        "    SELECT name, scope\n",
        "    FROM duckdb_secrets()\n",
        "    WHERE type = 's3'\n",
        "    ORDER BY name\n",
        "\"\"\").df()\n",
        "\n",
        "print(\"\\nSecrets criados:\")\n",
        "print(secrets)\n",
        "\n",
        "print(\"\"\"\n",
        "Matching de URLs:\n",
        "─────────────────\n",
        "'s3://bucket1/file.parquet'  → s3_bucket1\n",
        "'s3://bucket2/data.csv'      → s3_bucket2\n",
        "'s3://bucket3/other.parquet' → s3_default (fallback)\n",
        "'s3://bucket1/deep/nested'   → s3_bucket1 (prefix match)\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 2\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Hierarquia de SCOPEs\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_all (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'all',\n",
        "        SECRET 'all'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_prod_bucket (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'prod',\n",
        "        SECRET 'prod',\n",
        "        SCOPE 's3://production-bucket/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_prod_subfolder (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'sensitive',\n",
        "        SECRET 'sensitive',\n",
        "        SCOPE 's3://production-bucket/sensitive-data/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "print(\"\"\"\n",
        "Hierarquia de SCOPEs:\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "Secrets criados:\n",
        "────────────────\n",
        "1. s3_all                → SCOPE: (nenhum)\n",
        "2. s3_prod_bucket        → SCOPE: s3://production-bucket/\n",
        "3. s3_prod_subfolder     → SCOPE: s3://production-bucket/sensitive-data/\n",
        "\n",
        "Matching (longest prefix wins):\n",
        "────────────────────────────────\n",
        "URL                                              → Secret usado\n",
        "────────────────────────────────────────────────────────────────\n",
        "s3://other-bucket/file.parquet                   → s3_all\n",
        "s3://production-bucket/public/data.csv           → s3_prod_bucket\n",
        "s3://production-bucket/sensitive-data/pii.parquet → s3_prod_subfolder\n",
        "s3://production-bucket/sensitive-data/sub/file    → s3_prod_subfolder\n",
        "\n",
        "Regras:\n",
        "───────\n",
        "✓ SCOPE mais específico (mais longo) tem prioridade\n",
        "✓ Matching é por prefixo, não por regex\n",
        "✓ Trailing slash recomendado mas não obrigatório\n",
        "✓ Case-sensitive\n",
        "\"\"\")\n",
        "\n",
        "# Verificar matching\n",
        "urls = [\n",
        "    's3://other-bucket/file.parquet',\n",
        "    's3://production-bucket/public/data.csv',\n",
        "    's3://production-bucket/sensitive-data/pii.parquet'\n",
        "]\n",
        "\n",
        "print(\"\\nVerificação com which_secret():\\n\")\n",
        "for url in urls:\n",
        "    result = con.execute(f\"\"\"\n",
        "        SELECT name\n",
        "        FROM which_secret('{url}', 's3')\n",
        "    \"\"\").fetchone()\n",
        "\n",
        "    secret_name = result[0] if result else 'None'\n",
        "    print(f\"{url:55} → {secret_name}\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 3\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Criar múltiplos secrets\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_bucket_a (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'key_a',\n",
        "        SECRET 'secret_a',\n",
        "        SCOPE 's3://bucket-a/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_bucket_b (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'key_b',\n",
        "        SECRET 'secret_b',\n",
        "        SCOPE 's3://bucket-b/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# which_secret() básico\n",
        "print(\"which_secret(url, type):\\n\")\n",
        "\n",
        "result = con.execute(\"\"\"\n",
        "    SELECT * FROM which_secret('s3://bucket-a/file.parquet', 's3')\n",
        "\"\"\").df()\n",
        "\n",
        "print(\"Para 's3://bucket-a/file.parquet':\")\n",
        "print(result[['name', 'type', 'scope']])\n",
        "\n",
        "print(\"\"\"\n",
        "which_secret() function:\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "Sintaxe:\n",
        "────────\n",
        "which_secret(path: VARCHAR, type: VARCHAR) → TABLE\n",
        "\n",
        "Parâmetros:\n",
        "───────────\n",
        "- path: URL ou path para verificar\n",
        "- type: Tipo de secret (s3, azure, gcs, etc.)\n",
        "\n",
        "Retorna:\n",
        "────────\n",
        "Tabela com informações do secret que será usado:\n",
        "- name: Nome do secret\n",
        "- type: Tipo do secret\n",
        "- provider: Provider usado\n",
        "- scope: SCOPE do secret\n",
        "- ... outros campos\n",
        "\n",
        "Uso:\n",
        "────\n",
        "✓ Debug: verificar qual secret será usado\n",
        "✓ Testing: validar configuração de SCOPEs\n",
        "✓ Documentation: listar mapeamentos URL → secret\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 4\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Setup complexo\n",
        "con.execute(\"CREATE SECRET s3_default (TYPE s3, KEY_ID 'default', SECRET 'default')\")\n",
        "con.execute(\"CREATE SECRET s3_prod (TYPE s3, KEY_ID 'prod', SECRET 'prod', SCOPE 's3://prod/')\")\n",
        "con.execute(\"CREATE SECRET s3_analytics (TYPE s3, KEY_ID 'analytics', SECRET 'analytics', SCOPE 's3://prod/analytics/')\")\n",
        "\n",
        "# Testar múltiplas URLs\n",
        "test_urls = [\n",
        "    's3://dev-bucket/data.parquet',\n",
        "    's3://prod/logs/2024/01/data.parquet',\n",
        "    's3://prod/analytics/reports/summary.parquet',\n",
        "    's3://prod/analytics/raw/events.parquet'\n",
        "]\n",
        "\n",
        "print(\"Verificação de Secrets para Múltiplas URLs:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for url in test_urls:\n",
        "    result = con.execute(f\"\"\"\n",
        "        SELECT name, scope\n",
        "        FROM which_secret('{url}', 's3')\n",
        "    \"\"\").fetchone()\n",
        "\n",
        "    if result:\n",
        "        secret_name, scope = result\n",
        "        scope_display = scope if scope else '(global)'\n",
        "        print(f\"\\nURL: {url}\")\n",
        "        print(f\"  → Secret: {secret_name}\")\n",
        "        print(f\"  → Scope: {scope_display}\")\n",
        "    else:\n",
        "        print(f\"\\nURL: {url}\")\n",
        "        print(f\"  → Nenhum secret encontrado!\")\n",
        "\n",
        "print(\"\"\"\n",
        "Análise:\n",
        "────────\n",
        "- s3://dev-bucket/           → s3_default (fallback global)\n",
        "- s3://prod/logs/            → s3_prod (match 's3://prod/')\n",
        "- s3://prod/analytics/*      → s3_analytics (longest match)\n",
        "\n",
        "Hierarquia aplicada:\n",
        "1. s3_analytics: 's3://prod/analytics/' (mais específico)\n",
        "2. s3_prod: 's3://prod/' (intermediário)\n",
        "3. s3_default: (nenhum scope) (fallback)\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 5\n",
        "import duckdb\n",
        "\n",
        "def diagnose_secret_configuration(con, urls, secret_type='s3'):\n",
        "    \"\"\"\n",
        "    Diagnosticar configuração de secrets para múltiplas URLs\n",
        "    \"\"\"\n",
        "    print(f\"\\nDiagnóstico de Secrets ({secret_type}):\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Listar todos os secrets do tipo\n",
        "    all_secrets = con.execute(f\"\"\"\n",
        "        SELECT name, scope\n",
        "        FROM duckdb_secrets()\n",
        "        WHERE type = '{secret_type}'\n",
        "        ORDER BY LENGTH(scope) DESC, name\n",
        "    \"\"\").df()\n",
        "\n",
        "    print(f\"\\nSecrets configurados ({len(all_secrets)}):\")\n",
        "    for _, row in all_secrets.iterrows():\n",
        "        scope = row['scope'] if row['scope'] else '(global)'\n",
        "        print(f\"  - {row['name']:20} → {scope}\")\n",
        "\n",
        "    # Testar cada URL\n",
        "    print(f\"\\nTeste de URLs:\")\n",
        "    for url in urls:\n",
        "        try:\n",
        "            result = con.execute(f\"\"\"\n",
        "                SELECT name, scope\n",
        "                FROM which_secret('{url}', '{secret_type}')\n",
        "            \"\"\").fetchone()\n",
        "\n",
        "            if result:\n",
        "                name, scope = result\n",
        "                scope_display = scope if scope else '(global)'\n",
        "                print(f\"  ✓ {url:50} → {name} [{scope_display}]\")\n",
        "            else:\n",
        "                print(f\"  ✗ {url:50} → NENHUM SECRET\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ {url:50} → ERRO: {e}\")\n",
        "\n",
        "# Exemplo de uso\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Configurar secrets\n",
        "con.execute(\"CREATE SECRET s3_public (TYPE s3, KEY_ID 'pub', SECRET 'pub', SCOPE 's3://public-data/')\")\n",
        "con.execute(\"CREATE SECRET s3_private (TYPE s3, KEY_ID 'priv', SECRET 'priv', SCOPE 's3://private-data/')\")\n",
        "con.execute(\"CREATE SECRET s3_backup (TYPE s3, KEY_ID 'backup', SECRET 'backup')\")\n",
        "\n",
        "# URLs para testar\n",
        "urls_to_test = [\n",
        "    's3://public-data/dataset.parquet',\n",
        "    's3://private-data/sensitive.parquet',\n",
        "    's3://unknown-bucket/file.parquet',\n",
        "    's3://public-data/subfolder/nested.parquet'\n",
        "]\n",
        "\n",
        "diagnose_secret_configuration(con, urls_to_test, 's3')\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 6\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "print(\"\"\"\n",
        "Cenário: Múltiplos Buckets S3 com Diferentes Credenciais\n",
        "════════════════════════════════════════════════════════\n",
        "\"\"\")\n",
        "\n",
        "# Bucket público (credenciais de read-only)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_public_datasets (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAPUBLIC',\n",
        "        SECRET 'public_secret',\n",
        "        REGION 'us-east-1',\n",
        "        SCOPE 's3://company-public-datasets/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Bucket de analytics (credenciais de read/write)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_analytics (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAANALYTICS',\n",
        "        SECRET 'analytics_secret',\n",
        "        REGION 'us-west-2',\n",
        "        SCOPE 's3://company-analytics/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Bucket de ML (credenciais específicas com GPU)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_ml_models (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAML',\n",
        "        SECRET 'ml_secret',\n",
        "        REGION 'eu-west-1',\n",
        "        SCOPE 's3://company-ml-models/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Bucket de logs (write-only)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_logs (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIALOGS',\n",
        "        SECRET 'logs_secret',\n",
        "        REGION 'us-east-1',\n",
        "        SCOPE 's3://company-logs/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Listar configuração\n",
        "secrets = con.execute(\"\"\"\n",
        "    SELECT name, scope\n",
        "    FROM duckdb_secrets()\n",
        "    WHERE type = 's3'\n",
        "    ORDER BY name\n",
        "\"\"\").df()\n",
        "\n",
        "print(\"\\nConfiguração de Secrets:\")\n",
        "for _, row in secrets.iterrows():\n",
        "    print(f\"  {row['name']:25} → {row['scope']}\")\n",
        "\n",
        "print(\"\"\"\n",
        "Vantagens desta Abordagem:\n",
        "──────────────────────────\n",
        "✓ Privilégios mínimos (least privilege)\n",
        "✓ Separação de concerns\n",
        "✓ Diferentes regiões otimizadas\n",
        "✓ Isolamento de credenciais\n",
        "✓ Facilita rotação por bucket\n",
        "✓ Auditoria granular\n",
        "\n",
        "Queries Exemplo:\n",
        "────────────────\n",
        "-- Ler dados públicos\n",
        "SELECT * FROM 's3://company-public-datasets/census/2020.parquet';\n",
        "\n",
        "-- Análise\n",
        "SELECT * FROM 's3://company-analytics/reports/monthly.parquet';\n",
        "\n",
        "-- ML inference\n",
        "SELECT * FROM 's3://company-ml-models/prod/model-v2.parquet';\n",
        "\n",
        "-- Logs\n",
        "COPY (SELECT * FROM events) TO 's3://company-logs/2024/01/events.parquet';\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 7\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "print(\"\"\"\n",
        "Cenário: Cross-Account S3 Access\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "Empresa com múltiplas AWS accounts:\n",
        "- Account A (111111111111): Production\n",
        "- Account B (222222222222): Analytics\n",
        "- Account C (333333333333): Partner\n",
        "\"\"\")\n",
        "\n",
        "# Account A - Production\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_account_a (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAACCOUNTA',\n",
        "        SECRET 'account_a_secret',\n",
        "        REGION 'us-east-1',\n",
        "        SCOPE 's3://prod-account-a/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Account B - Analytics (com assume role)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_account_b (\n",
        "        TYPE s3,\n",
        "        PROVIDER credential_chain,\n",
        "        CHAIN 'sts',\n",
        "        ROLE_ARN 'arn:aws:iam::222222222222:role/AnalyticsRole',\n",
        "        REGION 'us-west-2',\n",
        "        SCOPE 's3://analytics-account-b/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Account C - Partner (read-only)\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET s3_account_c (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAACCOUNTC',\n",
        "        SECRET 'account_c_secret',\n",
        "        REGION 'eu-west-1',\n",
        "        SCOPE 's3://partner-account-c/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "print(\"\"\"\n",
        "Setup de Cross-Account:\n",
        "───────────────────────\n",
        "\n",
        "Account A → Account B (Assume Role):\n",
        "1. No Account B, criar role com trust policy:\n",
        "   {\n",
        "     \"Version\": \"2012-10-17\",\n",
        "     \"Statement\": [{\n",
        "       \"Effect\": \"Allow\",\n",
        "       \"Principal\": {\"AWS\": \"arn:aws:iam::111111111111:user/duckdb-user\"},\n",
        "       \"Action\": \"sts:AssumeRole\"\n",
        "     }]\n",
        "   }\n",
        "\n",
        "2. Attachar policy ao role:\n",
        "   {\n",
        "     \"Version\": \"2012-10-17\",\n",
        "     \"Statement\": [{\n",
        "       \"Effect\": \"Allow\",\n",
        "       \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"],\n",
        "       \"Resource\": [\n",
        "         \"arn:aws:s3:::analytics-account-b\",\n",
        "         \"arn:aws:s3:::analytics-account-b/*\"\n",
        "       ]\n",
        "     }]\n",
        "   }\n",
        "\n",
        "3. No Account A, dar permissão de AssumeRole ao usuário\n",
        "\n",
        "4. Usar no DuckDB com STS credential chain\n",
        "\n",
        "Query Cross-Account:\n",
        "────────────────────\n",
        "-- Account A\n",
        "SELECT * FROM 's3://prod-account-a/data.parquet';\n",
        "\n",
        "-- Account B (via assume role)\n",
        "SELECT * FROM 's3://analytics-account-b/reports.parquet';\n",
        "\n",
        "-- Account C\n",
        "SELECT * FROM 's3://partner-account-c/shared.parquet';\n",
        "\n",
        "-- JOIN entre accounts!\n",
        "SELECT\n",
        "    a.user_id,\n",
        "    a.transactions,\n",
        "    b.analytics_score\n",
        "FROM 's3://prod-account-a/users.parquet' a\n",
        "JOIN 's3://analytics-account-b/scores.parquet' b\n",
        "  ON a.user_id = b.user_id;\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 8\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "con.execute(\"INSTALL azure; LOAD azure;\")\n",
        "\n",
        "print(\"\"\"\n",
        "Cenário: Multi-Cloud Storage\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "Dados distribuídos em múltiplos cloud providers\n",
        "\"\"\")\n",
        "\n",
        "# AWS S3\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET aws_main (\n",
        "        TYPE s3,\n",
        "        KEY_ID 'AKIAAWS',\n",
        "        SECRET 'aws_secret',\n",
        "        REGION 'us-east-1',\n",
        "        SCOPE 's3://company-data-aws/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Cloudflare R2\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET cloudflare_cdn (\n",
        "        TYPE r2,\n",
        "        KEY_ID 'r2_key',\n",
        "        SECRET 'r2_secret',\n",
        "        ACCOUNT_ID 'cf_account_id',\n",
        "        SCOPE 'r2://company-cdn/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Google Cloud Storage\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET gcs_archive (\n",
        "        TYPE gcs,\n",
        "        PROVIDER credential_chain,\n",
        "        SCOPE 'gs://company-archive-gcs/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "# Azure Blob Storage\n",
        "con.execute(\"\"\"\n",
        "    CREATE SECRET azure_backup (\n",
        "        TYPE azure,\n",
        "        PROVIDER managed_identity,\n",
        "        ACCOUNT_NAME 'companybackup',\n",
        "        SCOPE 'azure://backups/'\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "secrets = con.execute(\"\"\"\n",
        "    SELECT name, type, scope\n",
        "    FROM duckdb_secrets()\n",
        "    ORDER BY type, name\n",
        "\"\"\").df()\n",
        "\n",
        "print(\"\\nConfiguração Multi-Cloud:\")\n",
        "print(secrets.to_string(index=False))\n",
        "\n",
        "print(\"\"\"\n",
        "Queries Multi-Cloud:\n",
        "────────────────────\n",
        "-- AWS S3 (production data)\n",
        "SELECT * FROM 's3://company-data-aws/sales/2024.parquet';\n",
        "\n",
        "-- Cloudflare R2 (CDN assets)\n",
        "SELECT * FROM 'r2://company-cdn/images/catalog.parquet';\n",
        "\n",
        "-- GCS (long-term archive)\n",
        "SELECT * FROM 'gs://company-archive-gcs/historical/2020.parquet';\n",
        "\n",
        "-- Azure (backups)\n",
        "SELECT * FROM 'azure://backups/daily/backup-2024-01-20.parquet';\n",
        "\n",
        "-- Cross-cloud analytics!\n",
        "SELECT\n",
        "    'AWS' as source, COUNT(*) as records\n",
        "FROM 's3://company-data-aws/sales/2024.parquet'\n",
        "UNION ALL\n",
        "SELECT\n",
        "    'GCS' as source, COUNT(*) as records\n",
        "FROM 'gs://company-archive-gcs/historical/2020.parquet'\n",
        "UNION ALL\n",
        "SELECT\n",
        "    'Azure' as source, COUNT(*) as records\n",
        "FROM 'azure://backups/daily/backup-2024-01-20.parquet';\n",
        "\n",
        "Vantagens Multi-Cloud:\n",
        "──────────────────────\n",
        "✓ Vendor lock-in mitigation\n",
        "✓ Cost optimization (use cheapest for each use case)\n",
        "✓ Geographic distribution\n",
        "✓ Compliance (data residency requirements)\n",
        "✓ Disaster recovery\n",
        "✓ Best-of-breed services\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 9\n",
        "import duckdb\n",
        "\n",
        "print(\"\"\"\n",
        "Estratégias de Naming para Secrets:\n",
        "════════════════════════════════════════════════════════\n",
        "\n",
        "1. Por Ambiente:\n",
        "   ─────────────\n",
        "   - dev_s3_analytics\n",
        "   - staging_s3_analytics\n",
        "   - prod_s3_analytics\n",
        "\n",
        "2. Por Projeto/Team:\n",
        "   ──────────────────\n",
        "   - s3_marketing_data\n",
        "   - s3_engineering_logs\n",
        "   - s3_finance_reports\n",
        "\n",
        "3. Por Região:\n",
        "   ───────────\n",
        "   - s3_us_east_1\n",
        "   - s3_eu_west_1\n",
        "   - s3_ap_southeast_1\n",
        "\n",
        "4. Por Função:\n",
        "   ───────────\n",
        "   - s3_readonly_public\n",
        "   - s3_readwrite_analytics\n",
        "   - s3_writeonly_logs\n",
        "\n",
        "5. Hierárquico:\n",
        "   ────────────\n",
        "   - company_aws_s3_prod_analytics\n",
        "   - company_gcp_gcs_dev_ml\n",
        "   - company_azure_blob_staging_backup\n",
        "\n",
        "Recomendações:\n",
        "──────────────\n",
        "✓ Usar snake_case\n",
        "✓ Incluir provider no nome (s3_, gcs_, azure_)\n",
        "✓ Ser descritivo mas conciso\n",
        "✓ Consistente em todo o projeto\n",
        "✓ Documentar convenção no README\n",
        "\"\"\")\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Exemplo de naming bem estruturado\n",
        "secrets_config = [\n",
        "    # Ambiente → Provider → Projeto → Região\n",
        "    (\"prod_s3_analytics_us\", \"s3://prod-analytics-us/\", \"us-east-1\"),\n",
        "    (\"prod_s3_analytics_eu\", \"s3://prod-analytics-eu/\", \"eu-west-1\"),\n",
        "    (\"staging_s3_analytics\", \"s3://staging-analytics/\", \"us-west-2\"),\n",
        "    (\"dev_s3_analytics\", \"s3://dev-analytics/\", \"us-west-2\"),\n",
        "]\n",
        "\n",
        "for name, scope, region in secrets_config:\n",
        "    con.execute(f\"\"\"\n",
        "        CREATE SECRET {name} (\n",
        "            TYPE s3,\n",
        "            KEY_ID 'key',\n",
        "            SECRET 'secret',\n",
        "            REGION '{region}',\n",
        "            SCOPE '{scope}'\n",
        "        )\n",
        "    \"\"\")\n",
        "    print(f\"✓ Created: {name:30} → {scope}\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 10\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "def create_secret_inventory(con):\n",
        "    \"\"\"\n",
        "    Criar inventário de secrets para documentação\n",
        "    \"\"\"\n",
        "    secrets = con.execute(\"\"\"\n",
        "        SELECT\n",
        "            name,\n",
        "            type,\n",
        "            provider,\n",
        "            scope,\n",
        "            persistent,\n",
        "            storage\n",
        "        FROM duckdb_secrets()\n",
        "        ORDER BY type, name\n",
        "    \"\"\").df()\n",
        "\n",
        "    return secrets\n",
        "\n",
        "def export_secret_documentation(secrets_df, filename='secrets_inventory.md'):\n",
        "    \"\"\"\n",
        "    Exportar documentação de secrets\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"# DuckDB Secrets Inventory\\n\\n\")\n",
        "        f.write(f\"**Total Secrets:** {len(secrets_df)}\\n\\n\")\n",
        "\n",
        "        # Agrupar por tipo\n",
        "        for secret_type in secrets_df['type'].unique():\n",
        "            type_secrets = secrets_df[secrets_df['type'] == secret_type]\n",
        "            f.write(f\"## {secret_type.upper()} Secrets\\n\\n\")\n",
        "\n",
        "            for _, secret in type_secrets.iterrows():\n",
        "                f.write(f\"### {secret['name']}\\n\\n\")\n",
        "                f.write(f\"- **Type:** {secret['type']}\\n\")\n",
        "                f.write(f\"- **Provider:** {secret['provider']}\\n\")\n",
        "                f.write(f\"- **Scope:** {secret['scope'] if secret['scope'] else '(global)'}\\n\")\n",
        "                f.write(f\"- **Persistent:** {secret['persistent']}\\n\")\n",
        "                f.write(f\"- **Storage:** {secret['storage']}\\n\\n\")\n",
        "\n",
        "    print(f\"✓ Documentation exported to {filename}\")\n",
        "\n",
        "# Exemplo de uso\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "\n",
        "# Criar alguns secrets\n",
        "con.execute(\"CREATE SECRET prod_s3_data (TYPE s3, KEY_ID 'k', SECRET 's', SCOPE 's3://prod-data/')\")\n",
        "con.execute(\"CREATE SECRET dev_s3_data (TYPE s3, KEY_ID 'k', SECRET 's', SCOPE 's3://dev-data/')\")\n",
        "con.execute(\"CREATE SECRET api_auth (TYPE http, BEARER_TOKEN 'token')\")\n",
        "\n",
        "# Gerar inventário\n",
        "inventory = create_secret_inventory(con)\n",
        "print(\"\\nSecret Inventory:\")\n",
        "print(inventory[['name', 'type', 'scope']])\n",
        "\n",
        "# Exportar documentação\n",
        "export_secret_documentation(inventory)\n",
        "\n",
        "print(\"\"\"\n",
        "Secret Management Best Practices:\n",
        "══════════════════════════════════════════════════════\n",
        "\n",
        "1. Documentation:\n",
        "   ──────────────\n",
        "   ✓ Manter inventário atualizado\n",
        "   ✓ Documentar purpose de cada secret\n",
        "   ✓ Documentar SCOPEs e seus significados\n",
        "   ✓ Incluir owner/team responsável\n",
        "\n",
        "2. Lifecycle Management:\n",
        "   ─────────────────────\n",
        "   ✓ Rotação regular de credenciais\n",
        "   ✓ Remoção de secrets não utilizados\n",
        "   ✓ Versionamento de configurações\n",
        "   ✓ Backup de persistent secrets\n",
        "\n",
        "3. Security:\n",
        "   ─────────\n",
        "   ✓ Princípio de privilégio mínimo\n",
        "   ✓ Separação por ambiente\n",
        "   ✓ Auditoria de acesso\n",
        "   ✓ Secrets em variáveis de ambiente (não hardcoded)\n",
        "\n",
        "4. Testing:\n",
        "   ────────\n",
        "   ✓ Validar SCOPEs com which_secret()\n",
        "   ✓ Testar em staging antes de prod\n",
        "   ✓ Automated tests para configuração\n",
        "   ✓ Rollback plan\n",
        "\n",
        "5. Monitoring:\n",
        "   ───────────\n",
        "   ✓ Alertas para credenciais expiradas\n",
        "   ✓ Log de uso de secrets\n",
        "   ✓ Detecção de secrets vazados (git-secrets, trufflehog)\n",
        "   ✓ Regular security audits\n",
        "\"\"\")\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 11\n",
        "# 1. Crie 5 secrets S3 com hierarquia de SCOPEs:\n",
        "#    - Um global (sem SCOPE)\n",
        "#    - Um para 's3://data/'\n",
        "#    - Um para 's3://data/prod/'\n",
        "#    - Um para 's3://data/prod/sensitive/'\n",
        "#    - Um para bucket diferente 's3://logs/'\n",
        "# 2. Teste 10 URLs diferentes com which_secret()\n",
        "# 3. Documente o matching de cada URL\n",
        "# 4. Explique a hierarquia aplicada\n",
        "\n",
        "# Sua solução aqui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 12\n",
        "# 1. Crie secrets para 3 ambientes (dev, staging, prod)\n",
        "# 2. Cada ambiente deve ter:\n",
        "#    - S3 secret com SCOPE específico\n",
        "#    - PostgreSQL secret\n",
        "#    - HTTP secret para API\n",
        "# 3. Use naming convention consistente\n",
        "# 4. Documente a estratégia de naming\n",
        "# 5. Crie função para switch entre ambientes\n",
        "\n",
        "# Sua solução aqui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 13\n",
        "# 1. Configure secrets para:\n",
        "#    - AWS S3 (2 buckets diferentes)\n",
        "#    - Azure Blob Storage (1 container)\n",
        "#    - GCS (1 bucket)\n",
        "# 2. Use SCOPEs apropriados\n",
        "# 3. Teste which_secret() para cada provider\n",
        "# 4. Crie query que une dados de todos os providers\n",
        "# 5. Documente vantagens e challenges\n",
        "\n",
        "# Sua solução aqui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo/Bloco 14\n",
        "# 1. Crie 10+ secrets variados (diferentes types, SCOPEs)\n",
        "# 2. Implemente função para gerar inventário completo\n",
        "# 3. Exporte para Markdown com formatação\n",
        "# 4. Inclua recommendations e warnings\n",
        "# 5. Adicione validation checks (duplicate SCOPEs, etc.)\n",
        "\n",
        "# Sua solução aqui"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}