{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstalaÃ§Ã£o de pacotes necessÃ¡rios\n",
    "!pip install -q duckdb\n",
    "\n",
    "print(\"âœ… DependÃªncias instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb5abd",
   "metadata": {},
   "source": [
    "## ğŸ“¦ InstalaÃ§Ã£o de DependÃªncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 07 Scope Named Secrets\n",
    "\n",
    "Notebook gerado automaticamente a partir do cÃ³digo fonte python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "capitulo_07_scope_named_secrets\n",
    "\"\"\"\n",
    "\n",
    "# capitulo_07_scope_named_secrets\n",
    "import duckdb\n",
    "import os\n",
    "\n",
    "# Exemplo/Bloco 1\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "print(\"\"\"\n",
    "SCOPE em DuckDB Secrets:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "O que Ã©:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SCOPE define para quais URLs/paths um secret se aplica.\n",
    "Ã‰ um pattern matching de prefixo de URL.\n",
    "\n",
    "Funcionamento:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Quando vocÃª faz uma query para 's3://bucket1/file.parquet',\n",
    "DuckDB procura o secret com SCOPE que melhor casa com a URL.\n",
    "\n",
    "Matching:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. Procura exact match\n",
    "2. Procura longest prefix match\n",
    "3. Usa secret sem SCOPE como fallback\n",
    "\n",
    "Exemplos:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\")\n",
    "\n",
    "# Secret sem SCOPE (aplica a todos os S3)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_default (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'default_key',\n",
    "        SECRET 'default_secret'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Secret com SCOPE especÃ­fico\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_bucket1 (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'bucket1_key',\n",
    "        SECRET 'bucket1_secret',\n",
    "        SCOPE 's3://bucket1/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_bucket2 (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'bucket2_key',\n",
    "        SECRET 'bucket2_secret',\n",
    "        SCOPE 's3://bucket2/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Verificar SCOPEs\n",
    "secrets = con.execute(\"\"\"\n",
    "    SELECT name, scope\n",
    "    FROM duckdb_secrets()\n",
    "    WHERE type = 's3'\n",
    "    ORDER BY name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nSecrets criados:\")\n",
    "print(secrets)\n",
    "\n",
    "print(\"\"\"\n",
    "Matching de URLs:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "'s3://bucket1/file.parquet'  â†’ s3_bucket1\n",
    "'s3://bucket2/data.csv'      â†’ s3_bucket2\n",
    "'s3://bucket3/other.parquet' â†’ s3_default (fallback)\n",
    "'s3://bucket1/deep/nested'   â†’ s3_bucket1 (prefix match)\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 2\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Hierarquia de SCOPEs\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_all (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'all',\n",
    "        SECRET 'all'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_prod_bucket (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'prod',\n",
    "        SECRET 'prod',\n",
    "        SCOPE 's3://production-bucket/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_prod_subfolder (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'sensitive',\n",
    "        SECRET 'sensitive',\n",
    "        SCOPE 's3://production-bucket/sensitive-data/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Hierarquia de SCOPEs:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Secrets criados:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. s3_all                â†’ SCOPE: (nenhum)\n",
    "2. s3_prod_bucket        â†’ SCOPE: s3://production-bucket/\n",
    "3. s3_prod_subfolder     â†’ SCOPE: s3://production-bucket/sensitive-data/\n",
    "\n",
    "Matching (longest prefix wins):\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "URL                                              â†’ Secret usado\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "s3://other-bucket/file.parquet                   â†’ s3_all\n",
    "s3://production-bucket/public/data.csv           â†’ s3_prod_bucket\n",
    "s3://production-bucket/sensitive-data/pii.parquet â†’ s3_prod_subfolder\n",
    "s3://production-bucket/sensitive-data/sub/file    â†’ s3_prod_subfolder\n",
    "\n",
    "Regras:\n",
    "â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ SCOPE mais especÃ­fico (mais longo) tem prioridade\n",
    "âœ“ Matching Ã© por prefixo, nÃ£o por regex\n",
    "âœ“ Trailing slash recomendado mas nÃ£o obrigatÃ³rio\n",
    "âœ“ Case-sensitive\n",
    "\"\"\")\n",
    "\n",
    "# Verificar matching\n",
    "urls = [\n",
    "    's3://other-bucket/file.parquet',\n",
    "    's3://production-bucket/public/data.csv',\n",
    "    's3://production-bucket/sensitive-data/pii.parquet'\n",
    "]\n",
    "\n",
    "print(\"\\nVerificaÃ§Ã£o com which_secret():\\n\")\n",
    "for url in urls:\n",
    "    result = con.execute(f\"\"\"\n",
    "        SELECT name\n",
    "        FROM which_secret('{url}', 's3')\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "    secret_name = result[0] if result else 'None'\n",
    "    print(f\"{url:55} â†’ {secret_name}\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 3\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Criar mÃºltiplos secrets\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_bucket_a (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'key_a',\n",
    "        SECRET 'secret_a',\n",
    "        SCOPE 's3://bucket-a/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_bucket_b (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'key_b',\n",
    "        SECRET 'secret_b',\n",
    "        SCOPE 's3://bucket-b/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# which_secret() bÃ¡sico\n",
    "print(\"which_secret(url, type):\\n\")\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT * FROM which_secret('s3://bucket-a/file.parquet', 's3')\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Para 's3://bucket-a/file.parquet':\")\n",
    "print(result[['name', 'type', 'scope']])\n",
    "\n",
    "print(\"\"\"\n",
    "which_secret() function:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Sintaxe:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "which_secret(path: VARCHAR, type: VARCHAR) â†’ TABLE\n",
    "\n",
    "ParÃ¢metros:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- path: URL ou path para verificar\n",
    "- type: Tipo de secret (s3, azure, gcs, etc.)\n",
    "\n",
    "Retorna:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Tabela com informaÃ§Ãµes do secret que serÃ¡ usado:\n",
    "- name: Nome do secret\n",
    "- type: Tipo do secret\n",
    "- provider: Provider usado\n",
    "- scope: SCOPE do secret\n",
    "- ... outros campos\n",
    "\n",
    "Uso:\n",
    "â”€â”€â”€â”€\n",
    "âœ“ Debug: verificar qual secret serÃ¡ usado\n",
    "âœ“ Testing: validar configuraÃ§Ã£o de SCOPEs\n",
    "âœ“ Documentation: listar mapeamentos URL â†’ secret\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 4\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Setup complexo\n",
    "con.execute(\"CREATE SECRET s3_default (TYPE s3, KEY_ID 'default', SECRET 'default')\")\n",
    "con.execute(\"CREATE SECRET s3_prod (TYPE s3, KEY_ID 'prod', SECRET 'prod', SCOPE 's3://prod/')\")\n",
    "con.execute(\"CREATE SECRET s3_analytics (TYPE s3, KEY_ID 'analytics', SECRET 'analytics', SCOPE 's3://prod/analytics/')\")\n",
    "\n",
    "# Testar mÃºltiplas URLs\n",
    "test_urls = [\n",
    "    's3://dev-bucket/data.parquet',\n",
    "    's3://prod/logs/2024/01/data.parquet',\n",
    "    's3://prod/analytics/reports/summary.parquet',\n",
    "    's3://prod/analytics/raw/events.parquet'\n",
    "]\n",
    "\n",
    "print(\"VerificaÃ§Ã£o de Secrets para MÃºltiplas URLs:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for url in test_urls:\n",
    "    result = con.execute(f\"\"\"\n",
    "        SELECT name, scope\n",
    "        FROM which_secret('{url}', 's3')\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "    if result:\n",
    "        secret_name, scope = result\n",
    "        scope_display = scope if scope else '(global)'\n",
    "        print(f\"\\nURL: {url}\")\n",
    "        print(f\"  â†’ Secret: {secret_name}\")\n",
    "        print(f\"  â†’ Scope: {scope_display}\")\n",
    "    else:\n",
    "        print(f\"\\nURL: {url}\")\n",
    "        print(f\"  â†’ Nenhum secret encontrado!\")\n",
    "\n",
    "print(\"\"\"\n",
    "AnÃ¡lise:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- s3://dev-bucket/           â†’ s3_default (fallback global)\n",
    "- s3://prod/logs/            â†’ s3_prod (match 's3://prod/')\n",
    "- s3://prod/analytics/*      â†’ s3_analytics (longest match)\n",
    "\n",
    "Hierarquia aplicada:\n",
    "1. s3_analytics: 's3://prod/analytics/' (mais especÃ­fico)\n",
    "2. s3_prod: 's3://prod/' (intermediÃ¡rio)\n",
    "3. s3_default: (nenhum scope) (fallback)\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 5\n",
    "import duckdb\n",
    "\n",
    "def diagnose_secret_configuration(con, urls, secret_type='s3'):\n",
    "    \"\"\"\n",
    "    Diagnosticar configuraÃ§Ã£o de secrets para mÃºltiplas URLs\n",
    "    \"\"\"\n",
    "    print(f\"\\nDiagnÃ³stico de Secrets ({secret_type}):\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Listar todos os secrets do tipo\n",
    "    all_secrets = con.execute(f\"\"\"\n",
    "        SELECT name, scope\n",
    "        FROM duckdb_secrets()\n",
    "        WHERE type = '{secret_type}'\n",
    "        ORDER BY LENGTH(scope) DESC, name\n",
    "    \"\"\").df()\n",
    "\n",
    "    print(f\"\\nSecrets configurados ({len(all_secrets)}):\")\n",
    "    for _, row in all_secrets.iterrows():\n",
    "        scope = row['scope'] if row['scope'] else '(global)'\n",
    "        print(f\"  - {row['name']:20} â†’ {scope}\")\n",
    "\n",
    "    # Testar cada URL\n",
    "    print(f\"\\nTeste de URLs:\")\n",
    "    for url in urls:\n",
    "        try:\n",
    "            result = con.execute(f\"\"\"\n",
    "                SELECT name, scope\n",
    "                FROM which_secret('{url}', '{secret_type}')\n",
    "            \"\"\").fetchone()\n",
    "\n",
    "            if result:\n",
    "                name, scope = result\n",
    "                scope_display = scope if scope else '(global)'\n",
    "                print(f\"  âœ“ {url:50} â†’ {name} [{scope_display}]\")\n",
    "            else:\n",
    "                print(f\"  âœ— {url:50} â†’ NENHUM SECRET\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— {url:50} â†’ ERRO: {e}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Configurar secrets\n",
    "con.execute(\"CREATE SECRET s3_public (TYPE s3, KEY_ID 'pub', SECRET 'pub', SCOPE 's3://public-data/')\")\n",
    "con.execute(\"CREATE SECRET s3_private (TYPE s3, KEY_ID 'priv', SECRET 'priv', SCOPE 's3://private-data/')\")\n",
    "con.execute(\"CREATE SECRET s3_backup (TYPE s3, KEY_ID 'backup', SECRET 'backup')\")\n",
    "\n",
    "# URLs para testar\n",
    "urls_to_test = [\n",
    "    's3://public-data/dataset.parquet',\n",
    "    's3://private-data/sensitive.parquet',\n",
    "    's3://unknown-bucket/file.parquet',\n",
    "    's3://public-data/subfolder/nested.parquet'\n",
    "]\n",
    "\n",
    "diagnose_secret_configuration(con, urls_to_test, 's3')\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 6\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "print(\"\"\"\n",
    "CenÃ¡rio: MÃºltiplos Buckets S3 com Diferentes Credenciais\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "# Bucket pÃºblico (credenciais de read-only)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_public_datasets (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAPUBLIC',\n",
    "        SECRET 'public_secret',\n",
    "        REGION 'us-east-1',\n",
    "        SCOPE 's3://company-public-datasets/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Bucket de analytics (credenciais de read/write)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_analytics (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAANALYTICS',\n",
    "        SECRET 'analytics_secret',\n",
    "        REGION 'us-west-2',\n",
    "        SCOPE 's3://company-analytics/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Bucket de ML (credenciais especÃ­ficas com GPU)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_ml_models (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAML',\n",
    "        SECRET 'ml_secret',\n",
    "        REGION 'eu-west-1',\n",
    "        SCOPE 's3://company-ml-models/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Bucket de logs (write-only)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_logs (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIALOGS',\n",
    "        SECRET 'logs_secret',\n",
    "        REGION 'us-east-1',\n",
    "        SCOPE 's3://company-logs/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Listar configuraÃ§Ã£o\n",
    "secrets = con.execute(\"\"\"\n",
    "    SELECT name, scope\n",
    "    FROM duckdb_secrets()\n",
    "    WHERE type = 's3'\n",
    "    ORDER BY name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nConfiguraÃ§Ã£o de Secrets:\")\n",
    "for _, row in secrets.iterrows():\n",
    "    print(f\"  {row['name']:25} â†’ {row['scope']}\")\n",
    "\n",
    "print(\"\"\"\n",
    "Vantagens desta Abordagem:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ PrivilÃ©gios mÃ­nimos (least privilege)\n",
    "âœ“ SeparaÃ§Ã£o de concerns\n",
    "âœ“ Diferentes regiÃµes otimizadas\n",
    "âœ“ Isolamento de credenciais\n",
    "âœ“ Facilita rotaÃ§Ã£o por bucket\n",
    "âœ“ Auditoria granular\n",
    "\n",
    "Queries Exemplo:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "-- Ler dados pÃºblicos\n",
    "SELECT * FROM 's3://company-public-datasets/census/2020.parquet';\n",
    "\n",
    "-- AnÃ¡lise\n",
    "SELECT * FROM 's3://company-analytics/reports/monthly.parquet';\n",
    "\n",
    "-- ML inference\n",
    "SELECT * FROM 's3://company-ml-models/prod/model-v2.parquet';\n",
    "\n",
    "-- Logs\n",
    "COPY (SELECT * FROM events) TO 's3://company-logs/2024/01/events.parquet';\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 7\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "print(\"\"\"\n",
    "CenÃ¡rio: Cross-Account S3 Access\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Empresa com mÃºltiplas AWS accounts:\n",
    "- Account A (111111111111): Production\n",
    "- Account B (222222222222): Analytics\n",
    "- Account C (333333333333): Partner\n",
    "\"\"\")\n",
    "\n",
    "# Account A - Production\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_account_a (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAACCOUNTA',\n",
    "        SECRET 'account_a_secret',\n",
    "        REGION 'us-east-1',\n",
    "        SCOPE 's3://prod-account-a/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Account B - Analytics (com assume role)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_account_b (\n",
    "        TYPE s3,\n",
    "        PROVIDER credential_chain,\n",
    "        CHAIN 'sts',\n",
    "        ROLE_ARN 'arn:aws:iam::222222222222:role/AnalyticsRole',\n",
    "        REGION 'us-west-2',\n",
    "        SCOPE 's3://analytics-account-b/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Account C - Partner (read-only)\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET s3_account_c (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAACCOUNTC',\n",
    "        SECRET 'account_c_secret',\n",
    "        REGION 'eu-west-1',\n",
    "        SCOPE 's3://partner-account-c/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Setup de Cross-Account:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Account A â†’ Account B (Assume Role):\n",
    "1. No Account B, criar role com trust policy:\n",
    "   {\n",
    "     \"Version\": \"2012-10-17\",\n",
    "     \"Statement\": [{\n",
    "       \"Effect\": \"Allow\",\n",
    "       \"Principal\": {\"AWS\": \"arn:aws:iam::111111111111:user/duckdb-user\"},\n",
    "       \"Action\": \"sts:AssumeRole\"\n",
    "     }]\n",
    "   }\n",
    "\n",
    "2. Attachar policy ao role:\n",
    "   {\n",
    "     \"Version\": \"2012-10-17\",\n",
    "     \"Statement\": [{\n",
    "       \"Effect\": \"Allow\",\n",
    "       \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"],\n",
    "       \"Resource\": [\n",
    "         \"arn:aws:s3:::analytics-account-b\",\n",
    "         \"arn:aws:s3:::analytics-account-b/*\"\n",
    "       ]\n",
    "     }]\n",
    "   }\n",
    "\n",
    "3. No Account A, dar permissÃ£o de AssumeRole ao usuÃ¡rio\n",
    "\n",
    "4. Usar no DuckDB com STS credential chain\n",
    "\n",
    "Query Cross-Account:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "-- Account A\n",
    "SELECT * FROM 's3://prod-account-a/data.parquet';\n",
    "\n",
    "-- Account B (via assume role)\n",
    "SELECT * FROM 's3://analytics-account-b/reports.parquet';\n",
    "\n",
    "-- Account C\n",
    "SELECT * FROM 's3://partner-account-c/shared.parquet';\n",
    "\n",
    "-- JOIN entre accounts!\n",
    "SELECT\n",
    "    a.user_id,\n",
    "    a.transactions,\n",
    "    b.analytics_score\n",
    "FROM 's3://prod-account-a/users.parquet' a\n",
    "JOIN 's3://analytics-account-b/scores.parquet' b\n",
    "  ON a.user_id = b.user_id;\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 8\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "con.execute(\"INSTALL azure; LOAD azure;\")\n",
    "\n",
    "print(\"\"\"\n",
    "CenÃ¡rio: Multi-Cloud Storage\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Dados distribuÃ­dos em mÃºltiplos cloud providers\n",
    "\"\"\")\n",
    "\n",
    "# AWS S3\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET aws_main (\n",
    "        TYPE s3,\n",
    "        KEY_ID 'AKIAAWS',\n",
    "        SECRET 'aws_secret',\n",
    "        REGION 'us-east-1',\n",
    "        SCOPE 's3://company-data-aws/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Cloudflare R2\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET cloudflare_cdn (\n",
    "        TYPE r2,\n",
    "        KEY_ID 'r2_key',\n",
    "        SECRET 'r2_secret',\n",
    "        ACCOUNT_ID 'cf_account_id',\n",
    "        SCOPE 'r2://company-cdn/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Google Cloud Storage\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET gcs_archive (\n",
    "        TYPE gcs,\n",
    "        PROVIDER credential_chain,\n",
    "        SCOPE 'gs://company-archive-gcs/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Azure Blob Storage\n",
    "con.execute(\"\"\"\n",
    "    CREATE SECRET azure_backup (\n",
    "        TYPE azure,\n",
    "        PROVIDER managed_identity,\n",
    "        ACCOUNT_NAME 'companybackup',\n",
    "        SCOPE 'azure://backups/'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "secrets = con.execute(\"\"\"\n",
    "    SELECT name, type, scope\n",
    "    FROM duckdb_secrets()\n",
    "    ORDER BY type, name\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nConfiguraÃ§Ã£o Multi-Cloud:\")\n",
    "print(secrets.to_string(index=False))\n",
    "\n",
    "print(\"\"\"\n",
    "Queries Multi-Cloud:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "-- AWS S3 (production data)\n",
    "SELECT * FROM 's3://company-data-aws/sales/2024.parquet';\n",
    "\n",
    "-- Cloudflare R2 (CDN assets)\n",
    "SELECT * FROM 'r2://company-cdn/images/catalog.parquet';\n",
    "\n",
    "-- GCS (long-term archive)\n",
    "SELECT * FROM 'gs://company-archive-gcs/historical/2020.parquet';\n",
    "\n",
    "-- Azure (backups)\n",
    "SELECT * FROM 'azure://backups/daily/backup-2024-01-20.parquet';\n",
    "\n",
    "-- Cross-cloud analytics!\n",
    "SELECT\n",
    "    'AWS' as source, COUNT(*) as records\n",
    "FROM 's3://company-data-aws/sales/2024.parquet'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'GCS' as source, COUNT(*) as records\n",
    "FROM 'gs://company-archive-gcs/historical/2020.parquet'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Azure' as source, COUNT(*) as records\n",
    "FROM 'azure://backups/daily/backup-2024-01-20.parquet';\n",
    "\n",
    "Vantagens Multi-Cloud:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Vendor lock-in mitigation\n",
    "âœ“ Cost optimization (use cheapest for each use case)\n",
    "âœ“ Geographic distribution\n",
    "âœ“ Compliance (data residency requirements)\n",
    "âœ“ Disaster recovery\n",
    "âœ“ Best-of-breed services\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 9\n",
    "import duckdb\n",
    "\n",
    "print(\"\"\"\n",
    "EstratÃ©gias de Naming para Secrets:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "1. Por Ambiente:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   - dev_s3_analytics\n",
    "   - staging_s3_analytics\n",
    "   - prod_s3_analytics\n",
    "\n",
    "2. Por Projeto/Team:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   - s3_marketing_data\n",
    "   - s3_engineering_logs\n",
    "   - s3_finance_reports\n",
    "\n",
    "3. Por RegiÃ£o:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   - s3_us_east_1\n",
    "   - s3_eu_west_1\n",
    "   - s3_ap_southeast_1\n",
    "\n",
    "4. Por FunÃ§Ã£o:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   - s3_readonly_public\n",
    "   - s3_readwrite_analytics\n",
    "   - s3_writeonly_logs\n",
    "\n",
    "5. HierÃ¡rquico:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   - company_aws_s3_prod_analytics\n",
    "   - company_gcp_gcs_dev_ml\n",
    "   - company_azure_blob_staging_backup\n",
    "\n",
    "RecomendaÃ§Ãµes:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Usar snake_case\n",
    "âœ“ Incluir provider no nome (s3_, gcs_, azure_)\n",
    "âœ“ Ser descritivo mas conciso\n",
    "âœ“ Consistente em todo o projeto\n",
    "âœ“ Documentar convenÃ§Ã£o no README\n",
    "\"\"\")\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Exemplo de naming bem estruturado\n",
    "secrets_config = [\n",
    "    # Ambiente â†’ Provider â†’ Projeto â†’ RegiÃ£o\n",
    "    (\"prod_s3_analytics_us\", \"s3://prod-analytics-us/\", \"us-east-1\"),\n",
    "    (\"prod_s3_analytics_eu\", \"s3://prod-analytics-eu/\", \"eu-west-1\"),\n",
    "    (\"staging_s3_analytics\", \"s3://staging-analytics/\", \"us-west-2\"),\n",
    "    (\"dev_s3_analytics\", \"s3://dev-analytics/\", \"us-west-2\"),\n",
    "]\n",
    "\n",
    "for name, scope, region in secrets_config:\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE SECRET {name} (\n",
    "            TYPE s3,\n",
    "            KEY_ID 'key',\n",
    "            SECRET 'secret',\n",
    "            REGION '{region}',\n",
    "            SCOPE '{scope}'\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(f\"âœ“ Created: {name:30} â†’ {scope}\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 10\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def create_secret_inventory(con):\n",
    "    \"\"\"\n",
    "    Criar inventÃ¡rio de secrets para documentaÃ§Ã£o\n",
    "    \"\"\"\n",
    "    secrets = con.execute(\"\"\"\n",
    "        SELECT\n",
    "            name,\n",
    "            type,\n",
    "            provider,\n",
    "            scope,\n",
    "            persistent,\n",
    "            storage\n",
    "        FROM duckdb_secrets()\n",
    "        ORDER BY type, name\n",
    "    \"\"\").df()\n",
    "\n",
    "    return secrets\n",
    "\n",
    "def export_secret_documentation(secrets_df, filename='secrets_inventory.md'):\n",
    "    \"\"\"\n",
    "    Exportar documentaÃ§Ã£o de secrets\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"# DuckDB Secrets Inventory\\n\\n\")\n",
    "        f.write(f\"**Total Secrets:** {len(secrets_df)}\\n\\n\")\n",
    "\n",
    "        # Agrupar por tipo\n",
    "        for secret_type in secrets_df['type'].unique():\n",
    "            type_secrets = secrets_df[secrets_df['type'] == secret_type]\n",
    "            f.write(f\"## {secret_type.upper()} Secrets\\n\\n\")\n",
    "\n",
    "            for _, secret in type_secrets.iterrows():\n",
    "                f.write(f\"### {secret['name']}\\n\\n\")\n",
    "                f.write(f\"- **Type:** {secret['type']}\\n\")\n",
    "                f.write(f\"- **Provider:** {secret['provider']}\\n\")\n",
    "                f.write(f\"- **Scope:** {secret['scope'] if secret['scope'] else '(global)'}\\n\")\n",
    "                f.write(f\"- **Persistent:** {secret['persistent']}\\n\")\n",
    "                f.write(f\"- **Storage:** {secret['storage']}\\n\\n\")\n",
    "\n",
    "    print(f\"âœ“ Documentation exported to {filename}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
    "\n",
    "# Criar alguns secrets\n",
    "con.execute(\"CREATE SECRET prod_s3_data (TYPE s3, KEY_ID 'k', SECRET 's', SCOPE 's3://prod-data/')\")\n",
    "con.execute(\"CREATE SECRET dev_s3_data (TYPE s3, KEY_ID 'k', SECRET 's', SCOPE 's3://dev-data/')\")\n",
    "con.execute(\"CREATE SECRET api_auth (TYPE http, BEARER_TOKEN 'token')\")\n",
    "\n",
    "# Gerar inventÃ¡rio\n",
    "inventory = create_secret_inventory(con)\n",
    "print(\"\\nSecret Inventory:\")\n",
    "print(inventory[['name', 'type', 'scope']])\n",
    "\n",
    "# Exportar documentaÃ§Ã£o\n",
    "export_secret_documentation(inventory)\n",
    "\n",
    "print(\"\"\"\n",
    "Secret Management Best Practices:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "1. Documentation:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   âœ“ Manter inventÃ¡rio atualizado\n",
    "   âœ“ Documentar purpose de cada secret\n",
    "   âœ“ Documentar SCOPEs e seus significados\n",
    "   âœ“ Incluir owner/team responsÃ¡vel\n",
    "\n",
    "2. Lifecycle Management:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   âœ“ RotaÃ§Ã£o regular de credenciais\n",
    "   âœ“ RemoÃ§Ã£o de secrets nÃ£o utilizados\n",
    "   âœ“ Versionamento de configuraÃ§Ãµes\n",
    "   âœ“ Backup de persistent secrets\n",
    "\n",
    "3. Security:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   âœ“ PrincÃ­pio de privilÃ©gio mÃ­nimo\n",
    "   âœ“ SeparaÃ§Ã£o por ambiente\n",
    "   âœ“ Auditoria de acesso\n",
    "   âœ“ Secrets em variÃ¡veis de ambiente (nÃ£o hardcoded)\n",
    "\n",
    "4. Testing:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   âœ“ Validar SCOPEs com which_secret()\n",
    "   âœ“ Testar em staging antes de prod\n",
    "   âœ“ Automated tests para configuraÃ§Ã£o\n",
    "   âœ“ Rollback plan\n",
    "\n",
    "5. Monitoring:\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   âœ“ Alertas para credenciais expiradas\n",
    "   âœ“ Log de uso de secrets\n",
    "   âœ“ DetecÃ§Ã£o de secrets vazados (git-secrets, trufflehog)\n",
    "   âœ“ Regular security audits\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "# Exemplo/Bloco 11\n",
    "# 1. Crie 5 secrets S3 com hierarquia de SCOPEs:\n",
    "#    - Um global (sem SCOPE)\n",
    "#    - Um para 's3://data/'\n",
    "#    - Um para 's3://data/prod/'\n",
    "#    - Um para 's3://data/prod/sensitive/'\n",
    "#    - Um para bucket diferente 's3://logs/'\n",
    "# 2. Teste 10 URLs diferentes com which_secret()\n",
    "# 3. Documente o matching de cada URL\n",
    "# 4. Explique a hierarquia aplicada\n",
    "\n",
    "# Sua soluÃ§Ã£o aqui\n",
    "\n",
    "# Exemplo/Bloco 12\n",
    "# 1. Crie secrets para 3 ambientes (dev, staging, prod)\n",
    "# 2. Cada ambiente deve ter:\n",
    "#    - S3 secret com SCOPE especÃ­fico\n",
    "#    - PostgreSQL secret\n",
    "#    - HTTP secret para API\n",
    "# 3. Use naming convention consistente\n",
    "# 4. Documente a estratÃ©gia de naming\n",
    "# 5. Crie funÃ§Ã£o para switch entre ambientes\n",
    "\n",
    "# Sua soluÃ§Ã£o aqui\n",
    "\n",
    "# Exemplo/Bloco 13\n",
    "# 1. Configure secrets para:\n",
    "#    - AWS S3 (2 buckets diferentes)\n",
    "#    - Azure Blob Storage (1 container)\n",
    "#    - GCS (1 bucket)\n",
    "# 2. Use SCOPEs apropriados\n",
    "# 3. Teste which_secret() para cada provider\n",
    "# 4. Crie query que une dados de todos os providers\n",
    "# 5. Documente vantagens e challenges\n",
    "\n",
    "# Sua soluÃ§Ã£o aqui\n",
    "\n",
    "# Exemplo/Bloco 14\n",
    "# 1. Crie 10+ secrets variados (diferentes types, SCOPEs)\n",
    "# 2. Implemente funÃ§Ã£o para gerar inventÃ¡rio completo\n",
    "# 3. Exporte para Markdown com formataÃ§Ã£o\n",
    "# 4. Inclua recommendations e warnings\n",
    "# 5. Adicione validation checks (duplicate SCOPEs, etc.)\n",
    "\n",
    "# Sua soluÃ§Ã£o aqui\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
