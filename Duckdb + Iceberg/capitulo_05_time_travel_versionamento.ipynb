{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f66ac6",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 05 - Time Travel e Versionamento\n",
    "\n",
    "## ‚è≥ Objetivo\n",
    "\n",
    "Uma das features mais poderosas do Apache Iceberg √© o **Time Travel** (viagem no tempo). Ele permite:\n",
    "1.  Consultar os dados como eram no passado (por timestamp ou snapshot ID).\n",
    "2.  Reverter a tabela para um estado anterior (Rollback).\n",
    "3.  Reproduzir experimentos ou corrigir cargas erradas de dados.\n",
    "\n",
    "Neste notebook, vamos:\n",
    "1.  Gerar novas vers√µes (snapshots) da tabela de vendas.\n",
    "2.  Consultar vers√µes antigas.\n",
    "3.  Praticar o Rollback.\n",
    "\n",
    "## üîß Requisitos\n",
    "\n",
    "- Tabela `default.sales` criada no Cap√≠tulo 03.\n",
    "- Biblioteca `pyiceberg` configurada.\n",
    "- DuckDB para an√°lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fadea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "import pyarrow as pa\n",
    "\n",
    "# Configura√ß√£o Visual\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Configura√ß√£o Paths\n",
    "WAREHOUSE_PATH = './iceberg_warehouse'\n",
    "CATALOG_DB = f\"{WAREHOUSE_PATH}/catalog.db\"\n",
    "\n",
    "# Inicializar Cat√°logo\n",
    "catalog = SqlCatalog(\n",
    "    \"local\",\n",
    "    **{\n",
    "        \"uri\": f\"sqlite:///{CATALOG_DB}\",\n",
    "        \"warehouse\": f\"file://{os.path.abspath(WAREHOUSE_PATH)}\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Setup inicial conclu√≠do\")\n",
    "print(f\"üìÇ Warehouse: {os.path.abspath(WAREHOUSE_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753e06b",
   "metadata": {},
   "source": [
    "## 1. Preparar Dados: Criando Hist√≥rico\n",
    "\n",
    "Para viajar no tempo, precisamos de um hist√≥rico. Vamos adicionar novos commits na tabela.\n",
    "\n",
    "1.  **Snapshot 1**: J√° criado no Cap 03 (Jan/Fev/Mar/Abr).\n",
    "2.  **Snapshot 2**: Vamos adicionar vendas de **Maio**.\n",
    "3.  **Snapshot 3**: Vamos adicionar vendas de **Junho** (com um erro proposital para corrigir depois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper para adicionar dados\n",
    "def append_sales_data(df_pandas, snapshot_name=\"Novo Snapshot\"):\n",
    "    try:\n",
    "        tbl = catalog.load_table(\"default.sales\")\n",
    "        \n",
    "        # Casting para compatibilidade (ns -> us)\n",
    "        if 'order_date' in df_pandas.columns:\n",
    "            df_pandas['order_date'] = df_pandas['order_date'].astype('datetime64[us]')\n",
    "            \n",
    "        arrow_table = pa.Table.from_pandas(df_pandas)\n",
    "        tbl.append(arrow_table)\n",
    "        print(f\"‚úÖ {snapshot_name}: {len(df_pandas)} linhas adicionadas.\")\n",
    "        print(f\"   Snapshot ID: {tbl.current_snapshot().snapshot_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao adicionar dados: {e}\")\n",
    "\n",
    "# Criar Batch: Maio 2024\n",
    "batch_may = pd.DataFrame({\n",
    "    'order_id': range(1000, 1020),\n",
    "    'customer_id': [f'CUST{i:03d}' for i in range(20)],\n",
    "    'product_id': ['PROD005'] * 20,\n",
    "    'order_date': pd.date_range('2024-05-01', periods=20, freq='1D'),\n",
    "    'quantity': [1] * 20,\n",
    "    'total_amount': [150] * 20\n",
    "})\n",
    "\n",
    "append_sales_data(batch_may, \"Snapshot 2 (Maio)\")\n",
    "\n",
    "# Aguardar um pouco para diferencial de timestamp\n",
    "time.sleep(1)\n",
    "\n",
    "# Criar Batch: Junho 2024 (COM ERRO: valores duplicados/errados)\n",
    "batch_june_error = pd.DataFrame({\n",
    "    'order_id': range(2000, 2010),\n",
    "    'customer_id': ['ERROR'] * 10,\n",
    "    'product_id': ['INVALID'] * 10,\n",
    "    'order_date': pd.date_range('2024-06-01', periods=10, freq='1D'),\n",
    "    'quantity': [999] * 10,\n",
    "    'total_amount': [999999] * 10\n",
    "})\n",
    "\n",
    "append_sales_data(batch_june_error, \"Snapshot 3 (Junho - Errado)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd059b",
   "metadata": {},
   "source": [
    "## 2. Inspecionar Hist√≥rico (Snapshots)\n",
    "\n",
    "Vamos visualizar a lista de snapshots dispon√≠veis usando a propriedade `metadata.snapshots` do PyIceberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = catalog.load_table(\"default.sales\")\n",
    "print(f\"Vers√£o Atual: {tbl.current_snapshot().snapshot_id}\")\n",
    "\n",
    "print(\"\\nüìú Hist√≥rico de Snapshots:\")\n",
    "history = []\n",
    "for s in tbl.metadata.snapshots:\n",
    "    ts = datetime.fromtimestamp(s.timestamp_ms / 1000)\n",
    "    history.append({\n",
    "        'snapshot_id': s.snapshot_id,\n",
    "        'timestamp': ts,\n",
    "        'operation': s.summary.get('operation', 'unknown'),\n",
    "        'records': s.summary.get('added-records', 0)\n",
    "    })\n",
    "\n",
    "df_history = pd.DataFrame(history)\n",
    "print(df_history)\n",
    "\n",
    "# Guardar IDs para uso posterior\n",
    "snap_ids = df_history['snapshot_id'].tolist()\n",
    "print(f\"\\nIDs capturados: {snap_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b6add",
   "metadata": {},
   "source": [
    "## 3. Time Travel: Consultando o Passado\n",
    "\n",
    "Com os IDs de snapshot, podemos consultar como a tabela estava antes da inser√ß√£o dos dados \"errados\" de Junho.\n",
    "\n",
    "DuckDB nativo suporta `FOR VERSION AS OF`, mas devido a peculiaridades de caminhos no Windows, usaremos a abordagem segura:\n",
    "`PyIceberg.scan(snapshot_id=...) -> Arrow -> DuckDB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51451d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_at_snapshot(snapshot_id, label):\n",
    "    print(f\"\\nüîç Consultando Snapshot: {snapshot_id} ({label})\")\n",
    "    try:\n",
    "        # Load table at specific snapshot\n",
    "        arrow_table = tbl.scan(snapshot_id=snapshot_id).to_arrow()\n",
    "        \n",
    "        # Analyze with DuckDB\n",
    "        con = duckdb.connect()\n",
    "        stats = con.execute(f\"\"\"\n",
    "            SELECT\n",
    "                count(*) as total_rows,\n",
    "                sum(total_amount) as total_revenue,\n",
    "                max(order_date) as last_order\n",
    "            FROM arrow_table\n",
    "        \"\"\").df()\n",
    "        \n",
    "        print(stats)\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {e}\")\n",
    "\n",
    "# √öltimo Snapshot (Com Erro)\n",
    "query_at_snapshot(snap_ids[-1], \"Atual - Com erro\")\n",
    "\n",
    "# Pen√∫ltimo Snapshot (Correto - Apenas Maio)\n",
    "query_at_snapshot(snap_ids[-2], \"Passado - Apenas Maio\")\n",
    "\n",
    "# Antepen√∫ltimo (Se houver - Apenas carga inicial)\n",
    "if len(snap_ids) >= 3:\n",
    "    query_at_snapshot(snap_ids[-3], \"Passado - Carga Inicial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0a2f2",
   "metadata": {},
   "source": [
    "## 4. Rollback (Revers√£o)\n",
    "\n",
    "Identificamos que o √∫ltimo snapshot contem dados errados (vendas de Junho com valores absurdos).\n",
    "Vamos usar a API de transa√ß√£o do PyIceberg para reverter a tabela para o estado anterior (Rollback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a080094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar ID seguro (pen√∫ltimo)\n",
    "safe_snapshot_id = snap_ids[-2]\n",
    "print(f\"üéØ Alvo de Restaura√ß√£o: {safe_snapshot_id}\")\n",
    "\n",
    "restore_branch = \"restored_v1\"\n",
    "\n",
    "print(f\"Criando branch '{restore_branch}'...\")\n",
    "try:\n",
    "    with tbl.manage_snapshots() as ms:\n",
    "        if restore_branch not in tbl.metadata.refs:\n",
    "             print(\"Argument order try: snapshot_id, name\")\n",
    "             # Tentativa invertida conforme erro do Pydantic sugeriu\n",
    "             ms.create_branch(safe_snapshot_id, restore_branch)\n",
    "        else:\n",
    "             print(f\"‚ÑπÔ∏è Branch {restore_branch} j√° existe\")\n",
    "             \n",
    "    print(f\"‚úÖ Branch check ok\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao gerenciar branch: {e}\")\n",
    "\n",
    "# Consultar dados usando a Branch\n",
    "print(f\"\\nVerificando dados da branch '{restore_branch}':\")\n",
    "try:\n",
    "    if restore_branch in tbl.metadata.refs:\n",
    "        ref = tbl.metadata.refs[restore_branch]\n",
    "        branch_snap_id = ref.snapshot_id\n",
    "        print(f\"Branch '{restore_branch}' aponta para Snapshot ID: {branch_snap_id}\")\n",
    "        query_at_snapshot(branch_snap_id, f\"Branch: {restore_branch}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Branch {restore_branch} n√£o encontrada refs\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Falha leitura branch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca51ce",
   "metadata": {},
   "source": [
    "## 5. Time Travel por Timestamp\n",
    "\n",
    "Al√©m de ID, podemos viajar para um momento espec√≠fico no tempo.\n",
    "Vamos usar o `timestamp_ms` registrado no hist√≥rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c007829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Travel via Timestamp (Manual Resolution)\n",
    "# Como PyIceberg scan() pode variar, a forma mais robusta √© resolver o ID via metadados\n",
    "\n",
    "target_time = df_history.iloc[0]['timestamp']\n",
    "print(f\"üïí Buscando snapshot ativo em: {target_time}\")\n",
    "\n",
    "# L√≥gica: Encontrar o snapshot mais recente que seja <= target_time\n",
    "# (No nosso caso, √© exato, mas em produ√ß√£o seria <=)\n",
    "snap_by_time = df_history[df_history['timestamp'] <= target_time].sort_values('timestamp', ascending=False).iloc[0]\n",
    "target_id = snap_by_time['snapshot_id']\n",
    "\n",
    "print(f\"üéØ ID Resolvido: {target_id}\")\n",
    "\n",
    "try:\n",
    "    # Scan usando o ID resolvido\n",
    "    query_at_snapshot(target_id, f\"Time Travel: {target_time}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro Time Travel: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536db5a9",
   "metadata": {},
   "source": [
    "## ‚úÖ Resumo\n",
    "\n",
    "Neste cap√≠tulo:\n",
    "1.  Geramos m√∫ltiplos Snapshots na tabela.\n",
    "2.  Consultamos vers√µes passadas (Time Travel) via ID.\n",
    "3.  Realizamos um Rollback para corrigir dados errados.\n",
    "4.  Aprendemos a usar timestamp para Time Travel.\n",
    "\n",
    "**Pr√≥ximo:** Cap√≠tulo 06 - Cat√°logos REST e Autentica√ß√£o (ou manipula√ß√£o avan√ßada de parti√ß√µes)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
