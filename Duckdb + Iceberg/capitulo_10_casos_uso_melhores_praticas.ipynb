{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592d94e0",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 10 - Casos de Uso e Melhores Pr√°ticas\n",
    "\n",
    "## üéì Conclus√£o do Curso\n",
    "\n",
    "Chegamos ao final da nossa jornada **DuckDB + Iceberg**.\n",
    "Come√ßamos configurando um ambiente local, aprendemos a ler e escrever dados, exploramos features avan√ßadas como **Time Travel** e **Schema Evolution**, e finalmente migramos para um ambiente de nuvem simulado com **MinIO**.\n",
    "\n",
    "Neste √∫ltimo cap√≠tulo, vamos resumir as **Melhores Pr√°ticas** e discutir **Arquitetura**.\n",
    "\n",
    "## üèÜ Melhores Pr√°ticas\n",
    "\n",
    "### 1. Particionamento (Hidden Partitioning)\n",
    "Evite particionar por colunas de alta cardinalidade (ex: `user_id`, `timestamp_preciso`).\n",
    "Prefira as transforma√ß√µes do Iceberg:\n",
    "*   `days(timestamp)`\n",
    "*   `months(timestamp)`\n",
    "*   `bucket(coluna, N)` -> √ìtimo para distribuir dados uniformemente.\n",
    "\n",
    "A grande vantagem do Iceberg √© que **voc√™ consulta a coluna original**, e ele descobre a parti√ß√£o sozinho (Hidden Partitioning).\n",
    "\n",
    "### 2. Manuten√ß√£o (Compaction & Cleaning)\n",
    "O Iceberg resolve o problema dos arquivos pequenos (\"small files problem\") gerados por streaming, mas cria um d√©bito de manuten√ß√£o.\n",
    "*   Agende jobs peri√≥dicos de `rewrite_data_files` (Compacta√ß√£o).\n",
    "*   Configure `expire_snapshots` para n√£o guardar hist√≥rico infinito (custo de storage).\n",
    "\n",
    "### 3. Catalog Choice\n",
    "Para produ√ß√£o em AWS: Use **AWS Glue Catalog**.\n",
    "Para produ√ß√£o Agn√≥stica/On-Premise: Use **REST Catalog** (Project Nessie, Gravitino ou Tabular).\n",
    "Evite usar FileSystem direto (Hadoop/S3FileIO sem cat√°logo robusto) em ambientes com concorr√™ncia massiva.\n",
    "\n",
    "## üèóÔ∏è Casos de Uso Comuns\n",
    "\n",
    "### CDC (Change Data Capture)\n",
    "Iceberg suporta `MERGE INTO`, permitindo aplicar upserts (inserts + updates + deletes) vindos de bancos transacionais (Postgres/MySQL) via Debezium/Kafka.\n",
    "Isso cria um **Lakehouse Transactional**.\n",
    "\n",
    "### LGPD / GDPR (Right to be Forgotten)\n",
    "Diferente de Data Lakes tradicionais (onde deletar um registro num arquivo CSV/Parquet exige reescrever o arquivo inteiro manualmente), o Iceberg permite deletar linhas espec√≠ficas.\n",
    "Com `expire_snapshots`, voc√™ garante que a vers√£o antiga com o dado sens√≠vel foi de fato eliminada fisicamente.\n",
    "\n",
    "## üèÅ Exemplo Final: Conectando Tudo\n",
    "\n",
    "Vamos fazer uma leitura final no nosso ambiente **S3 (MinIO)** para confirmar que nossa arquitetura \"Cloud\" est√° est√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c068658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiceberg\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suprimir avisos de SSL inseguro (comum em dev local)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o Cloud (Simulada)\n",
    "S3_ENDPOINT = \"http://localhost:9000\"\n",
    "S3_ACCESS_KEY = \"admin\"\n",
    "S3_SECRET_KEY = \"password\"\n",
    "BUCKET_NAME = \"warehouse\"\n",
    "\n",
    "# Conectando ao Cat√°logo S3 (criado no Cap 09)\n",
    "try:\n",
    "    catalog = SqlCatalog(\n",
    "        \"minio_catalog\",\n",
    "        **{\n",
    "            \"uri\": \"sqlite:///iceberg_warehouse/s3_catalog.db\",\n",
    "            \"warehouse\": f\"s3://{BUCKET_NAME}/iceberg\",\n",
    "            \"s3.endpoint\": S3_ENDPOINT,\n",
    "            \"s3.access-key-id\": S3_ACCESS_KEY,\n",
    "            \"s3.secret-access-key\": S3_SECRET_KEY,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Carregar tabela\n",
    "    tbl = catalog.load_table(\"s3_sales_db.cloud_sales\")\n",
    "    print(f\"‚úÖ Conex√£o estabelecida com sucesso!\")\n",
    "    print(f\"üìç Tabela: {tbl.location()}\")\n",
    "    print(f\"üî¢ Snapshots Atuais: {len(tbl.snapshots())}\")\n",
    "    \n",
    "    # Leitura Final\n",
    "    df = tbl.scan().to_pandas()\n",
    "    print(\"\\nüìä Dados no Lakehouse:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao conectar (Execute o Cap 09 primeiro): {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Parab√©ns! Voc√™ concluiu a trilha DuckDB + Iceberg.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
