{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb67d604",
   "metadata": {},
   "source": [
    "## 4. Padrão Recomendado\n",
    "\n",
    "**Processamento pesado:** Spark (TBs de dados)  \n",
    "**Analytics rápidas:** DuckDB (GBs a TBs)  \n",
    "**Transformações:** Polars (performance) ou Pandas (simplicidade)  \n",
    "**Interoperabilidade:** Arrow (zero-copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Delta → Arrow (zero-copy quando possível)\n",
    "arrow_table = con.execute(\"SELECT * FROM delta_scan('./sales_partitioned') LIMIT 1000\").arrow()\n",
    "\n",
    "print(f\"✓ Arrow Table:\")\n",
    "print(f\"  Schema: {arrow_table.schema}\")\n",
    "print(f\"  Rows: {arrow_table.num_rows:,}\")\n",
    "\n",
    "# Arrow → Parquet\n",
    "pq.write_table(arrow_table, 'output.parquet', compression='snappy')\n",
    "\n",
    "# Arrow → Pandas (zero-copy)\n",
    "df_pandas = arrow_table.to_pandas()\n",
    "print(f\"\\n✓ Convertido para Pandas: {len(df_pandas)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c53aecb",
   "metadata": {},
   "source": [
    "## 3. DuckDB + Arrow (Zero-Copy)\n",
    "\n",
    "Arrow permite transferência zero-copy entre sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43655928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Ler Delta → Polars\n",
    "df_polars = con.execute(\"SELECT * FROM delta_scan('./sales_partitioned') LIMIT 1000\").pl()\n",
    "\n",
    "# Processar com Polars (lazy)\n",
    "result = (\n",
    "    df_polars\n",
    "    .lazy()\n",
    "    .filter(pl.col('amount') > 100)\n",
    "    .with_columns([\n",
    "        (pl.col('amount') * 1.1).alias('amount_with_tax'),\n",
    "        pl.col('year').cast(pl.Int32)\n",
    "    ])\n",
    "    .group_by(['year', 'country'])\n",
    "    .agg([\n",
    "        pl.col('amount').sum().alias('total_amount'),\n",
    "        pl.col('order_id').count().alias('order_count')\n",
    "    ])\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"✓ Polars lazy execution:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e77f7",
   "metadata": {},
   "source": [
    "## 2. DuckDB + Polars\n",
    "\n",
    "Polars oferece performance superior para transformações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from deltalake import write_deltalake\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Ler Delta → Pandas\n",
    "df = con.execute(\"SELECT * FROM delta_scan('./sales_partitioned') LIMIT 1000\").df()\n",
    "print(f\"✓ Loaded {len(df)} rows to Pandas\")\n",
    "print(df.head())\n",
    "\n",
    "# Processar com Pandas\n",
    "df['amount_with_tax'] = df['amount'] * 1.1\n",
    "aggregated = df.groupby('country')['amount'].sum().reset_index()\n",
    "\n",
    "# Escrever Pandas → Delta\n",
    "write_deltalake(\"./processed_sales\", aggregated, mode=\"overwrite\")\n",
    "print(\"\\n✓ Pipeline Pandas completo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5dc73",
   "metadata": {},
   "source": [
    "## 1. DuckDB + Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação\n",
    "%pip install duckdb deltalake pyarrow pandas polars -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d58653",
   "metadata": {},
   "source": [
    "# Capítulo 09: Integração Python e Spark\n",
    "\n",
    "Integrar DuckDB com Pandas, Polars, Arrow e PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 09 Integracao Python Spark\n",
    "\n",
    "Notebook gerado automaticamente a partir do código fonte python.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
