{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1821dd84",
   "metadata": {},
   "source": [
    "## 6. Dicas de Performance\n",
    "\n",
    "**✓ Sempre:**\n",
    "- Use filtros específicos (WHERE)\n",
    "- Selecione apenas colunas necessárias\n",
    "- Habilite profiling para análise\n",
    "- Configure row group size adequado\n",
    "- Use compression apropriada (SNAPPY para queries, ZSTD para storage)\n",
    "\n",
    "**✗ Evite:**\n",
    "- SELECT * em tabelas grandes\n",
    "- Queries sem filtros em produção\n",
    "- Row groups muito pequenos (< 1MB) ou grandes (> 1GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43571cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class QueryMetrics:\n",
    "    query: str\n",
    "    execution_time: float\n",
    "    rows_processed: int\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor de performance para queries\"\"\"\n",
    "    \n",
    "    def __init__(self, con: duckdb.DuckDBPyConnection):\n",
    "        self.con = con\n",
    "        self.metrics: List[QueryMetrics] = []\n",
    "    \n",
    "    def execute_and_measure(self, query: str) -> QueryMetrics:\n",
    "        \"\"\"Executar query e coletar métricas\"\"\"\n",
    "        self.con.execute(\"SET enable_profiling=true\")\n",
    "        \n",
    "        start = time.time()\n",
    "        result = self.con.execute(query).fetchdf()\n",
    "        execution_time = time.time() - start\n",
    "        \n",
    "        metrics = QueryMetrics(\n",
    "            query=query[:80],\n",
    "            execution_time=execution_time,\n",
    "            rows_processed=len(result)\n",
    "        )\n",
    "        \n",
    "        self.metrics.append(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Imprimir resumo\"\"\"\n",
    "        print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
    "        total_time = sum(m.execution_time for m in self.metrics)\n",
    "        print(f\"Total queries: {len(self.metrics)}\")\n",
    "        print(f\"Total time: {total_time:.2f}s\")\n",
    "        print(f\"Average time: {total_time/len(self.metrics):.2f}s\")\n",
    "        \n",
    "        print(\"\\n=== SLOWEST QUERIES ===\")\n",
    "        sorted_metrics = sorted(\n",
    "            self.metrics,\n",
    "            key=lambda m: m.execution_time,\n",
    "            reverse=True\n",
    "        )[:3]\n",
    "        \n",
    "        for i, m in enumerate(sorted_metrics, 1):\n",
    "            print(f\"{i}. {m.execution_time:.2f}s - {m.query}...\")\n",
    "\n",
    "# Exemplo de uso\n",
    "con = duckdb.connect()\n",
    "monitor = PerformanceMonitor(con)\n",
    "\n",
    "queries = [\n",
    "    \"SELECT COUNT(*) FROM sample\",\n",
    "    \"SELECT region, COUNT(*) FROM sample GROUP BY region\",\n",
    "    \"SELECT * FROM sample WHERE date = '2024-01-15'\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    metrics = monitor.execute_and_measure(query)\n",
    "    print(f\"✓ Query: {metrics.execution_time:.3f}s\")\n",
    "\n",
    "monitor.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f6f90",
   "metadata": {},
   "source": [
    "## 5. Monitor de Performance Completo\n",
    "\n",
    "Classe para monitorar e analisar performance de queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60950159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "# Benchmark: queries repetidas em dados in-memory\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    con.execute(\"SELECT region, COUNT(*) FROM sample GROUP BY region\").fetchall()\n",
    "time_native = time.time() - start\n",
    "\n",
    "print(f\"DuckDB nativo: {time_native:.3f}s (10 queries)\")\n",
    "print(\"\\n✓ Para queries intensivas, considere carregar dados para DuckDB nativo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae00e6",
   "metadata": {},
   "source": [
    "## 4. Comparação: Delta vs DuckDB Nativo\n",
    "\n",
    "Delta Lake tem overhead adicional - para queries intensivas, carregar para DuckDB nativo pode ser mais rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Criar dados exemplo\n",
    "df = pd.DataFrame({\n",
    "    'id': range(10000),\n",
    "    'value': ['data-' + str(i) for i in range(10000)]\n",
    "})\n",
    "\n",
    "# Configurar escrita otimizada\n",
    "table = pa.Table.from_pandas(df)\n",
    "\n",
    "# Escrever com SNAPPY (rápido para queries frequentes)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    './optimized_snappy.parquet',\n",
    "    compression='snappy',\n",
    "    row_group_size=10000  # Ajustar conforme necessidade\n",
    ")\n",
    "\n",
    "# Escrever com ZSTD (melhor compressão)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    './optimized_zstd.parquet',\n",
    "    compression='zstd',\n",
    "    compression_level=3,\n",
    "    row_group_size=10000\n",
    ")\n",
    "\n",
    "print(\"✓ Arquivos otimizados criados\")\n",
    "print(\"  - SNAPPY: queries rápidas\")\n",
    "print(\"  - ZSTD: armazenamento eficiente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172a4f4",
   "metadata": {},
   "source": [
    "## 3. Row Group Size e Compression\n",
    "\n",
    "Configurar tamanho de row groups e compressão para otimizar performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Teste 1: SELECT *\n",
    "start = time.time()\n",
    "df1 = con.execute(\"SELECT * FROM sample LIMIT 10000\").df()\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Teste 2: Projeção específica\n",
    "start = time.time()\n",
    "df2 = con.execute(\"SELECT id, region, amount FROM sample LIMIT 10000\").df()\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(f\"SELECT *           : {time1:.3f}s\")\n",
    "print(f\"Projeção específica: {time2:.3f}s\")\n",
    "print(f\"\\n✓ Speedup: {time1/time2:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef527d4e",
   "metadata": {},
   "source": [
    "## 2. Projection Pushdown\n",
    "\n",
    "Selecionar apenas colunas necessárias reduz I/O drasticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Criar tabela exemplo\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE sample AS\n",
    "    SELECT \n",
    "        i as id,\n",
    "        'Region-' || (i % 5) as region,\n",
    "        DATE '2024-01-01' + (i % 365) * INTERVAL '1 day' as date,\n",
    "        random() * 1000 as amount\n",
    "    FROM range(100000) t(i)\n",
    "\"\"\")\n",
    "\n",
    "# Habilitar profiling\n",
    "con.execute(\"SET enable_profiling=true\")\n",
    "con.execute(\"SET profiling_mode='detailed'\")\n",
    "\n",
    "# Query com filter pushdown\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT COUNT(*), SUM(amount)\n",
    "    FROM sample\n",
    "    WHERE date = '2024-01-15' AND region = 'Region-2'\n",
    "\"\"\").fetchone()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Resultado: {result}\")\n",
    "print(f\"Tempo: {elapsed:.3f}s\")\n",
    "print(\"\\n✓ Filtros aplicados antes da leitura completa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83310a2",
   "metadata": {},
   "source": [
    "## 1. Filter Pushdown\n",
    "\n",
    "DuckDB automaticamente empurra filtros para o Delta Lake, reduzindo dados lidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b32ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de dependências\n",
    "%pip install duckdb deltalake pyarrow pandas -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cff41",
   "metadata": {},
   "source": [
    "# Capítulo 07: Otimizações e Performance\n",
    "\n",
    "Técnicas para maximizar performance em queries Delta Lake com DuckDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 07 Otimizacoes Performance\n",
    "\n",
    "Notebook gerado automaticamente a partir do código fonte python.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
