{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 07 Otimizacoes Performance\n",
    "\n",
    "Notebook gerado automaticamente a partir do código fonte python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "capitulo_07_otimizacoes_performance\n",
    "\"\"\"\n",
    "\n",
    "# capitulo_07_otimizacoes_performance\n",
    "import duckdb\n",
    "import os\n",
    "\n",
    "# Exemplo/Bloco 1\n",
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Habilitar profiling para ver otimizações\n",
    "con.execute(\"SET enable_profiling=true\")\n",
    "con.execute(\"SET profiling_mode='detailed'\")\n",
    "\n",
    "# Query com filter pushdown\n",
    "start = time.time()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT COUNT(*), SUM(amount)\n",
    "    FROM delta_scan('./large_delta_table')\n",
    "    WHERE date = '2024-01-15'\n",
    "        AND region = 'US'\n",
    "\"\"\").fetchone()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Results: {result}\")\n",
    "print(f\"Time: {elapsed:.2f}s\")\n",
    "\n",
    "# Ver profile da query\n",
    "profile = con.execute(\"PRAGMA last_profiling_output\").fetchone()[0]\n",
    "print(profile)\n",
    "\n",
    "# Exemplo/Bloco 2\n",
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Teste 1: SELECT *\n",
    "start = time.time()\n",
    "df1 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM delta_scan('./sales')\n",
    "    LIMIT 100000\n",
    "\"\"\").df()\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Teste 2: Projeção específica\n",
    "start = time.time()\n",
    "df2 = con.execute(\"\"\"\n",
    "    SELECT customer_id, date, amount\n",
    "    FROM delta_scan('./sales')\n",
    "    LIMIT 100000\n",
    "\"\"\").df()\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(f\"SELECT * : {time1:.2f}s\")\n",
    "print(f\"Projection: {time2:.2f}s\")\n",
    "print(f\"Speedup: {time1/time2:.2f}x\")\n",
    "\n",
    "# Exemplo/Bloco 3\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Analisar metadata Parquet da tabela Delta\n",
    "metadata = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM parquet_metadata('./my_delta_table/part-00000.parquet')\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Row Groups:\")\n",
    "print(metadata[['row_group_id', 'num_rows', 'total_compressed_size']])\n",
    "\n",
    "# Exemplo/Bloco 4\n",
    "from deltalake import write_deltalake\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Criar DataFrame grande\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        i as id,\n",
    "        'value-' || i as data\n",
    "    FROM range(0, 10000000) tbl(i)\n",
    "\"\"\").df()\n",
    "\n",
    "# Escrever com row group size otimizado\n",
    "write_deltalake(\n",
    "    \"./optimized_table\",\n",
    "    df,\n",
    "    # pandas chunksize controla row group size\n",
    "    engine='pyarrow',\n",
    "    # Ajustar via PyArrow\n",
    ")\n",
    "\n",
    "# Exemplo/Bloco 5\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Ver compression codec usado\n",
    "metadata = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        column_name,\n",
    "        codec,\n",
    "        total_compressed_size,\n",
    "        total_uncompressed_size,\n",
    "        (total_uncompressed_size::FLOAT / total_compressed_size) as compression_ratio\n",
    "    FROM parquet_metadata('./my_delta_table/part-00000.parquet')\n",
    "\"\"\").df()\n",
    "\n",
    "print(metadata)\n",
    "\n",
    "# Exemplo/Bloco 6\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from deltalake import write_deltalake\n",
    "\n",
    "# Para escrita rápida e queries frequentes: SNAPPY\n",
    "write_deltalake(\n",
    "    \"./fast_table\",\n",
    "    df,\n",
    "    mode=\"overwrite\"\n",
    ")  # Snappy é padrão\n",
    "\n",
    "# Para armazenamento eficiente: ZSTD\n",
    "# (Requer configuração via PyArrow)\n",
    "table = pa.Table.from_pandas(df)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    \"./compressed_table/data.parquet\",\n",
    "    compression='zstd',\n",
    "    compression_level=3\n",
    ")\n",
    "\n",
    "# Exemplo/Bloco 7\n",
    "import duckdb\n",
    "import time\n",
    "\n",
    "con = duckdb.connect('benchmark.db')\n",
    "\n",
    "# Teste 1: Query em Delta\n",
    "start = time.time()\n",
    "result1 = con.execute(\"\"\"\n",
    "    SELECT region, COUNT(*), SUM(amount)\n",
    "    FROM delta_scan('./sales')\n",
    "    GROUP BY region\n",
    "\"\"\").fetchdf()\n",
    "delta_time = time.time() - start\n",
    "\n",
    "# Carregar para DuckDB\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE sales_local AS\n",
    "    SELECT * FROM delta_scan('./sales')\n",
    "\"\"\")\n",
    "\n",
    "# Teste 2: Query em DuckDB native\n",
    "start = time.time()\n",
    "result2 = con.execute(\"\"\"\n",
    "    SELECT region, COUNT(*), SUM(amount)\n",
    "    FROM sales_local\n",
    "    GROUP BY region\n",
    "\"\"\").fetchdf()\n",
    "native_time = time.time() - start\n",
    "\n",
    "print(f\"Delta scan: {delta_time:.2f}s\")\n",
    "print(f\"DuckDB native: {native_time:.2f}s\")\n",
    "print(f\"Speedup: {delta_time/native_time:.2f}x\")\n",
    "\n",
    "# Exemplo/Bloco 8\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"SET enable_profiling=true\")\n",
    "con.execute(\"SET profiling_mode='detailed'\")\n",
    "\n",
    "# Executar query\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT region, COUNT(*)\n",
    "    FROM delta_scan('./sales')\n",
    "    WHERE date = '2024-01-15'\n",
    "    GROUP BY region\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Ver profile detalhado\n",
    "profile = con.execute(\"PRAGMA last_profiling_output\").fetchone()[0]\n",
    "\n",
    "# Parsear profile\n",
    "print(\"=== QUERY PROFILE ===\")\n",
    "print(profile)\n",
    "\n",
    "# Métricas importantes:\n",
    "# - Rows scanned\n",
    "# - Files read\n",
    "# - Execution time por operador\n",
    "# - Memory usage\n",
    "\n",
    "# Exemplo/Bloco 9\n",
    "import duckdb\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "def has_module(name):\n",
    "    return importlib.util.find_spec(name) is not None\n",
    "\n",
    "def safe_install_ext(con, ext_name):\n",
    "    try:\n",
    "        con.execute(f\"INSTALL {ext_name}\")\n",
    "        con.execute(f\"LOAD {ext_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to install/load {ext_name} extension: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class QueryMetrics:\n",
    "    query: str\n",
    "    execution_time: float\n",
    "    rows_processed: int\n",
    "    memory_used: int\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor de performance para queries Delta\"\"\"\n",
    "\n",
    "    def __init__(self, con: duckdb.DuckDBPyConnection):\n",
    "        self.con = con\n",
    "        self.metrics: List[QueryMetrics] = []\n",
    "\n",
    "    def execute_and_measure(self, query: str) -> QueryMetrics:\n",
    "        \"\"\"Executar query e coletar métricas\"\"\"\n",
    "\n",
    "        # Habilitar profiling\n",
    "        self.con.execute(\"SET enable_profiling=true\")\n",
    "\n",
    "        # Executar query\n",
    "        start = time.time()\n",
    "        result = self.con.execute(query).fetchdf()\n",
    "        execution_time = time.time() - start\n",
    "\n",
    "        # Coletar métricas\n",
    "        rows = len(result)\n",
    "\n",
    "        metrics = QueryMetrics(\n",
    "            query=query[:100],  # Primeiros 100 chars\n",
    "            execution_time=execution_time,\n",
    "            rows_processed=rows,\n",
    "            memory_used=0  # Implementar se necessário\n",
    "        )\n",
    "\n",
    "        self.metrics.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Imprimir resumo de performance\"\"\"\n",
    "        print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
    "        total_time = sum(m.execution_time for m in self.metrics)\n",
    "        print(f\"Total queries: {len(self.metrics)}\")\n",
    "        print(f\"Total time: {total_time:.2f}s\")\n",
    "        print(f\"Average time: {total_time/len(self.metrics):.2f}s\")\n",
    "\n",
    "        print(\"\\n=== SLOWEST QUERIES ===\")\n",
    "        sorted_metrics = sorted(\n",
    "            self.metrics,\n",
    "            key=lambda m: m.execution_time,\n",
    "            reverse=True\n",
    "        )[:5]\n",
    "\n",
    "        for i, m in enumerate(sorted_metrics, 1):\n",
    "            print(f\"{i}. {m.execution_time:.2f}s - {m.query}...\")\n",
    "\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    con = duckdb.connect()\n",
    "    monitor = PerformanceMonitor(con)\n",
    "\n",
    "    # Executar queries com monitoramento\n",
    "    queries = [\n",
    "        \"SELECT COUNT(*) FROM delta_scan('./sales')\",\n",
    "        \"SELECT region, COUNT(*) FROM delta_scan('./sales') GROUP BY region\",\n",
    "        \"SELECT * FROM delta_scan('./sales') WHERE date = '2024-01-15'\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        metrics = monitor.execute_and_measure(query)\n",
    "        print(f\"✓ Query completed in {metrics.execution_time:.2f}s\")\n",
    "\n",
    "    monitor.print_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}