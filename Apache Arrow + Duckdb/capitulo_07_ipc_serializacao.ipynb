{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6fc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow duckdb pandas numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b1cf1",
   "metadata": {},
   "source": [
    "# üì¶ Instala√ß√£o de Pacotes\n",
    "\n",
    "Antes de come√ßar, vamos instalar os pacotes necess√°rios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 07 Ipc Serializacao\n",
    "\n",
    "Notebook gerado automaticamente a partir do c√≥digo fonte python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9691f83",
   "metadata": {},
   "source": [
    "## üìö Importa√ß√£o de Bibliotecas\n",
    "\n",
    "Importando as bibliotecas necess√°rias para o cap√≠tulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Bibliotecas carregadas!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cc1b7",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o Inicial\n",
    "\n",
    "Preparando dados de exemplo e conex√£o com DuckDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo globais\n",
    "try:\n",
    "    print(\"\\nGerando dados de exemplo...\")\n",
    "    # Aumentando para 100k para ver diferen√ßa na compress√£o\n",
    "    data = pa.table({\n",
    "        'id': range(100_000),\n",
    "        'valor': np.random.randn(100_000),\n",
    "        'categoria': np.random.choice(['A', 'B', 'C', 'D', 'E'], 100_000)\n",
    "    })\n",
    "    print(f\"Tabela PyArrow criada: {data.num_rows} linhas\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar dados: {e}\")\n",
    "\n",
    "# Conex√£o DuckDB\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ed7b9",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ IPC Format\n",
    "\n",
    "Inter-Process Communication Format do Apache Arrow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- {'IPC Format'.upper()} ---\")\n",
    "\n",
    "# 7.1.1 Introdu√ß√£o ao IPC (Inter-Process Communication)\n",
    "# O formato IPC √© uma representa√ß√£o bin√°ria de Record Batches\n",
    "# Ele pode ser escrito em streams (soquetes) ou arquivos.\n",
    "\n",
    "# 7.1.2 Escrevendo em um stream IPCInMemory\n",
    "sink = pa.BufferOutputStream()\n",
    "with pa.ipc.new_stream(sink, data.schema) as writer:\n",
    "    # Escrever os batches da nossa tabela\n",
    "    for batch in data.to_batches():\n",
    "        writer.write_batch(batch)\n",
    "\n",
    "buffer = sink.getvalue()\n",
    "print(f\"Stream IPC criado na mem√≥ria.\")\n",
    "print(f\"  Tamanho do buffer: {buffer.size / 1024:.2f} KB\")\n",
    "\n",
    "# 7.1.3 Lendo a partir de um stream IPC\n",
    "stream_reader = pa.ipc.open_stream(buffer)\n",
    "recovered_table = stream_reader.read_all()\n",
    "\n",
    "print(f\"\\nTabela recuperada do stream IPC:\")\n",
    "print(f\"  Linhas: {recovered_table.num_rows}\")\n",
    "print(f\"  Schema: {recovered_table.schema.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da73bd7",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Feather Format\n",
    "\n",
    "Formato Feather para armazenamento eficiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- {'Feather format'.upper()} ---\")\n",
    "\n",
    "# 7.2.1 O que √© o Feather?\n",
    "# Feather (V2) √© basicamente o formato IPC do Arrow persistido em disco.\n",
    "# √â extremamente r√°pido porque √© id√™ntico ao layout na RAM.\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "# 7.2.2 Escrevendo arquivo Feather\n",
    "file_path = \"dados_cap7.feather\"\n",
    "feather.write_feather(data, file_path)\n",
    "print(f\"Arquivo Feather salvo: {file_path}\")\n",
    "\n",
    "# 7.2.3 Lendo arquivo Feather\n",
    "# Podemos ler como Table ou como Pandas\n",
    "table_feather = feather.read_table(file_path)\n",
    "print(f\"Leitura bem-sucedida (Table): {table_feather.num_rows} linhas\")\n",
    "\n",
    "# Limpeza\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(\"Arquivo tempor√°rio removido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f10ab",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Serializa√ß√£o para Disco\n",
    "\n",
    "Salvando e carregando dados do disco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79339f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- {'Serializa√ß√£o para disco'.upper()} ---\")\n",
    "\n",
    "# 7.3.1 Serializa√ß√£o Gen√©rica\n",
    "# M√©todos antigos como array.serialize() foram removidos.\n",
    "# A recomenda√ß√£o atual √© usar o formato IPC mesmo para componentes individuais.\n",
    "\n",
    "# Serializando um Array (via RecordBatch)\n",
    "array = pa.array([10, 20, 30, 40])\n",
    "batch = pa.RecordBatch.from_arrays([array], names=['v'])\n",
    "\n",
    "sink = pa.BufferOutputStream()\n",
    "with pa.ipc.new_stream(sink, batch.schema) as writer:\n",
    "    writer.write_batch(batch)\n",
    "\n",
    "buffer_array = sink.getvalue()\n",
    "print(f\"Array serializado para buffer IPC: {buffer_array.size} bytes\")\n",
    "\n",
    "# 7.3.2 Exemplo usando LocalFileSystem\n",
    "from pyarrow import fs\n",
    "local = fs.LocalFileSystem()\n",
    "\n",
    "with local.open_output_stream(\"raw_batches.arrow\") as stream:\n",
    "    with pa.ipc.new_file(stream, data.schema) as writer:\n",
    "        writer.write_table(data)\n",
    "\n",
    "info = local.get_file_info(\"raw_batches.arrow\")\n",
    "print(f\"Arquivo IPC (file format) criado: {info.size / 1024:.2f} KB\")\n",
    "\n",
    "# Limpeza\n",
    "if os.path.exists(\"raw_batches.arrow\"):\n",
    "    os.remove(\"raw_batches.arrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50664b8c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Shared Memory\n",
    "\n",
    "Compartilhamento de dados em mem√≥ria compartilhada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- {'Shared memory'.upper()} ---\")\n",
    "\n",
    "# 7.4.1 Mapas de Mem√≥ria (Memory-Mapped Files)\n",
    "# Permite que m√∫ltiplos processos acessem o mesmo arquivo como se estivesse na RAM,\n",
    "# sem copiar os dados para o espa√ßo de endere√ßamento de cada processo.\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "# 1. Criar um arquivo Feather formatado\n",
    "feather.write_feather(data, \"shared_data.feather\")\n",
    "\n",
    "# 2. Abrir usando memory map (mmap)\n",
    "# mmap=True √© o padr√£o no read_table para feather, mas vamos explicitar\n",
    "mmap_table = feather.read_table(\"shared_data.feather\", memory_map=True)\n",
    "\n",
    "print(\"Tabela mapeada em mem√≥ria (Shared Memory Simulation):\")\n",
    "print(f\"  Refer√™ncia de mem√≥ria: {mmap_table[0].chunk(0).buffers()[1]}\")\n",
    "print(\"Os dados permanecem no disco/cache do SO e s√£o acessados sob demanda.\")\n",
    "\n",
    "# Limpeza\n",
    "os.remove(\"shared_data.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bf8d2",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Compress√£o\n",
    "\n",
    "T√©cnicas de compress√£o de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f06f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- {'Compress√£o'.upper()} ---\")\n",
    "\n",
    "# 7.5.1 Algoritmos de Compress√£o Suportados\n",
    "# Arrow suporta LZ4 e ZSTD nativamente no formato IPC/Feather.\n",
    "\n",
    "def benchmark_compression(compression):\n",
    "    sink = pa.BufferOutputStream()\n",
    "    options = pa.ipc.IpcWriteOptions(compression=compression)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    with pa.ipc.new_file(sink, data.schema, options=options) as writer:\n",
    "        writer.write_table(data)\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    buf = sink.getvalue()\n",
    "    return buf.size, end - start\n",
    "\n",
    "# Comparando\n",
    "print(\"Comparativo de Compress√£o (IPC File):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for comp in [None, 'lz4', 'zstd']:\n",
    "    size, duration = benchmark_compression(comp)\n",
    "    name = comp if comp else \"Sem compress√£o\"\n",
    "    print(f\"{name:15}: {size/1024:>9.2f} KB | Tempo: {duration*1000:7.4f}ms\")\n",
    "\n",
    "# Nota: LZ4 geralmente √© mais r√°pido, ZSTD comprime mais (dependendo dos dados)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
