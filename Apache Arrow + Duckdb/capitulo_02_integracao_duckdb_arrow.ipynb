{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capítulo 02: Integração DuckDB + Arrow\n",
    "**Curso:** Apache Arrow + DuckDB\n",
    "\n",
    "### Tópicos abordados:\n",
    "- Modos de integração\n",
    "- Conversões bidirecionais\n",
    "- Query em Arrow Tables\n",
    "- Schemas e metadados\n",
    "- Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b629b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependências necessárias:\n",
      "pip install pyarrow duckdb pandas numpy\n",
      "============================================================\n",
      "CAPÍTULO 02: INTEGRAÇÃO DUCKDB + ARROW\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Configuração inicial e imports\n",
    "Nota: UTF-8 é configurado automaticamente em notebooks Jupyter\n",
    "\"\"\"\n",
    "\n",
    "import pyarrow as pa\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Instalar dependências\n",
    "print(\"Dependências necessárias:\")\n",
    "print(\"pip install pyarrow duckdb pandas numpy\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"CAPÍTULO 02: INTEGRAÇÃO DUCKDB + ARROW\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd76d7d",
   "metadata": {},
   "source": [
    "### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb0579ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gerando dados de exemplo...\n",
      "Tabela PyArrow criada: 1000 linhas\n"
     ]
    }
   ],
   "source": [
    "# Dados de exemplo globais\n",
    "try:\n",
    "    print(\"\\nGerando dados de exemplo...\")\n",
    "    data = pa.table({\n",
    "        'id': range(1000),\n",
    "        'valor': np.random.randn(1000),\n",
    "        'categoria': np.random.choice(['A', 'B', 'C'], 1000)\n",
    "    })\n",
    "    print(f\"Tabela PyArrow criada: {data.num_rows} linhas\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar dados: {e}\")\n",
    "\n",
    "# Conexão DuckDB\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12863693",
   "metadata": {},
   "source": [
    "### Tópico 1: Modos de integração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf95d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MODOS DE INTEGRAÇÃO ---\n",
      "\n",
      "1. Query Direto em Arrow Tables:\n",
      "----------------------------------------\n",
      "Resultado como Arrow:\n",
      "pyarrow.Table\n",
      "country: string\n",
      "total: decimal128(38, 0)\n",
      "----\n",
      "country: [[\"USA\",\"UK\",\"Canada\"]]\n",
      "total: [[25,17,8]]\n",
      "\n",
      "2. Registrar Arrow Tables:\n",
      "----------------------------------------\n",
      "  product_name  quantity   price    total\n",
      "0       Laptop         1  999.99   999.99\n",
      "1        Mouse         5   29.99   149.95\n",
      "2     Keyboard         3   79.99   239.97\n",
      "3       Laptop         2  999.99  1999.98\n",
      "\n",
      "3. Arrow Views (Sem Cópia - Zero-Copy):\n",
      "----------------------------------------\n",
      "Count: 33,333\n",
      "Average: 124,999.50\n",
      "Min: 100,000.50\n",
      "Max: 149,998.50\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- {'Modos de integração'.upper()} ---\")\n",
    "\n",
    "# 2.1.1 Query Direto em Arrow Tables\n",
    "print(\"\\n1. Query Direto em Arrow Tables:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar Arrow table\n",
    "customers = pa.table({\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Carol', 'David', 'Eve'],\n",
    "    'country': ['USA', 'UK', 'USA', 'Canada', 'UK'],\n",
    "    'total_orders': [10, 5, 15, 8, 12]\n",
    "})\n",
    "\n",
    "# Método 1: Query direta (variável em escopo)\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT country, sum(total_orders) as total\n",
    "    FROM customers\n",
    "    GROUP BY country\n",
    "    ORDER BY total DESC\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"Resultado como Arrow:\")\n",
    "print(result)\n",
    "\n",
    "# 2.1.2 Registrar Arrow Tables\n",
    "print(\"\\n2. Registrar Arrow Tables:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar múltiplas Arrow tables\n",
    "products = pa.table({\n",
    "    'product_id': [101, 102, 103],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard'],\n",
    "    'price': [999.99, 29.99, 79.99]\n",
    "})\n",
    "\n",
    "orders = pa.table({\n",
    "    'order_id': [1, 2, 3, 4],\n",
    "    'product_id': [101, 102, 101, 103],\n",
    "    'quantity': [2, 5, 1, 3]\n",
    "})\n",
    "\n",
    "# Registrar explicitamente\n",
    "con.register('products_table', products)\n",
    "con.register('orders_table', orders)\n",
    "\n",
    "# Fazer JOIN entre tables\n",
    "result_join = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        p.product_name,\n",
    "        o.quantity,\n",
    "        p.price,\n",
    "        o.quantity * p.price as total\n",
    "    FROM orders_table o\n",
    "    JOIN products_table p ON o.product_id = p.product_id\n",
    "\"\"\").df()\n",
    "\n",
    "print(result_join)\n",
    "\n",
    "# 2.1.3 Arrow Views (Sem Cópia)\n",
    "print(\"\\n3. Arrow Views (Sem Cópia - Zero-Copy):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar Arrow table grande\n",
    "large_table = pa.table({\n",
    "    'id': range(100_000),\n",
    "    'value': [i * 1.5 for i in range(100_000)]\n",
    "})\n",
    "\n",
    "# DuckDB cria uma VIEW sobre os dados Arrow - Não há cópia!\n",
    "con.execute(\"CREATE OR REPLACE VIEW arrow_view AS SELECT * FROM large_table\")\n",
    "\n",
    "# Query na view\n",
    "result_view = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        count(*) as count,\n",
    "        avg(value) as avg_value,\n",
    "        min(value) as min_value,\n",
    "        max(value) as max_value\n",
    "    FROM arrow_view\n",
    "    WHERE value > 100000\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Count: {result_view[0]:,}\")\n",
    "print(f\"Average: {result_view[1]:,.2f}\")\n",
    "print(f\"Min: {result_view[2]:,.2f}\")\n",
    "print(f\"Max: {result_view[3]:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed3275",
   "metadata": {},
   "source": [
    "### Tópico 2: Conversões bidirecionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754bcc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CONVERSÕES BIDIRECIONAIS ---\n",
      "\n",
      "1. Retornar como Arrow Table (.arrow()):\n",
      "----------------------------------------\n",
      "Tipo: <class 'pyarrow.lib.Table'>\n",
      "pyarrow.Table\n",
      "product: string\n",
      "sales: int64\n",
      "----\n",
      "product: [[\"D\",\"B\",\"C\"]]\n",
      "sales: [[300,200,150]]\n",
      "\n",
      "Produtos: ['D', 'B', 'C']\n",
      "Vendas: [300, 200, 150]\n",
      "\n",
      "2. Retornar como Pandas DataFrame (.df()):\n",
      "----------------------------------------\n",
      "Tipo: <class 'pandas.core.frame.DataFrame'>\n",
      "         date  revenue\n",
      "0  2024-01-02     1500\n",
      "1  2024-01-03     1200\n",
      "2  2024-01-01     1000\n",
      "\n",
      "Soma total: $3,700\n",
      "\n",
      "3. Retornar como Python nativo (.fetchall(), .fetchone()):\n",
      "----------------------------------------\n",
      "Todas as linhas: [('Electronics', 50), ('Clothing', 30), ('Food', 100)]\n",
      "Uma linha: ('Electronics', 50)\n",
      "Primeiras 2 linhas: [('Electronics', 50), ('Clothing', 30)]\n",
      "\n",
      "4. Trabalhando com Record Batches:\n",
      "----------------------------------------\n",
      "Table criada de batches:\n",
      "pyarrow.Table\n",
      "id: int64\n",
      "category: string\n",
      "----\n",
      "id: [[1,2,3],[4,5,6]]\n",
      "category: [[\"A\",\"B\",\"C\"],[\"D\",\"E\",\"F\"]]\n",
      "\n",
      "Resultado:\n",
      "pyarrow.Table\n",
      "id: int64\n",
      "category: string\n",
      "----\n",
      "id: [[1,2,3,4,5,6]]\n",
      "category: [[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- {'Conversões bidirecionais'.upper()} ---\")\n",
    "\n",
    "# 2.2.1 .arrow() - Retornar como Arrow Table\n",
    "print(\"\\n1. Retornar como Arrow Table (.arrow()):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data_sales = pa.table({\n",
    "    'product': ['A', 'B', 'C', 'D'],\n",
    "    'sales': [100, 200, 150, 300]\n",
    "})\n",
    "\n",
    "# Retornar como Arrow table\n",
    "result_arrow = con.execute(\"\"\"\n",
    "    SELECT product, sales\n",
    "    FROM data_sales\n",
    "    WHERE sales > 100\n",
    "    ORDER BY sales DESC\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(f\"Tipo: {type(result_arrow)}\")\n",
    "print(result_arrow)\n",
    "\n",
    "# Acessar colunas Arrow\n",
    "print(f\"\\nProdutos: {result_arrow['product'].to_pylist()}\")\n",
    "print(f\"Vendas: {result_arrow['sales'].to_pylist()}\")\n",
    "\n",
    "# 2.2.2 .df() - Retornar como Pandas\n",
    "print(\"\\n2. Retornar como Pandas DataFrame (.df()):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data_revenue = pa.table({\n",
    "    'date': pa.array(['2024-01-01', '2024-01-02', '2024-01-03'], type=pa.string()),\n",
    "    'revenue': [1000, 1500, 1200]\n",
    "})\n",
    "\n",
    "# Retornar como Pandas DataFrame\n",
    "result_df = con.execute(\"\"\"\n",
    "    SELECT date, revenue\n",
    "    FROM data_revenue\n",
    "    ORDER BY revenue DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"Tipo: {type(result_df)}\")\n",
    "print(result_df)\n",
    "print(f\"\\nSoma total: ${result_df['revenue'].sum():,}\")\n",
    "\n",
    "# 2.2.3 .fetchall() / .fetchone() - Retornar como Python\n",
    "print(\"\\n3. Retornar como Python nativo (.fetchall(), .fetchone()):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data_category = pa.table({\n",
    "    'category': ['Electronics', 'Clothing', 'Food'],\n",
    "    'count': [50, 30, 100]\n",
    "})\n",
    "\n",
    "# Retornar como lista de tuplas Python\n",
    "all_rows = con.execute(\"SELECT * FROM data_category\").fetchall()\n",
    "print(f\"Todas as linhas: {all_rows}\")\n",
    "\n",
    "# Retornar uma linha\n",
    "one_row = con.execute(\"SELECT * FROM data_category WHERE count > 40\").fetchone()\n",
    "print(f\"Uma linha: {one_row}\")\n",
    "\n",
    "# Retornar muitas linhas (com limite)\n",
    "many_rows = con.execute(\"SELECT * FROM data_category\").fetchmany(size=2)\n",
    "print(f\"Primeiras 2 linhas: {many_rows}\")\n",
    "\n",
    "# 2.3 Arrow Record Batches\n",
    "print(\"\\n4. Trabalhando com Record Batches:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar record batches (streaming)\n",
    "batch1 = pa.record_batch([\n",
    "    pa.array([1, 2, 3]),\n",
    "    pa.array(['A', 'B', 'C'])\n",
    "], names=['id', 'category'])\n",
    "\n",
    "batch2 = pa.record_batch([\n",
    "    pa.array([4, 5, 6]),\n",
    "    pa.array(['D', 'E', 'F'])\n",
    "], names=['id', 'category'])\n",
    "\n",
    "# Criar table de batches\n",
    "batches = [batch1, batch2]\n",
    "schema = pa.schema([\n",
    "    ('id', pa.int64()),\n",
    "    ('category', pa.string())\n",
    "])\n",
    "table_from_batches = pa.Table.from_batches(batches, schema=schema)\n",
    "\n",
    "print(\"Table criada de batches:\")\n",
    "print(table_from_batches)\n",
    "\n",
    "# Query com DuckDB\n",
    "result_batches = con.execute(\"SELECT * FROM table_from_batches ORDER BY id\").arrow()\n",
    "print(\"\\nResultado:\")\n",
    "print(result_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c4579",
   "metadata": {},
   "source": [
    "### Tópico 3: Query em Arrow Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3bd4f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QUERY EM ARROW TABLES ---\n",
      "\n",
      "1. Queries SQL Complexas em Arrow Tables:\n",
      "----------------------------------------\n",
      "Top 5 vendas por produto/região:\n",
      "pyarrow.Table\n",
      "product: string\n",
      "region: string\n",
      "num_sales: int64\n",
      "total_amount: decimal128(38, 0)\n",
      "avg_amount: double\n",
      "total_qty: decimal128(38, 0)\n",
      "----\n",
      "product: [[\"Laptop\",\"Monitor\",\"Keyboard\",\"Mouse\"]]\n",
      "region: [[\"North\",\"West\",\"East\",\"South\"]]\n",
      "num_sales: [[8,4,4,4]]\n",
      "total_amount: [[9580,1515,318,115]]\n",
      "avg_amount: [[1197.5,378.75,79.5,28.75]]\n",
      "total_qty: [[8,4,11,9]]\n",
      "\n",
      "2. Window Functions em Arrow Tables:\n",
      "----------------------------------------\n",
      "Ranking e agregações por janela:\n",
      "   sale_id   product  amount  rank_in_product  total_per_product  \\\n",
      "0       13  Keyboard      85                1              318.0   \n",
      "1        3  Keyboard      80                2              318.0   \n",
      "2       18  Keyboard      78                3              318.0   \n",
      "3        8  Keyboard      75                4              318.0   \n",
      "4        6    Laptop    1300                1             9580.0   \n",
      "5       16    Laptop    1280                2             9580.0   \n",
      "6       11    Laptop    1250                3             9580.0   \n",
      "7        1    Laptop    1200                4             9580.0   \n",
      "8       15    Laptop    1175                5             9580.0   \n",
      "9        5    Laptop    1150                6             9580.0   \n",
      "\n",
      "   avg_per_product  \n",
      "0             79.5  \n",
      "1             79.5  \n",
      "2             79.5  \n",
      "3             79.5  \n",
      "4           1197.5  \n",
      "5           1197.5  \n",
      "6           1197.5  \n",
      "7           1197.5  \n",
      "8           1197.5  \n",
      "9           1197.5  \n",
      "\n",
      "3. Subqueries e CTEs (Common Table Expressions):\n",
      "----------------------------------------\n",
      "Análise com CTEs:\n",
      "pyarrow.Table\n",
      "product: string\n",
      "product_total: decimal128(38, 0)\n",
      "avg_sales: double\n",
      "grand_total: decimal128(38, 0)\n",
      "pct_of_total: double\n",
      "----\n",
      "product: [[\"Laptop\",\"Monitor\",\"Keyboard\",\"Mouse\"]]\n",
      "product_total: [[9580,1515,318,115]]\n",
      "avg_sales: [[1197.5,378.75,79.5,28.75]]\n",
      "grand_total: [[11528,11528,11528,11528]]\n",
      "pct_of_total: [[83.1,13.14,2.76,1]]\n",
      "\n",
      "4. JOINs entre múltiplas Arrow Tables:\n",
      "----------------------------------------\n",
      "Análise de lucro por região/produto:\n",
      "  region manager   product     category  revenue  total_cost  profit  target  \\\n",
      "0  North   Alice    Laptop  Electronics   9580.0      6400.0  3180.0   50000   \n",
      "1   West   David   Monitor  Electronics   1515.0       800.0   715.0   48000   \n",
      "2  South     Bob     Mouse  Accessories    115.0       135.0   -20.0   40000   \n",
      "3   East   Carol  Keyboard  Accessories    318.0       440.0  -122.0   45000   \n",
      "\n",
      "   pct_target  \n",
      "0   19.160000  \n",
      "1    3.156250  \n",
      "2    0.287500  \n",
      "3    0.706667  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- {'Query em Arrow Tables'.upper()} ---\")\n",
    "\n",
    "# 2.4.1 Queries SQL Complexas em Arrow\n",
    "print(\"\\n1. Queries SQL Complexas em Arrow Tables:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar dados de vendas\n",
    "sales_data = pa.table({\n",
    "    'sale_id': range(1, 21),\n",
    "    'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Laptop'] * 4,\n",
    "    'region': ['North', 'South', 'East', 'West', 'North'] * 4,\n",
    "    'amount': [1200, 25, 80, 350, 1150, 1300, 30, 75, 400, 1100,\n",
    "               1250, 28, 85, 375, 1175, 1280, 32, 78, 390, 1125],\n",
    "    'quantity': [1, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 2, 3, 1, 1, 1, 2, 3, 1, 1]\n",
    "})\n",
    "\n",
    "# Query agregada complexa\n",
    "result_complex = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        product,\n",
    "        region,\n",
    "        count(*) as num_sales,\n",
    "        sum(amount) as total_amount,\n",
    "        avg(amount) as avg_amount,\n",
    "        sum(quantity) as total_qty\n",
    "    FROM sales_data\n",
    "    GROUP BY product, region\n",
    "    HAVING sum(amount) > 100\n",
    "    ORDER BY total_amount DESC\n",
    "    LIMIT 5\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"Top 5 vendas por produto/região:\")\n",
    "print(result_complex)\n",
    "\n",
    "# 2.4.2 Window Functions em Arrow\n",
    "print(\"\\n2. Window Functions em Arrow Tables:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Query com window functions\n",
    "result_window = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        sale_id,\n",
    "        product,\n",
    "        amount,\n",
    "        row_number() OVER (PARTITION BY product ORDER BY amount DESC) as rank_in_product,\n",
    "        sum(amount) OVER (PARTITION BY product) as total_per_product,\n",
    "        avg(amount) OVER (PARTITION BY product) as avg_per_product\n",
    "    FROM sales_data\n",
    "    ORDER BY product, rank_in_product\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Ranking e agregações por janela:\")\n",
    "print(result_window.head(10))\n",
    "\n",
    "# 2.4.3 Subqueries e CTEs\n",
    "print(\"\\n3. Subqueries e CTEs (Common Table Expressions):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Query com CTE\n",
    "result_cte = con.execute(\"\"\"\n",
    "    WITH product_stats AS (\n",
    "        SELECT\n",
    "            product,\n",
    "            sum(amount) as total_sales,\n",
    "            avg(amount) as avg_sales,\n",
    "            count(*) as num_transactions\n",
    "        FROM sales_data\n",
    "        GROUP BY product\n",
    "    ),\n",
    "    region_stats AS (\n",
    "        SELECT\n",
    "            region,\n",
    "            sum(amount) as total_sales,\n",
    "            count(*) as num_transactions\n",
    "        FROM sales_data\n",
    "        GROUP BY region\n",
    "    )\n",
    "    SELECT\n",
    "        p.product,\n",
    "        p.total_sales as product_total,\n",
    "        p.avg_sales,\n",
    "        (SELECT sum(total_sales) FROM region_stats) as grand_total,\n",
    "        ROUND(p.total_sales * 100.0 / (SELECT sum(total_sales) FROM region_stats), 2) as pct_of_total\n",
    "    FROM product_stats p\n",
    "    ORDER BY product_total DESC\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"Análise com CTEs:\")\n",
    "print(result_cte)\n",
    "\n",
    "# 2.4.4 JOINs entre múltiplas Arrow Tables\n",
    "print(\"\\n4. JOINs entre múltiplas Arrow Tables:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar tabelas relacionadas\n",
    "products_info = pa.table({\n",
    "    'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor'],\n",
    "    'category': ['Electronics', 'Accessories', 'Accessories', 'Electronics'],\n",
    "    'cost': [800, 15, 40, 200]\n",
    "})\n",
    "\n",
    "regions_info = pa.table({\n",
    "    'region': ['North', 'South', 'East', 'West'],\n",
    "    'manager': ['Alice', 'Bob', 'Carol', 'David'],\n",
    "    'target': [50000, 40000, 45000, 48000]\n",
    "})\n",
    "\n",
    "# Registrar as tabelas\n",
    "con.register('products_info', products_info)\n",
    "con.register('regions_info', regions_info)\n",
    "\n",
    "# Query com múltiplos JOINs\n",
    "result_joins = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        s.region,\n",
    "        r.manager,\n",
    "        s.product,\n",
    "        p.category,\n",
    "        sum(s.amount) as revenue,\n",
    "        sum(s.quantity * p.cost) as total_cost,\n",
    "        sum(s.amount) - sum(s.quantity * p.cost) as profit,\n",
    "        r.target,\n",
    "        sum(s.amount) * 100.0 / r.target as pct_target\n",
    "    FROM sales_data s\n",
    "    JOIN products_info p ON s.product = p.product\n",
    "    JOIN regions_info r ON s.region = r.region\n",
    "    GROUP BY s.region, r.manager, s.product, p.category, r.target\n",
    "    ORDER BY profit DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Análise de lucro por região/produto:\")\n",
    "print(result_joins.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0302bd",
   "metadata": {},
   "source": [
    "### Tópico 4: Schemas e metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4d9d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SCHEMAS E METADADOS ---\n",
      "\n",
      "1. Definir e Validar Schemas:\n",
      "----------------------------------------\n",
      "Schema definido:\n",
      "employee_id: int32 not null\n",
      "name: string not null\n",
      "department: string\n",
      "salary: decimal128(10, 2) not null\n",
      "hire_date: date32[day] not null\n",
      "is_manager: bool not null\n",
      "\n",
      "Tabela criada:\n",
      "pyarrow.Table\n",
      "employee_id: int32 not null\n",
      "name: string not null\n",
      "department: string\n",
      "salary: decimal128(10, 2) not null\n",
      "hire_date: date32[day] not null\n",
      "is_manager: bool not null\n",
      "----\n",
      "employee_id: [[1,2,3]]\n",
      "name: [[\"Alice\",\"Bob\",\"Carol\"]]\n",
      "department: [[\"HR\",\"IT\",\"Sales\"]]\n",
      "salary: [[75000.00,85000.00,70000.00]]\n",
      "hire_date: [[2021-01-01,2021-03-14,2021-05-03]]\n",
      "is_manager: [[true,false,true]]\n",
      "\n",
      "Resultado:\n",
      "pyarrow.Table\n",
      "name: string\n",
      "department: string\n",
      "salary: decimal128(10, 2)\n",
      "is_manager: bool\n",
      "----\n",
      "name: [[\"Bob\",\"Alice\"]]\n",
      "department: [[\"IT\",\"HR\"]]\n",
      "salary: [[85000.00,75000.00]]\n",
      "is_manager: [[false,true]]\n",
      "\n",
      "2. Modificar Schemas:\n",
      "----------------------------------------\n",
      "Schema original:\n",
      "id: int64\n",
      "name: string\n",
      "value: int64\n",
      "\n",
      "Schema renomeado:\n",
      "product_id: int64\n",
      "product_name: string\n",
      "quantity: int64\n",
      "\n",
      "Schema com colunas selecionadas:\n",
      "id: int64\n",
      "name: string\n",
      "\n",
      "Schema com colunas computadas:\n",
      "id: int64\n",
      "name: string\n",
      "value: int64\n",
      "doubled_value: int64\n",
      "is_high: bool\n",
      "\n",
      "3. Inspecionar Metadados:\n",
      "----------------------------------------\n",
      "Schema com metadados:\n",
      "id: int32\n",
      "sales: double\n",
      "-- schema metadata --\n",
      "author: 'Data Team'\n",
      "version: '1.0'\n",
      "description: 'Sales data 2024'\n",
      "\n",
      "Metadados customizados:\n",
      "  author: Data Team\n",
      "  version: 1.0\n",
      "  description: Sales data 2024\n",
      "\n",
      "4. Verificar Tipos de Dados:\n",
      "----------------------------------------\n",
      "Tipos de dados de cada coluna:\n",
      "  int_col: int64 (nullable=True)\n",
      "  float_col: double (nullable=True)\n",
      "  string_col: string (nullable=True)\n",
      "  bool_col: bool (nullable=True)\n",
      "  date_col: date32[day] (nullable=True)\n",
      "\n",
      "Schema após query no DuckDB:\n",
      "  int_col: int64\n",
      "  float_col: double\n",
      "  string_col: string\n",
      "  bool_col: bool\n",
      "  date_col: date32[day]\n",
      "\n",
      "5. Schema Evolution (Evolução de Schema):\n",
      "----------------------------------------\n",
      "Schema v1:\n",
      "id: int32\n",
      "name: string\n",
      "\n",
      "Schema v2 (com novas colunas):\n",
      "id: int32\n",
      "name: string\n",
      "balance: decimal128(2, 1)\n",
      "active: bool\n",
      "created_date: date32[day]\n",
      "\n",
      "Dados:\n",
      "pyarrow.Table\n",
      "id: int32\n",
      "name: string\n",
      "balance: decimal128(2, 1)\n",
      "active: bool\n",
      "created_date: date32[day]\n",
      "----\n",
      "id: [[1,2]]\n",
      "name: [[\"Alice\",\"Bob\"]]\n",
      "balance: [[0.0,0.0]]\n",
      "active: [[true,true]]\n",
      "created_date: [[2026-01-22,2026-01-22]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- {'Schemas e metadados'.upper()} ---\")\n",
    "\n",
    "# 2.5.1 Definir e Validar Schemas\n",
    "print(\"\\n1. Definir e Validar Schemas:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from datetime import date\n",
    "from decimal import Decimal\n",
    "\n",
    "# Definir schema explícito\n",
    "schema = pa.schema([\n",
    "    pa.field('employee_id', pa.int32(), nullable=False),\n",
    "    pa.field('name', pa.string(), nullable=False),\n",
    "    pa.field('department', pa.string(), nullable=True),\n",
    "    pa.field('salary', pa.decimal128(10, 2), nullable=False),\n",
    "    pa.field('hire_date', pa.date32(), nullable=False),\n",
    "    pa.field('is_manager', pa.bool_(), nullable=False)\n",
    "])\n",
    "\n",
    "print(\"Schema definido:\")\n",
    "print(schema)\n",
    "\n",
    "# Criar table com schema\n",
    "data_arrays = [\n",
    "    pa.array([1, 2, 3], type=pa.int32()),\n",
    "    pa.array(['Alice', 'Bob', 'Carol'], type=pa.string()),\n",
    "    pa.array(['HR', 'IT', 'Sales'], type=pa.string()),\n",
    "    pa.array([Decimal('75000.00'), Decimal('85000.00'), Decimal('70000.00')], type=pa.decimal128(10, 2)),\n",
    "    pa.array([18628, 18700, 18750], type=pa.date32()),  # Dias desde epoch\n",
    "    pa.array([True, False, True], type=pa.bool_())\n",
    "]\n",
    "\n",
    "employees = pa.Table.from_arrays(data_arrays, schema=schema)\n",
    "print(\"\\nTabela criada:\")\n",
    "print(employees)\n",
    "\n",
    "# Query com DuckDB\n",
    "result_schema = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        name,\n",
    "        department,\n",
    "        salary,\n",
    "        is_manager\n",
    "    FROM employees\n",
    "    WHERE salary > 70000\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"\\nResultado:\")\n",
    "print(result_schema)\n",
    "\n",
    "# 2.5.2 Modificar Schemas\n",
    "print(\"\\n2. Modificar Schemas:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Table original\n",
    "original = pa.table({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['A', 'B', 'C'],\n",
    "    'value': [10, 20, 30]\n",
    "})\n",
    "\n",
    "print(\"Schema original:\")\n",
    "print(original.schema)\n",
    "\n",
    "# Renomear colunas\n",
    "renamed = original.rename_columns(['product_id', 'product_name', 'quantity'])\n",
    "print(\"\\nSchema renomeado:\")\n",
    "print(renamed.schema)\n",
    "\n",
    "# Selecionar colunas específicas\n",
    "selected = original.select(['id', 'name'])\n",
    "print(\"\\nSchema com colunas selecionadas:\")\n",
    "print(selected.schema)\n",
    "\n",
    "# Adicionar coluna computada com DuckDB\n",
    "con.register('original', original)\n",
    "with_computed = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        *,\n",
    "        value * 2 as doubled_value,\n",
    "        value > 15 as is_high\n",
    "    FROM original\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"\\nSchema com colunas computadas:\")\n",
    "print(with_computed.schema)\n",
    "\n",
    "# 2.5.3 Inspecionar Metadados\n",
    "print(\"\\n3. Inspecionar Metadados:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar table com metadados customizados\n",
    "custom_metadata = {\n",
    "    b'author': b'Data Team',\n",
    "    b'version': b'1.0',\n",
    "    b'description': b'Sales data 2024'\n",
    "}\n",
    "\n",
    "schema_with_metadata = pa.schema([\n",
    "    pa.field('id', pa.int32()),\n",
    "    pa.field('sales', pa.float64())\n",
    "], metadata=custom_metadata)\n",
    "\n",
    "table_with_metadata = pa.table({\n",
    "    'id': [1, 2, 3],\n",
    "    'sales': [100.5, 200.3, 150.8]\n",
    "}, schema=schema_with_metadata)\n",
    "\n",
    "print(\"Schema com metadados:\")\n",
    "print(table_with_metadata.schema)\n",
    "print(\"\\nMetadados customizados:\")\n",
    "for key, value in table_with_metadata.schema.metadata.items():\n",
    "    print(f\"  {key.decode()}: {value.decode()}\")\n",
    "\n",
    "# 2.5.4 Verificar Tipos de Dados\n",
    "print(\"\\n4. Verificar Tipos de Dados:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Criar table com tipos variados\n",
    "mixed_types = pa.table({\n",
    "    'int_col': pa.array([1, 2, 3], type=pa.int64()),\n",
    "    'float_col': pa.array([1.1, 2.2, 3.3], type=pa.float64()),\n",
    "    'string_col': pa.array(['a', 'b', 'c'], type=pa.string()),\n",
    "    'bool_col': pa.array([True, False, True], type=pa.bool_()),\n",
    "    'date_col': pa.array([date(2024, 1, 1), date(2024, 1, 2), date(2024, 1, 3)], type=pa.date32())\n",
    "})\n",
    "\n",
    "print(\"Tipos de dados de cada coluna:\")\n",
    "for i, field in enumerate(mixed_types.schema):\n",
    "    print(f\"  {field.name}: {field.type} (nullable={field.nullable})\")\n",
    "\n",
    "# Verificar compatibilidade com DuckDB\n",
    "result_types = con.execute(\"SELECT * FROM mixed_types\").arrow()\n",
    "print(\"\\nSchema após query no DuckDB:\")\n",
    "for field in result_types.schema:\n",
    "    print(f\"  {field.name}: {field.type}\")\n",
    "\n",
    "# 2.5.5 Schema Evolution\n",
    "print(\"\\n5. Schema Evolution (Evolução de Schema):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Schema v1\n",
    "schema_v1 = pa.schema([\n",
    "    pa.field('id', pa.int32()),\n",
    "    pa.field('name', pa.string())\n",
    "])\n",
    "\n",
    "table_v1 = pa.table({\n",
    "    'id': [1, 2],\n",
    "    'name': ['Alice', 'Bob']\n",
    "}, schema=schema_v1)\n",
    "\n",
    "print(\"Schema v1:\")\n",
    "print(table_v1.schema)\n",
    "\n",
    "# Schema v2 - Adicionar novas colunas com DuckDB\n",
    "result_v2 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        *,\n",
    "        0.0 as balance,\n",
    "        true as active,\n",
    "        CURRENT_DATE as created_date\n",
    "    FROM table_v1\n",
    "\"\"\").arrow()\n",
    "\n",
    "print(\"\\nSchema v2 (com novas colunas):\")\n",
    "print(result_v2.schema)\n",
    "print(\"\\nDados:\")\n",
    "print(result_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bee73",
   "metadata": {},
   "source": [
    "### Tópico 5: Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e009bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- {'Error handling'.upper()} ---\")\n",
    "\n",
    "# 2.7.1 Tratamento de Erros Arrow\n",
    "print(\"\\n1. Tratamento de Erros em Queries Arrow:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def safe_arrow_query(table, query):\n",
    "    \"\"\"Executa query com tratamento de erro\"\"\"\n",
    "    try:\n",
    "        # Registrar table\n",
    "        con.register('query_table', table)\n",
    "        \n",
    "        # Executar query\n",
    "        result = con.execute(query).arrow()\n",
    "        return result, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "# Teste 1: Query válida\n",
    "data_test = pa.table({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
    "result, error = safe_arrow_query(data_test, \"SELECT x, y FROM query_table WHERE x > 1\")\n",
    "\n",
    "if error:\n",
    "    print(f\"Erro: {error}\")\n",
    "else:\n",
    "    print(\"✓ Sucesso - Query válida:\")\n",
    "    print(result)\n",
    "\n",
    "# Teste 2: Query inválida (coluna não existe)\n",
    "result, error = safe_arrow_query(data_test, \"SELECT z FROM query_table\")\n",
    "\n",
    "if error:\n",
    "    print(f\"\\n✗ Erro esperado capturado: {error}\")\n",
    "\n",
    "# Teste 3: Erro de sintaxe SQL\n",
    "result, error = safe_arrow_query(data_test, \"SELEKT x FROM query_table\")\n",
    "\n",
    "if error:\n",
    "    print(f\"\\n✗ Erro de sintaxe capturado: {error}\")\n",
    "\n",
    "# 2.7.2 Validação de Schema\n",
    "print(\"\\n2. Validação de Schema:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def validate_and_query(table, expected_columns):\n",
    "    \"\"\"Valida schema antes de query\"\"\"\n",
    "    # Validar colunas\n",
    "    actual_columns = set(table.schema.names)\n",
    "    expected_set = set(expected_columns)\n",
    "    \n",
    "    if not expected_set.issubset(actual_columns):\n",
    "        missing = expected_set - actual_columns\n",
    "        raise ValueError(f\"Colunas faltando: {missing}\")\n",
    "    \n",
    "    # Se válido, fazer query\n",
    "    result = con.execute(f\"\"\"\n",
    "        SELECT {', '.join(expected_columns)}\n",
    "        FROM table\n",
    "    \"\"\").arrow()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Teste com schema válido\n",
    "data_valid = pa.table({\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['A', 'B', 'C'],\n",
    "    'value': [10, 20, 30]\n",
    "})\n",
    "\n",
    "try:\n",
    "    result = validate_and_query(data_valid, ['id', 'name'])\n",
    "    print(\"✓ Validação passou:\")\n",
    "    print(result)\n",
    "except ValueError as e:\n",
    "    print(f\"Erro de validação: {e}\")\n",
    "\n",
    "# Teste com coluna faltando\n",
    "try:\n",
    "    result = validate_and_query(data_valid, ['id', 'missing_column'])\n",
    "    print(\"Validação passou:\")\n",
    "    print(result)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n✗ Erro de validação esperado: {e}\")\n",
    "\n",
    "# 2.7.3 Validação de Tipos de Dados\n",
    "print(\"\\n3. Validação de Tipos de Dados:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def validate_types(table, expected_types):\n",
    "    \"\"\"Valida tipos de dados do schema\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for col_name, expected_type in expected_types.items():\n",
    "        if col_name not in table.schema.names:\n",
    "            errors.append(f\"Coluna '{col_name}' não encontrada\")\n",
    "            continue\n",
    "        \n",
    "        field = table.schema.field(col_name)\n",
    "        if str(field.type) != expected_type:\n",
    "            errors.append(\n",
    "                f\"Tipo incorreto para '{col_name}': \"\n",
    "                f\"esperado {expected_type}, obtido {field.type}\"\n",
    "            )\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# Criar table para teste\n",
    "test_table = pa.table({\n",
    "    'id': pa.array([1, 2, 3], type=pa.int32()),\n",
    "    'amount': pa.array([10.5, 20.3, 30.7], type=pa.float64()),\n",
    "    'active': pa.array([True, False, True], type=pa.bool_())\n",
    "})\n",
    "\n",
    "# Validar tipos corretos\n",
    "expected_correct = {\n",
    "    'id': 'int32',\n",
    "    'amount': 'double',\n",
    "    'active': 'bool'\n",
    "}\n",
    "\n",
    "errors = validate_types(test_table, expected_correct)\n",
    "if errors:\n",
    "    print(\"✗ Erros encontrados:\")\n",
    "    for error in errors:\n",
    "        print(f\"  - {error}\")\n",
    "else:\n",
    "    print(\"✓ Todos os tipos estão corretos!\")\n",
    "\n",
    "# Validar tipos incorretos\n",
    "expected_wrong = {\n",
    "    'id': 'int64',  # Tipo errado\n",
    "    'amount': 'double',\n",
    "    'missing': 'string'  # Coluna inexistente\n",
    "}\n",
    "\n",
    "errors = validate_types(test_table, expected_wrong)\n",
    "if errors:\n",
    "    print(\"\\n✗ Erros esperados encontrados:\")\n",
    "    for error in errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# 2.7.4 Try-Except com Conversões\n",
    "print(\"\\n4. Tratamento de Erros em Conversões:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def safe_conversion(data, target_format='arrow'):\n",
    "    \"\"\"Converte dados com tratamento de erro\"\"\"\n",
    "    try:\n",
    "        if target_format == 'arrow':\n",
    "            # Pandas para Arrow\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                result = pa.Table.from_pandas(data)\n",
    "                print(f\"✓ Conversão Pandas → Arrow bem-sucedida\")\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"Dados não são DataFrame Pandas\")\n",
    "        \n",
    "        elif target_format == 'pandas':\n",
    "            # Arrow para Pandas\n",
    "            if isinstance(data, pa.Table):\n",
    "                result = data.to_pandas()\n",
    "                print(f\"✓ Conversão Arrow → Pandas bem-sucedida\")\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"Dados não são Arrow Table\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Erro na conversão: {e}\")\n",
    "        return None\n",
    "\n",
    "# Teste conversões\n",
    "df_test = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "arrow_result = safe_conversion(df_test, 'arrow')\n",
    "\n",
    "if arrow_result:\n",
    "    pandas_result = safe_conversion(arrow_result, 'pandas')\n",
    "\n",
    "# Teste com tipo errado\n",
    "invalid_data = \"string inválida\"\n",
    "safe_conversion(invalid_data, 'arrow')\n",
    "\n",
    "# 2.7.5 Validação Completa de Pipeline\n",
    "print(\"\\n5. Validação Completa de Pipeline:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def safe_pipeline(data, operations):\n",
    "    \"\"\"Executa pipeline com validação em cada etapa\"\"\"\n",
    "    print(\"Iniciando pipeline...\")\n",
    "    current_data = data\n",
    "    \n",
    "    for i, operation in enumerate(operations, 1):\n",
    "        try:\n",
    "            print(f\"\\n  Etapa {i}: {operation['name']}\")\n",
    "            \n",
    "            # Validar entrada\n",
    "            if not isinstance(current_data, pa.Table):\n",
    "                raise TypeError(\"Dados devem ser Arrow Table\")\n",
    "            \n",
    "            # Executar operação\n",
    "            current_data = con.execute(operation['query']).arrow()\n",
    "            print(f\"  ✓ {current_data.num_rows} linhas processadas\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Erro na etapa {i}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    print(\"\\n✓ Pipeline concluído com sucesso!\")\n",
    "    return current_data\n",
    "\n",
    "# Criar dados de teste\n",
    "pipeline_data = pa.table({\n",
    "    'product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'price': [100, 50, 200, 75, 150],\n",
    "    'quantity': [10, 20, 5, 15, 8]\n",
    "})\n",
    "\n",
    "# Definir operações do pipeline\n",
    "operations = [\n",
    "    {\n",
    "        'name': 'Filtrar preço > 60',\n",
    "        'query': 'SELECT * FROM pipeline_data WHERE price > 60'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Calcular total',\n",
    "        'query': 'SELECT product, price, quantity, price * quantity as total FROM pipeline_data'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ordenar por total',\n",
    "        'query': 'SELECT * FROM pipeline_data ORDER BY total DESC'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Executar pipeline\n",
    "final_result = safe_pipeline(pipeline_data, operations)\n",
    "\n",
    "if final_result:\n",
    "    print(\"\\nResultado final:\")\n",
    "    print(final_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
