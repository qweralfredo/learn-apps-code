# üéì Curso Completo - DuckDB + Open Table Formats

## ‚úÖ Status: 100% CONCLU√çDO

---

## üìö Estrutura do Curso

### üìñ Parte 1: Teoria (10 Cap√≠tulos Markdown)

Localiza√ß√£o: `C:\projetos\Cursos\Open File Tables + Duckdb\`

1. ‚úÖ **[01-introducao-open-table-formats.md](../01-introducao-open-table-formats.md)**
   - Hist√≥ria e evolu√ß√£o dos formatos
   - Compara√ß√£o Delta Lake vs Iceberg vs Hudi vs Paimon
   - Decision matrix (quando usar cada formato)
   - 25+ p√°ginas de conte√∫do

2. ‚úÖ **[02-duckdb-arquitetura-lakehouse.md](../02-duckdb-arquitetura-lakehouse.md)**
   - Medallion Architecture (Bronze ‚Üí Silver ‚Üí Gold)
   - Query Federation (m√∫ltiplas fontes)
   - Classe `MedallionPipeline` completa
   - Exemplos com MinIO S3

3. ‚úÖ **[03-delta-lake-duckdb.md](../03-delta-lake-duckdb.md)**
   - ACID transactions explicadas
   - Time travel com `delta_scan(..., version=N)`
   - OPTIMIZE, VACUUM, Z-ordering
   - `DeltaManager` helper class

4. ‚úÖ **[04-apache-iceberg-duckdb.md](../04-apache-iceberg-duckdb.md)**
   - Hidden partitioning (vs Hive partitioning)
   - Metadata tables (`iceberg_metadata()`)
   - Snapshot isolation
   - Schema evolution

5. ‚úÖ **[05-apache-hudi-outros-formatos.md](../05-apache-hudi-outros-formatos.md)**
   - Hudi CoW (Copy-on-Write) vs MoR (Merge-on-Read)
   - Apache Paimon (Flink-native)
   - DuckLake, Vortex
   - Compara√ß√£o performance

6. ‚úÖ **[06-lance-format-machine-learning.md](../06-lance-format-machine-learning.md)**
   - Lance Format para ML/AI
   - Vector embeddings storage
   - KNN search nativo
   - RAG System architecture
   - Classe `RAGSystem`, `ImageVectorStore`

7. ‚úÖ **[07-interoperabilidade-xtable.md](../07-interoperabilidade-xtable.md)**
   - Apache XTable (Incubating)
   - Convers√£o Delta ‚Üî Iceberg ‚Üî Hudi
   - Classe `XTableManager`
   - Multi-engine support (Spark, Trino, Flink)

8. ‚úÖ **[08-formatos-especializados.md](../08-formatos-especializados.md)**
   - Apache Kudu (OLTP + OLAP)
   - CarbonData (indexa√ß√£o avan√ßada)
   - Vortex (structured arrays)
   - Classe `MultiFormatDataPipeline`

9. ‚úÖ **[09-performance-otimizacoes.md](../09-performance-otimizacoes.md)**
   - Benchmarks comparativos (10+ cen√°rios)
   - Query optimization patterns
   - EXPLAIN ANALYZE debugging
   - Classe `FormatBenchmark`, `DuckDBMonitor`
   - Memory profiling, execution plans

10. ‚úÖ **[10-casos-uso-projetos-praticos.md](../10-casos-uso-projetos-praticos.md)**
    - 4 Projetos Completos:
      - Medallion Lakehouse
      - RAG Knowledge Base
      - CDC Pipeline (PostgreSQL ‚Üí Delta)
      - Multi-Cloud Data Mesh

**Total Teoria**: ~250 p√°ginas de conte√∫do t√©cnico detalhado

---

### üß™ Parte 2: Pr√°tica (10 Notebooks Jupyter)

Localiza√ß√£o: `C:\projetos\Cursos\Open File Tables + Duckdb\code\notebooks\`

1. ‚úÖ **[01-introducao.ipynb](notebooks/01-introducao.ipynb)**
   - Dataset: 100k orders
   - Benchmarks: Parquet vs Delta vs Iceberg
   - Visualiza√ß√µes matplotlib
   - Decision matrix interativa

2. ‚úÖ **[02-lakehouse.ipynb](notebooks/02-lakehouse.ipynb)**
   - Implementa√ß√£o completa Medallion
   - MinIO S3 integration (boto3)
   - Bronze: raw data
   - Silver: cleaned, partitioned by date
   - Gold: business aggregates
   - Federation queries

3. ‚úÖ **[03-delta-lake.ipynb](notebooks/03-delta-lake.ipynb)**
   - Time travel hands-on (10k + 5k + 3k rows)
   - Classe `DeltaManager`:
     - `create_table()`
     - `append_data()`
     - `read_version()`
     - `compare_versions()`
     - `show_history()`
   - OPTIMIZE, VACUUM examples

4. ‚úÖ **[04-iceberg.ipynb](notebooks/04-iceberg.ipynb)**
   - Dataset IoT: 50k sensor readings
   - Hidden partitioning demo
   - Metadata exploration (glob `**/*.metadata.json`)
   - Classe `IcebergManager`:
     - `create_table()`
     - `query()`
     - `get_metadata()`
   - Partition pruning benchmarks

5. ‚úÖ **[05-hudi-paimon.ipynb](notebooks/05-hudi-paimon.ipynb)**
   - Dataset: 10k user activity logs
   - CoW simulation (full rewrites)
   - Classe `HudiSimulator`:
     - `create_table()`
     - `upsert()`
     - `query()`
     - `history()`
   - Spark integration example
   - Paimon comparison matrix

6. ‚úÖ **[06-lance-ml.ipynb](notebooks/06-lance-ml.ipynb)**
   - 1000 documentos com embeddings (384-dim)
   - LanceDB connection
   - KNN semantic search (top-k)
   - Classe `SimpleRAG`:
     - `retrieve()` - vector search
     - `augment()` - context injection
     - `generate()` - mock LLM
     - `query()` - full pipeline
   - Lance vs Parquet benchmarks (random access)

7. ‚úÖ **[07-xtable.ipynb](notebooks/07-xtable.ipynb)**
   - 50k sales records
   - Delta ‚Üí Iceberg conversion
   - Classe `XTableManager`:
     - `sync_delta_to_iceberg()`
     - `sync_iceberg_to_hudi()`
     - `validate_sync()`
   - Bidirectional sync example
   - Use cases: multi-engine, migration, vendor independence

8. ‚úÖ **[08-specialized.ipynb](notebooks/08-specialized.ipynb)**
   - Kudu simulation (10k IoT readings)
   - OLTP (point lookups) vs OLAP (aggregations)
   - CarbonData: MDK index, Bloom filters
   - Vortex: numerical arrays (1M elements)
   - Format comparison matrix
   - Decision tree diagram

9. ‚úÖ **[09-performance.ipynb](notebooks/09-performance.ipynb)**
   - Dataset: 1M records
   - Benchmarks:
     - CSV vs Parquet (none/snappy/gzip)
     - Write performance
     - Read performance (4 formats)
   - Query optimization:
     - EXPLAIN ANALYZE examples
     - Projection pushdown (speedup 2-5x)
     - Filter pushdown (speedup 3-10x)
   - Memory profiling (tracemalloc)
   - Best practices checklist

10. ‚úÖ **[10-projects.ipynb](notebooks/10-projects.ipynb)**
    - **Projeto 1 - Medallion Lakehouse**: 100k orders ‚Üí Bronze/Silver/Gold
    - **Projeto 2 - RAG System**: 8 documentos knowledge base + semantic search
    - **Projeto 3 - CDC Pipeline**: PostgreSQL ‚Üí Delta Lake
    - **Projeto 4 - Multi-Cloud Federation**: S3 + Delta + PostgreSQL queries
    - Complete end-to-end scenarios

**Total Pr√°tica**: 10 notebooks execut√°veis com 100+ c√©lulas de c√≥digo

---

### üê≥ Parte 3: Infraestrutura (Docker Compose)

Localiza√ß√£o: `C:\projetos\Cursos\Open File Tables + Duckdb\code\`

#### ‚úÖ Servi√ßos (8 containers, ~10GB RAM)

1. **Jupyter Lab** (`jupyter/datascience-notebook:latest`)
   - Port: 8888
   - Token: `duckdb123`
   - Python 3.11 + 50+ libraries
   - DuckDB, Delta Lake, Iceberg, LanceDB

2. **MinIO** (S3-compatible storage)
   - Ports: 9000 (API), 9001 (Console)
   - Credentials: minioadmin/minioadmin
   - Buckets: bronze, silver, gold, delta, iceberg, hudi, lance

3. **PostgreSQL** (Transactional database)
   - Port: 5432
   - Database: `demo_cdc`
   - User: duckdb/duckdb123
   - Pre-loaded: customers, orders, products, CDC triggers

4. **Spark Master**
   - Ports: 7077 (Spark), 8080 (UI)
   - Memory: auto
   - For Hudi/Paimon processing

5. **Spark Worker**
   - Memory: 2GB
   - Cores: 2
   - Connects to Master

6. **Flink JobManager**
   - Port: 8081 (Dashboard)
   - Memory: 1GB
   - For stream processing

7. **Flink TaskManager**
   - Memory: 2GB
   - Slots: 2
   - For Paimon examples

8. **Hive Metastore**
   - Port: 9083
   - For Iceberg catalog

#### ‚úÖ Arquivos de Configura√ß√£o

- **docker-compose.yml**: Orquestra√ß√£o completa
- **.env**: Vari√°veis de ambiente (MinIO, PostgreSQL, Spark, Flink)
- **requirements.txt**: 50+ Python packages
- **scripts/init-postgres.sql**: Dados demo + CDC triggers
- **scripts/test_environment.py**: Valida√ß√£o automatizada

#### ‚úÖ Documenta√ß√£o

- **README.md**: Overview do projeto
- **QUICK-START.md**: Guia r√°pido (6 se√ß√µes)
- **README-DOCKER.md**: Detalhes t√©cnicos Docker

---

## üìä Estat√≠sticas do Curso

### Conte√∫do
- **Markdown**: 10 cap√≠tulos, ~250 p√°ginas
- **Notebooks**: 10 arquivos .ipynb, ~120 c√©lulas
- **C√≥digo**: ~2500 linhas Python
- **Classes Helper**: 15+ (DeltaManager, IcebergManager, RAGSystem, XTableManager, etc.)

### Formatos Cobertos
1. ‚úÖ Parquet (baseline)
2. ‚úÖ Delta Lake (Databricks)
3. ‚úÖ Apache Iceberg (Netflix)
4. ‚úÖ Apache Hudi (Uber)
5. ‚úÖ Apache Paimon (Alibaba)
6. ‚úÖ Lance Format (LanceDB)
7. ‚úÖ Apache Kudu (Cloudera)
8. ‚úÖ CarbonData (Huawei)
9. ‚úÖ Vortex (Array-focused)
10. ‚úÖ DuckLake (DuckDB native)
11. ‚úÖ XTable (Interoperability)

### Tecnologias
- **DuckDB**: v1.4.0+
- **Delta Lake**: deltalake 0.17+
- **Apache Iceberg**: pyiceberg 0.6+
- **LanceDB**: lancedb 0.6+
- **Spark**: 3.5.0
- **Flink**: 1.18.0
- **PostgreSQL**: 16
- **MinIO**: RELEASE.2024-01-01T00-00-00Z

### Datasets
- **Sint√©ticos**: 1.5M+ registros totais
- **Reais**: PostgreSQL CDC logs, vector embeddings
- **Variados**: Orders, IoT sensors, user activity, documents, images

---

## üéØ O que voc√™ aprender√°

### üü¢ N√≠vel B√°sico
- ‚úÖ Conceitos de table formats
- ‚úÖ Parquet vs columnar vs row formats
- ‚úÖ DuckDB como engine anal√≠tica
- ‚úÖ Leitura/escrita de arquivos

### üü° N√≠vel Intermedi√°rio
- ‚úÖ Delta Lake: ACID, time travel
- ‚úÖ Apache Iceberg: metadata, partitioning
- ‚úÖ Lakehouse Architecture (Medallion)
- ‚úÖ S3/MinIO integration
- ‚úÖ Query optimization patterns

### üî¥ N√≠vel Avan√ßado
- ‚úÖ Hudi CoW/MoR strategies
- ‚úÖ Lance Format: vector search, RAG
- ‚úÖ XTable: format interoperability
- ‚úÖ CDC pipelines (PostgreSQL ‚Üí Delta)
- ‚úÖ Multi-cloud federation
- ‚úÖ Performance tuning (EXPLAIN ANALYZE)
- ‚úÖ Specialized formats (Kudu, CarbonData, Vortex)

---

## üöÄ Como Usar Este Curso

### üìñ Op√ß√£o 1: Apenas Teoria (sem Docker)

```bash
cd "C:\projetos\Cursos\Open File Tables + Duckdb"

# Ler cap√≠tulos na ordem:
# 01-introducao-open-table-formats.md
# 02-duckdb-arquitetura-lakehouse.md
# ... at√© 10-casos-uso-projetos-praticos.md
```

### üß™ Op√ß√£o 2: Teoria + Pr√°tica (com Docker)

```bash
cd "C:\projetos\Cursos\Open File Tables + Duckdb\code"

# 1. Iniciar ambiente
docker-compose up -d

# 2. Aguardar (~2 min)
docker-compose ps

# 3. Acessar Jupyter
# http://localhost:8888 (token: duckdb123)

# 4. Executar notebooks na ordem:
# notebooks/01-introducao.ipynb
# notebooks/02-lakehouse.ipynb
# ... at√© notebooks/10-projects.ipynb
```

### üéì Op√ß√£o 3: Curso Completo (recomendado)

1. **Dia 1-3**: Ler cap√≠tulos 01-03 (teoria) + executar notebooks 01-03
2. **Dia 4-6**: Ler cap√≠tulos 04-06 + executar notebooks 04-06
3. **Dia 7-9**: Ler cap√≠tulos 07-09 + executar notebooks 07-09
4. **Dia 10**: Projetos completos (cap√≠tulo 10 + notebook 10)

**Total**: ~40 horas de estudo (10 dias x 4h/dia)

---

## ‚úÖ Valida√ß√£o e Testes

### 1. Testar Ambiente Docker

```bash
cd code/
python scripts/test_environment.py
```

Espera-se:
```
‚úì All imports successful
‚úì DuckDB v1.4.0+ available
‚úì MinIO accessible (9000, 9001)
‚úì PostgreSQL accessible (5432)
‚úì Spark Master accessible (8080)
‚úì All 10 notebooks found
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úÖ Environment validation PASSED
```

### 2. Executar Todos Notebooks

```bash
cd notebooks/
jupyter nbconvert --to notebook --execute *.ipynb --output-dir=executed/
```

### 3. Validar Outputs

Cada notebook deve produzir:
- ‚úÖ Prints de status
- ‚úÖ DataFrames pandas
- ‚úÖ Visualiza√ß√µes matplotlib
- ‚úÖ Benchmarks (tempo de execu√ß√£o)
- ‚úÖ Sem erros (exit code 0)

---

## üìö Recursos Adicionais

### Documenta√ß√£o Oficial
- **DuckDB**: https://duckdb.org/docs/
- **Delta Lake**: https://docs.delta.io/
- **Apache Iceberg**: https://iceberg.apache.org/docs/latest/
- **Apache Hudi**: https://hudi.apache.org/docs/overview
- **LanceDB**: https://lancedb.github.io/lancedb/

### Papers de Refer√™ncia
- Delta Lake (VLDB 2020): Lakehouse Architecture
- Iceberg (VLDB 2020): Table Format Evolution
- Hudi (VLDB 2019): Incremental Processing at Uber

### Tutoriais Complementares
- DuckDB + Parquet: https://duckdb.org/docs/data/parquet
- Delta Lake Python API: https://delta-io.github.io/delta-rs/python/
- Iceberg Python (PyIceberg): https://py.iceberg.apache.org/

---

## üéì Certifica√ß√£o (Auto-Avalia√ß√£o)

### ‚úÖ Checklist de Aprendizado

#### Conceitos Te√≥ricos
- [ ] Posso explicar a diferen√ßa entre Parquet, Delta, Iceberg, Hudi
- [ ] Entendo Medallion Architecture (Bronze/Silver/Gold)
- [ ] Sei quando usar cada formato (decision matrix)
- [ ] Compreendo ACID transactions em data lakes
- [ ] Entendo hidden partitioning vs Hive partitioning
- [ ] Conhe√ßo CoW vs MoR strategies
- [ ] Sei o que √© XTable e para que serve

#### Pr√°tica
- [ ] Consigo ler/escrever Parquet com DuckDB
- [ ] Sei criar tabelas Delta Lake com time travel
- [ ] Posso query Iceberg tables com metadata
- [ ] Implementei uma pipeline Medallion completa
- [ ] Configurei MinIO (S3) e fiz queries remotas
- [ ] Criei um RAG system b√°sico com Lance
- [ ] Integrei PostgreSQL + DuckDB (CDC)
- [ ] Otimizei queries (EXPLAIN ANALYZE)

#### Projetos
- [ ] Implementei Projeto 1 (Medallion Lakehouse)
- [ ] Implementei Projeto 2 (RAG System)
- [ ] Implementei Projeto 3 (CDC Pipeline)
- [ ] Implementei Projeto 4 (Multi-Cloud Federation)

**Meta**: 80%+ checklist = Curso conclu√≠do! üéâ

---

## ü§ù Contribui√ß√µes

Este √© um curso open-source. Contribui√ß√µes s√£o bem-vindas!

### Como Contribuir

1. **Issues**: Reportar erros, sugerir melhorias
2. **Pull Requests**: Corrigir typos, adicionar exemplos
3. **Notebooks**: Criar exerc√≠cios adicionais
4. **Documenta√ß√£o**: Traduzir para outros idiomas

### Roadmap Futuro

- [ ] Adicionar exerc√≠cios com solu√ß√µes
- [ ] Criar v√≠deos explicativos
- [ ] Traduzir para ingl√™s
- [ ] Adicionar testes automatizados
- [ ] Deploy em Kubernetes (exemplos)
- [ ] Integrar com DBT (data transformations)

---

## üìÑ Licen√ßa

MIT License - Use livremente para aprender e ensinar!

---

## ‚ú® Cr√©ditos

**Curso criado por**: Alfredo Rodrigues  
**Data**: Janeiro 2025  
**Vers√£o**: 1.0.0  

**Baseado em**:
- DuckDB Official Docs
- Delta Lake Guide (Databricks)
- Apache Iceberg Spec (Netflix)
- Lance Format (LanceDB)
- Apache XTable (Incubating)

**Agradecimentos**:
- DuckDB Team (in-process analytics engine)
- Delta Lake Contributors
- Apache Software Foundation (Iceberg, Hudi, Paimon)
- LanceDB Team

---

## üéâ Happy Learning!

Esperamos que este curso seja √∫til na sua jornada com DuckDB e Open Table Formats!

**D√∫vidas?** Abra uma issue no reposit√≥rio.  
**Feedback?** Entre em contato via email/LinkedIn.

**Keep coding!** üöÄ
