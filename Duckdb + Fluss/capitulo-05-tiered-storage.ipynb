{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0424767",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 5: Tiered Storage Transparente\n",
    "\n",
    "Demonstra√ß√£o de armazenamento em camadas (Memory ‚Üí SSD ‚Üí S3) com queries transparentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0e014",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb pandas numpy matplotlib seaborn pyarrow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce18818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(f\"DuckDB: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d7fc8",
   "metadata": {},
   "source": [
    "## 5.1 Simular Tiers de Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rios para simular tiers\n",
    "tiers = {\n",
    "    'hot': 'tier_hot',      # Simula mem√≥ria/SSD (dados recentes)\n",
    "    'warm': 'tier_warm',    # Simula SSD local (dados de 7-30 dias)\n",
    "    'cold': 'tier_cold'     # Simula S3 (dados > 30 dias)\n",
    "}\n",
    "\n",
    "for tier, path in tiers.items():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "print(\"‚úÖ Tiers de storage criados:\")\n",
    "for tier, path in tiers.items():\n",
    "    print(f\"  - {tier.upper()}: {path}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e38135",
   "metadata": {},
   "source": [
    "## 5.2 Gerar Dados Hist√≥ricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Gerar dados para diferentes per√≠odos\n",
    "def generate_data(start_date, days, rows_per_day):\n",
    "    data = []\n",
    "    for day in range(days):\n",
    "        date = start_date + timedelta(days=day)\n",
    "        timestamp_base = int(date.timestamp())\n",
    "        \n",
    "        for i in range(rows_per_day):\n",
    "            data.append({\n",
    "                'order_id': f'{date.strftime(\"%Y%m%d\")}-{i:06d}',\n",
    "                'customer_id': np.random.randint(1, 100000),\n",
    "                'amount': round(np.random.uniform(10, 1000), 2),\n",
    "                'timestamp': timestamp_base + i,\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'region': np.random.choice(['north', 'south', 'east', 'west']),\n",
    "                'status': np.random.choice(['completed', 'pending'], p=[0.9, 0.1])\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"Gerando dados hist√≥ricos...\")\n",
    "\n",
    "# HOT: √öltimos 7 dias (100k linhas/dia)\n",
    "hot_data = generate_data(datetime.now() - timedelta(days=7), 7, 100000)\n",
    "pq.write_table(pa.Table.from_pandas(hot_data), f\"{tiers['hot']}/recent.parquet\")\n",
    "print(f\"  ‚úì HOT tier: {len(hot_data):,} linhas (√∫ltimos 7 dias)\")\n",
    "\n",
    "# WARM: 8-30 dias (50k linhas/dia)\n",
    "warm_data = generate_data(datetime.now() - timedelta(days=30), 23, 50000)\n",
    "pq.write_table(pa.Table.from_pandas(warm_data), f\"{tiers['warm']}/medium.parquet\")\n",
    "print(f\"  ‚úì WARM tier: {len(warm_data):,} linhas (8-30 dias)\")\n",
    "\n",
    "# COLD: 31-90 dias (10k linhas/dia)\n",
    "cold_data = generate_data(datetime.now() - timedelta(days=90), 60, 10000)\n",
    "pq.write_table(pa.Table.from_pandas(cold_data), f\"{tiers['cold']}/archive.parquet\")\n",
    "print(f\"  ‚úì COLD tier: {len(cold_data):,} linhas (31-90 dias)\")\n",
    "\n",
    "total_rows = len(hot_data) + len(warm_data) + len(cold_data)\n",
    "print(f\"\\n‚úÖ Total: {total_rows:,} linhas em 3 tiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffdc146",
   "metadata": {},
   "source": [
    "## 5.3 Query Cross-Tier Transparente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Query que acessa TODOS os tiers transparentemente\n",
    "print(\"=== Query Cross-Tier: √öltimos 90 dias ===\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        COUNT(*) as num_orders,\n",
    "        ROUND(SUM(amount), 2) as total_revenue,\n",
    "        ROUND(AVG(amount), 2) as avg_order_value\n",
    "    FROM read_parquet(['tier_hot/*.parquet', 'tier_warm/*.parquet', 'tier_cold/*.parquet'])\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY date\n",
    "    ORDER BY date DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "query_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"Tempo: {query_time*1000:.1f}ms\\n\")\n",
    "print(result.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1951e",
   "metadata": {},
   "source": [
    "## 5.4 Performance por Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark de cada tier individualmente\n",
    "tier_performance = []\n",
    "\n",
    "for tier_name, tier_path in tiers.items():\n",
    "    start = time.perf_counter()\n",
    "    result = con.execute(f\"\"\"\n",
    "        SELECT COUNT(*), SUM(amount)\n",
    "        FROM read_parquet('{tier_path}/*.parquet')\n",
    "    \"\"\").fetchone()\n",
    "    elapsed = time.perf_counter() - start\n",
    "    \n",
    "    # Tamanho do tier\n",
    "    size_mb = sum(os.path.getsize(f\"{tier_path}/{f}\") \n",
    "                  for f in os.listdir(tier_path) if f.endswith('.parquet')) / 1024 / 1024\n",
    "    \n",
    "    tier_performance.append({\n",
    "        'Tier': tier_name.upper(),\n",
    "        'Linhas': f\"{result[0]:,}\",\n",
    "        'Tamanho (MB)': f\"{size_mb:.1f}\",\n",
    "        'Query Time (ms)': f\"{elapsed*1000:.1f}\",\n",
    "        'Throughput (MB/s)': f\"{size_mb/elapsed:.1f}\"\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(tier_performance)\n",
    "print(\"\\n=== Performance por Tier ===\")\n",
    "print(perf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed362fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar performance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "tiers_list = ['HOT', 'WARM', 'COLD']\n",
    "sizes = [float(perf_df[perf_df['Tier'] == t]['Tamanho (MB)'].iloc[0]) for t in tiers_list]\n",
    "times = [float(perf_df[perf_df['Tier'] == t]['Query Time (ms)'].iloc[0]) for t in tiers_list]\n",
    "\n",
    "colors = ['#ff6b6b', '#ffd43b', '#51cf66']\n",
    "\n",
    "# Tamanho\n",
    "ax1.bar(tiers_list, sizes, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Tamanho (MB)')\n",
    "ax1.set_title('Tamanho de Dados por Tier')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (tier, size) in enumerate(zip(tiers_list, sizes)):\n",
    "    ax1.text(i, size, f'{size:.1f} MB', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Tempo de query\n",
    "ax2.bar(tiers_list, times, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Query Time (ms)')\n",
    "ax2.set_title('Performance de Query por Tier')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (tier, t) in enumerate(zip(tiers_list, times)):\n",
    "    ax2.text(i, t, f'{t:.1f}ms', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905e977",
   "metadata": {},
   "source": [
    "## 5.5 Retention Policy Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular pol√≠tica de reten√ß√£o\n",
    "retention_config = {\n",
    "    'hot': {'days': 7, 'format': 'Arrow', 'compression': None},\n",
    "    'warm': {'days': 30, 'format': 'Arrow IPC', 'compression': 'LZ4'},\n",
    "    'cold': {'days': 365, 'format': 'Parquet', 'compression': 'Snappy'}\n",
    "}\n",
    "\n",
    "print(\"=== Pol√≠tica de Reten√ß√£o ===\")\n",
    "for tier, config in retention_config.items():\n",
    "    print(f\"\\n{tier.upper()}:\")\n",
    "    print(f\"  - Reten√ß√£o: {config['days']} dias\")\n",
    "    print(f\"  - Formato: {config['format']}\")\n",
    "    print(f\"  - Compress√£o: {config['compression'] or 'Nenhuma'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b25a47",
   "metadata": {},
   "source": [
    "## 5.6 Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de custo (simulado)\n",
    "costs = {\n",
    "    'Memory': {'price_gb_month': 10.00, 'tier': 'HOT'},\n",
    "    'SSD': {'price_gb_month': 0.20, 'tier': 'WARM'},\n",
    "    'S3': {'price_gb_month': 0.023, 'tier': 'COLD'}\n",
    "}\n",
    "\n",
    "# Calcular custo por tier\n",
    "total_cost = 0\n",
    "cost_breakdown = []\n",
    "\n",
    "for storage, info in costs.items():\n",
    "    tier = info['tier']\n",
    "    size_gb = float(perf_df[perf_df['Tier'] == tier]['Tamanho (MB)'].iloc[0]) / 1024\n",
    "    monthly_cost = size_gb * info['price_gb_month']\n",
    "    total_cost += monthly_cost\n",
    "    \n",
    "    cost_breakdown.append({\n",
    "        'Storage': storage,\n",
    "        'Tier': tier,\n",
    "        'Size (GB)': f\"{size_gb:.2f}\",\n",
    "        'Price/GB/Month': f\"${info['price_gb_month']:.3f}\",\n",
    "        'Monthly Cost': f\"${monthly_cost:.2f}\"\n",
    "    })\n",
    "\n",
    "cost_df = pd.DataFrame(cost_breakdown)\n",
    "print(\"\\n=== An√°lise de Custo Mensal ===\")\n",
    "print(cost_df.to_string(index=False))\n",
    "print(f\"\\nCusto Total Mensal: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c28dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar com storage √∫nico em SSD\n",
    "total_size_gb = sum(float(cost_df['Size (GB)'].iloc[i]) for i in range(len(cost_df)))\n",
    "ssd_only_cost = total_size_gb * 0.20\n",
    "\n",
    "savings = (ssd_only_cost - total_cost) / ssd_only_cost * 100\n",
    "\n",
    "print(f\"\\n=== Compara√ß√£o ===\")\n",
    "print(f\"Tudo em SSD: ${ssd_only_cost:.2f}/m√™s\")\n",
    "print(f\"Tiered Storage: ${total_cost:.2f}/m√™s\")\n",
    "print(f\"Economia: {savings:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribui√ß√£o de custo\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart de custo\n",
    "labels = cost_df['Storage'].tolist()\n",
    "costs_values = [float(cost_df['Monthly Cost'].iloc[i].replace('$', '')) for i in range(len(cost_df))]\n",
    "colors_pie = ['#ff6b6b', '#ffd43b', '#51cf66']\n",
    "\n",
    "ax1.pie(costs_values, labels=labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
    "ax1.set_title('Distribui√ß√£o de Custo por Storage')\n",
    "\n",
    "# Bar chart compara√ß√£o\n",
    "strategies = ['SSD Only', 'Tiered Storage']\n",
    "strategy_costs = [ssd_only_cost, total_cost]\n",
    "colors_bar = ['#ff6b6b', '#51cf66']\n",
    "\n",
    "bars = ax2.bar(strategies, strategy_costs, color=colors_bar, alpha=0.7)\n",
    "ax2.set_ylabel('Custo Mensal ($)')\n",
    "ax2.set_title('Compara√ß√£o de Estrat√©gias')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, cost in zip(bars, strategy_costs):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
    "             f'${cost:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí∞ Economia de ${ssd_only_cost - total_cost:.2f}/m√™s com Tiered Storage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2461f5ef",
   "metadata": {},
   "source": [
    "## 5.7 Time-Travel Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec545ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query que acessa dados de diferentes per√≠odos\n",
    "print(\"=== Time-Travel Query ===\")\n",
    "print(\"Analisando tend√™ncias ao longo de 90 dias...\\n\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "trends = con.execute(\"\"\"\n",
    "    WITH daily_stats AS (\n",
    "        SELECT \n",
    "            date,\n",
    "            COUNT(*) as orders,\n",
    "            SUM(amount) as revenue,\n",
    "            AVG(amount) as avg_order\n",
    "        FROM read_parquet(['tier_hot/*.parquet', 'tier_warm/*.parquet', 'tier_cold/*.parquet'])\n",
    "        WHERE status = 'completed'\n",
    "        GROUP BY date\n",
    "    ),\n",
    "    weekly_avg AS (\n",
    "        SELECT \n",
    "            AVG(revenue) OVER (ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as ma7\n",
    "        FROM daily_stats\n",
    "        ORDER BY date DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    SELECT \n",
    "        COUNT(DISTINCT date) as total_days,\n",
    "        SUM(orders) as total_orders,\n",
    "        ROUND(SUM(revenue), 2) as total_revenue,\n",
    "        ROUND(AVG(revenue), 2) as daily_avg,\n",
    "        ROUND((SELECT ma7 FROM weekly_avg), 2) as ma7_revenue\n",
    "    FROM daily_stats\n",
    "\"\"\").fetchdf()\n",
    "query_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"Tempo: {query_time*1000:.1f}ms\\n\")\n",
    "print(trends.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Query acessou 90 dias de dados cross-tier transparentemente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d785f",
   "metadata": {},
   "source": [
    "## 5.8 Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf855b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'Tier': ['HOT (Memory/SSD)', 'WARM (SSD Local)', 'COLD (S3)'],\n",
    "    'Reten√ß√£o': ['7 dias', '8-30 dias', '31-365 dias'],\n",
    "    'Formato': ['Arrow', 'Arrow IPC + LZ4', 'Parquet + Snappy'],\n",
    "    'Custo/GB': ['$10.00', '$0.20', '$0.023'],\n",
    "    'Caso de Uso': [\n",
    "        'Real-time, alta lat√™ncia',\n",
    "        'Analytics recente',\n",
    "        'Hist√≥rico, compliance'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== RESUMO DO CAP√çTULO 5 ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ Principais Conclus√µes:\")\n",
    "print(f\"  1. Queries cross-tier s√£o transparentes\")\n",
    "print(f\"  2. Economia de custo: {savings:.1f}% vs SSD √∫nico\")\n",
    "print(f\"  3. Performance adequada por tier\")\n",
    "print(f\"  4. Reten√ß√£o autom√°tica por pol√≠tica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e600c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "con.close()\n",
    "\n",
    "for tier_path in tiers.values():\n",
    "    if os.path.exists(tier_path):\n",
    "        shutil.rmtree(tier_path)\n",
    "\n",
    "print(\"\\n‚úÖ Notebook conclu√≠do!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
