{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca111090",
   "metadata": {},
   "source": [
    "# Capítulo 4: Consultando Log vs. Tabela — A Dualidade do Fluss\n",
    "\n",
    "Demonstração prática de log (append-only) vs. table (upsert com primary key)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdf91b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckdb pandas numpy matplotlib seaborn faker -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(f\"DuckDB: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee42c0",
   "metadata": {},
   "source": [
    "## 4.1 Modo LOG: Append-Only Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c50db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar banco de dados\n",
    "con = duckdb.connect('fluss_demo.db')\n",
    "\n",
    "# Tabela de eventos (LOG mode)\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE user_events (\n",
    "        event_id VARCHAR PRIMARY KEY,\n",
    "        user_id INTEGER,\n",
    "        event_type VARCHAR,\n",
    "        page VARCHAR,\n",
    "        timestamp BIGINT,\n",
    "        session_id VARCHAR\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Tabela user_events criada (modo LOG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar eventos de navegação\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "n_events = 50000\n",
    "event_types = ['page_view', 'click', 'scroll', 'form_submit']\n",
    "pages = ['/home', '/products', '/cart', '/checkout', '/profile']\n",
    "\n",
    "events = []\n",
    "base_time = int(datetime.now().timestamp())\n",
    "\n",
    "for i in range(n_events):\n",
    "    events.append({\n",
    "        'event_id': str(uuid.uuid4()),\n",
    "        'user_id': random.randint(1, 1000),\n",
    "        'event_type': random.choice(event_types),\n",
    "        'page': random.choice(pages),\n",
    "        'timestamp': base_time + i,\n",
    "        'session_id': f'sess-{random.randint(1, 5000)}'\n",
    "    })\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "con.execute(\"INSERT INTO user_events SELECT * FROM events_df\")\n",
    "\n",
    "print(f\"✅ {n_events:,} eventos inseridos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Análise de funil\n",
    "print(\"=== Análise de Funil (Funnel) ===\")\n",
    "\n",
    "funnel = con.execute(\"\"\"\n",
    "    WITH funnel_steps AS (\n",
    "        SELECT \n",
    "            session_id,\n",
    "            MAX(CASE WHEN page = '/home' THEN 1 ELSE 0 END) as visited_home,\n",
    "            MAX(CASE WHEN page = '/products' THEN 1 ELSE 0 END) as visited_products,\n",
    "            MAX(CASE WHEN page = '/cart' THEN 1 ELSE 0 END) as visited_cart,\n",
    "            MAX(CASE WHEN page = '/checkout' THEN 1 ELSE 0 END) as visited_checkout\n",
    "        FROM user_events\n",
    "        GROUP BY session_id\n",
    "    )\n",
    "    SELECT \n",
    "        SUM(visited_home) as step1_home,\n",
    "        SUM(visited_products) as step2_products,\n",
    "        SUM(visited_cart) as step3_cart,\n",
    "        SUM(visited_checkout) as step4_checkout,\n",
    "        ROUND(SUM(visited_products)::FLOAT / SUM(visited_home) * 100, 1) as conversion_1_2,\n",
    "        ROUND(SUM(visited_cart)::FLOAT / SUM(visited_products) * 100, 1) as conversion_2_3,\n",
    "        ROUND(SUM(visited_checkout)::FLOAT / SUM(visited_cart) * 100, 1) as conversion_3_4\n",
    "    FROM funnel_steps\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(funnel.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar funil\n",
    "steps = ['Home', 'Products', 'Cart', 'Checkout']\n",
    "values = [\n",
    "    int(funnel['step1_home'].iloc[0]),\n",
    "    int(funnel['step2_products'].iloc[0]),\n",
    "    int(funnel['step3_cart'].iloc[0]),\n",
    "    int(funnel['step4_checkout'].iloc[0])\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = ['#4CAF50', '#2196F3', '#FF9800', '#F44336']\n",
    "bars = ax.barh(steps, values, color=colors, alpha=0.7)\n",
    "\n",
    "# Adicionar valores e percentuais\n",
    "for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "    pct = val / values[0] * 100\n",
    "    ax.text(val, bar.get_y() + bar.get_height()/2, \n",
    "            f' {val:,} ({pct:.1f}%)', \n",
    "            va='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Número de Sessões', fontsize=12)\n",
    "ax.set_title('Análise de Funil de Conversão', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757d2b0",
   "metadata": {},
   "source": [
    "## 4.2 Modo TABLE: Upsert com Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de inventário (TABLE mode com PK)\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE product_inventory (\n",
    "        product_id INTEGER PRIMARY KEY,\n",
    "        product_name VARCHAR,\n",
    "        quantity INTEGER,\n",
    "        price DECIMAL(10,2),\n",
    "        last_updated BIGINT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Tabela product_inventory criada (modo TABLE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado inicial do inventário\n",
    "products = []\n",
    "for i in range(1, 101):\n",
    "    products.append({\n",
    "        'product_id': i,\n",
    "        'product_name': f'Product {i}',\n",
    "        'quantity': random.randint(0, 1000),\n",
    "        'price': round(random.uniform(10, 500), 2),\n",
    "        'last_updated': int(datetime.now().timestamp())\n",
    "    })\n",
    "\n",
    "products_df = pd.DataFrame(products)\n",
    "con.execute(\"INSERT INTO product_inventory SELECT * FROM products_df\")\n",
    "\n",
    "print(f\"✅ {len(products)} produtos inseridos\")\n",
    "print(\"\\nPrimeiros 5 produtos:\")\n",
    "print(con.execute(\"SELECT * FROM product_inventory LIMIT 5\").fetchdf().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17633269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular atualizações (UPSERT)\n",
    "print(\"\\n=== Simulando vendas (UPSERT) ===\")\n",
    "\n",
    "# Venda de 20 produtos\n",
    "updates = []\n",
    "for _ in range(20):\n",
    "    product_id = random.randint(1, 100)\n",
    "    qty_sold = random.randint(1, 50)\n",
    "    updates.append((product_id, qty_sold))\n",
    "\n",
    "for product_id, qty_sold in updates:\n",
    "    con.execute(f\"\"\"\n",
    "        UPDATE product_inventory \n",
    "        SET quantity = quantity - {qty_sold},\n",
    "            last_updated = {int(datetime.now().timestamp())}\n",
    "        WHERE product_id = {product_id}\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"✅ {len(updates)} atualizações aplicadas\")\n",
    "\n",
    "# Verificar produtos com estoque baixo\n",
    "low_stock = con.execute(\"\"\"\n",
    "    SELECT product_id, product_name, quantity, price\n",
    "    FROM product_inventory\n",
    "    WHERE quantity < 50\n",
    "    ORDER BY quantity ASC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nProdutos com estoque baixo (<50):\")\n",
    "print(low_stock.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738fb100",
   "metadata": {},
   "source": [
    "## 4.3 Point Query: Lookup por Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82feca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Point query por PK\n",
    "print(\"=== Point Query Benchmark ===\")\n",
    "\n",
    "# Query 1000 produtos aleatórios\n",
    "product_ids = [random.randint(1, 100) for _ in range(1000)]\n",
    "\n",
    "start = time.perf_counter()\n",
    "for pid in product_ids:\n",
    "    result = con.execute(f\"\"\"\n",
    "        SELECT quantity, price FROM product_inventory WHERE product_id = {pid}\n",
    "    \"\"\").fetchone()\n",
    "time_point = time.perf_counter() - start\n",
    "\n",
    "latency_per_query = time_point / 1000 * 1000  # ms\n",
    "\n",
    "print(f\"1000 point queries: {time_point*1000:.1f}ms\")\n",
    "print(f\"Latência média: {latency_per_query:.2f}ms por query\")\n",
    "print(f\"Throughput: {1000/time_point:.0f} queries/segundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a24364",
   "metadata": {},
   "source": [
    "## 4.4 Temporal Join: ASOF JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d12bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de preços históricos\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE price_history (\n",
    "        product_id INTEGER,\n",
    "        price DECIMAL(10,2),\n",
    "        timestamp BIGINT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Gerar histórico de preços\n",
    "base_time = int((datetime.now() - timedelta(days=30)).timestamp())\n",
    "price_changes = []\n",
    "\n",
    "for product_id in range(1, 21):  # 20 produtos\n",
    "    base_price = random.uniform(100, 500)\n",
    "    for day in range(30):\n",
    "        price = base_price * (1 + random.uniform(-0.1, 0.1))  # ±10% variação\n",
    "        price_changes.append({\n",
    "            'product_id': product_id,\n",
    "            'price': round(price, 2),\n",
    "            'timestamp': base_time + (day * 86400)\n",
    "        })\n",
    "\n",
    "price_df = pd.DataFrame(price_changes)\n",
    "con.execute(\"INSERT INTO price_history SELECT * FROM price_df\")\n",
    "\n",
    "print(f\"✅ {len(price_changes)} registros de preço inseridos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de compras\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE purchases (\n",
    "        purchase_id INTEGER,\n",
    "        product_id INTEGER,\n",
    "        quantity INTEGER,\n",
    "        timestamp BIGINT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Gerar compras\n",
    "purchases = []\n",
    "for i in range(1000):\n",
    "    purchases.append({\n",
    "        'purchase_id': i,\n",
    "        'product_id': random.randint(1, 20),\n",
    "        'quantity': random.randint(1, 10),\n",
    "        'timestamp': base_time + random.randint(0, 30 * 86400)\n",
    "    })\n",
    "\n",
    "purchases_df = pd.DataFrame(purchases)\n",
    "con.execute(\"INSERT INTO purchases SELECT * FROM purchases_df\")\n",
    "\n",
    "print(f\"✅ {len(purchases)} compras inseridas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASOF JOIN: Encontrar preço no momento da compra\n",
    "print(\"\\n=== ASOF JOIN: Preço no momento da compra ===\")\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        p.purchase_id,\n",
    "        p.product_id,\n",
    "        p.quantity,\n",
    "        p.timestamp as purchase_time,\n",
    "        ph.price,\n",
    "        ph.timestamp as price_time,\n",
    "        ROUND(p.quantity * ph.price, 2) as total_value\n",
    "    FROM purchases p\n",
    "    ASOF LEFT JOIN price_history ph\n",
    "        ON p.product_id = ph.product_id\n",
    "        AND p.timestamp >= ph.timestamp\n",
    "    ORDER BY p.purchase_id\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(result.to_string(index=False))\n",
    "\n",
    "# Calcular valor total\n",
    "total_revenue = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as num_purchases,\n",
    "        ROUND(SUM(p.quantity * ph.price), 2) as total_revenue\n",
    "    FROM purchases p\n",
    "    ASOF LEFT JOIN price_history ph\n",
    "        ON p.product_id = ph.product_id\n",
    "        AND p.timestamp >= ph.timestamp\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"\\nTotal Revenue: ${total_revenue['total_revenue'].iloc[0]:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13249c79",
   "metadata": {},
   "source": [
    "## 4.5 Changelog Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de changelog\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE inventory_changelog (\n",
    "        change_id INTEGER PRIMARY KEY,\n",
    "        product_id INTEGER,\n",
    "        operation VARCHAR,  -- INSERT, UPDATE, DELETE\n",
    "        old_quantity INTEGER,\n",
    "        new_quantity INTEGER,\n",
    "        timestamp BIGINT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Gerar changelog simulado\n",
    "changes = []\n",
    "change_id = 0\n",
    "current_time = int(datetime.now().timestamp())\n",
    "\n",
    "for product_id in range(1, 51):\n",
    "    old_qty = random.randint(100, 500)\n",
    "    \n",
    "    # 5 mudanças por produto\n",
    "    for i in range(5):\n",
    "        delta = random.randint(-100, 100)\n",
    "        new_qty = max(0, old_qty + delta)\n",
    "        \n",
    "        changes.append({\n",
    "            'change_id': change_id,\n",
    "            'product_id': product_id,\n",
    "            'operation': 'UPDATE',\n",
    "            'old_quantity': old_qty,\n",
    "            'new_quantity': new_qty,\n",
    "            'timestamp': current_time + (i * 60)\n",
    "        })\n",
    "        \n",
    "        old_qty = new_qty\n",
    "        change_id += 1\n",
    "\n",
    "changelog_df = pd.DataFrame(changes)\n",
    "con.execute(\"INSERT INTO inventory_changelog SELECT * FROM changelog_df\")\n",
    "\n",
    "print(f\"✅ {len(changes)} mudanças no changelog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar delta de mudanças\n",
    "print(\"\\n=== Análise de Changelog ===\")\n",
    "\n",
    "analysis = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        product_id,\n",
    "        COUNT(*) as num_changes,\n",
    "        MIN(old_quantity) as initial_qty,\n",
    "        MAX(new_quantity) as final_qty,\n",
    "        MAX(new_quantity) - MIN(old_quantity) as net_change\n",
    "    FROM inventory_changelog\n",
    "    GROUP BY product_id\n",
    "    ORDER BY ABS(MAX(new_quantity) - MIN(old_quantity)) DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(analysis.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b3393",
   "metadata": {},
   "source": [
    "## 4.6 Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a21d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'Modo': ['LOG (Append-Only)', 'TABLE (Upsert PK)'],\n",
    "    'Caso de Uso': [\n",
    "        'Eventos, Logs, Auditoria',\n",
    "        'Estado atual, Inventário, Perfis'\n",
    "    ],\n",
    "    'Operações': [\n",
    "        'INSERT only',\n",
    "        'INSERT, UPDATE, DELETE'\n",
    "    ],\n",
    "    'Queries': [\n",
    "        'Funnel, Time-series, Agregações',\n",
    "        'Point query (1-5ms), Joins'\n",
    "    ],\n",
    "    'Latência': [\n",
    "        'Scan-based',\n",
    "        f'{latency_per_query:.2f}ms (point query)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== RESUMO DO CAPÍTULO 4 ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n✅ Principais Conclusões:\")\n",
    "print(\"  1. LOG: Imutável, ideal para eventos e análises temporais\")\n",
    "print(\"  2. TABLE: Mutável com PK, ideal para estado atual\")\n",
    "print(\"  3. ASOF JOIN: Query temporal com consistência\")\n",
    "print(\"  4. Changelog: Rastreamento de mudanças em tempo real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "con.close()\n",
    "import os\n",
    "if os.path.exists('fluss_demo.db'):\n",
    "    os.remove('fluss_demo.db')\n",
    "    \n",
    "print(\"\\n✅ Notebook concluído!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
