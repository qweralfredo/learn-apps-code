{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 08 Padroes Avancados Globbing\n",
    "\n",
    "Notebook gerado automaticamente a partir do código fonte python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "capitulo_08_padroes_avancados_globbing\n",
    "\"\"\"\n",
    "\n",
    "# capitulo_08_padroes_avancados_globbing\n",
    "import duckdb\n",
    "import os\n",
    "\n",
    "# Exemplo/Bloco 1\n",
    "import duckdb\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Todos os arquivos .parquet em um diretório\n",
    "SELECT * FROM 's3://my-bucket/data/*.parquet';\n",
    "\n",
    "-- Qualquer nome de arquivo\n",
    "SELECT * FROM 's3://my-bucket/data/*';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Todos os .parquet em todos os subdiretórios\n",
    "SELECT * FROM 's3://my-bucket/data/**/*.parquet';\n",
    "\n",
    "-- Estrutura:\n",
    "-- s3://my-bucket/data/\n",
    "--   2024/\n",
    "--     01/\n",
    "--       file1.parquet\n",
    "--     02/\n",
    "--       file2.parquet\n",
    "--   2023/\n",
    "--     12/\n",
    "--       file3.parquet\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Corresponde a qualquer caractere único\n",
    "SELECT * FROM 's3://my-bucket/data/file_?.parquet';\n",
    "\n",
    "-- Corresponde:\n",
    "-- file_1.parquet ✅\n",
    "-- file_2.parquet ✅\n",
    "-- file_a.parquet ✅\n",
    "-- file_10.parquet ❌ (dois caracteres)\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Dígitos de 0-9\n",
    "SELECT * FROM 's3://my-bucket/data/file_[0-9].parquet';\n",
    "\n",
    "-- Letras específicas\n",
    "SELECT * FROM 's3://my-bucket/data/file_[abc].parquet';\n",
    "\n",
    "-- Intervalo de letras\n",
    "SELECT * FROM 's3://my-bucket/data/file_[a-z].parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Padrão complexo do exemplo da documentação\n",
    "SELECT count(*)\n",
    "FROM read_parquet('s3://my-bucket/folder*/100?/t[0-9].parquet');\n",
    "\n",
    "-- Corresponde:\n",
    "-- s3://my-bucket/folder1/1001/t5.parquet ✅\n",
    "-- s3://my-bucket/folder2/1009/t3.parquet ✅\n",
    "-- s3://my-bucket/folderA/1000/t7.parquet ✅\n",
    "-- s3://my-bucket/folder/1001/t5.parquet ❌ (folder não tem sufixo)\n",
    "-- s3://my-bucket/folder1/100/t5.parquet ❌ (100 tem 3 dígitos, não 4)\n",
    "-- s3://my-bucket/folder1/1001/t15.parquet ❌ (t15 tem dois dígitos)\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura de diretórios por data\n",
    "-- s3://logs/2024/01/01/app.parquet\n",
    "-- s3://logs/2024/01/02/app.parquet\n",
    "\n",
    "-- Todos os logs de janeiro 2024\n",
    "SELECT *\n",
    "FROM 's3://logs-bucket/2024/01/**/*.parquet';\n",
    "\n",
    "-- Dia específico\n",
    "SELECT *\n",
    "FROM 's3://logs-bucket/2024/01/15/*.parquet';\n",
    "\n",
    "-- Primeiro dia de cada mês em 2024\n",
    "SELECT *\n",
    "FROM 's3://logs-bucket/2024/*/01/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Arquivos nomeados: data-2024-01-15.parquet\n",
    "\n",
    "-- Todos de janeiro\n",
    "SELECT *\n",
    "FROM 's3://bucket/data/data-2024-01-*.parquet';\n",
    "\n",
    "-- Primeiros 10 dias de qualquer mês\n",
    "SELECT *\n",
    "FROM 's3://bucket/data/data-2024-*-0[1-9].parquet'\n",
    "UNION ALL\n",
    "SELECT *\n",
    "FROM 's3://bucket/data/data-2024-*-10.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura Hive:\n",
    "-- s3://data/year=2024/month=01/day=15/data.parquet\n",
    "\n",
    "-- Mês específico\n",
    "SELECT *\n",
    "FROM 's3://data/year=2024/month=01/**/*.parquet'\n",
    "WHERE year = 2024 AND month = 1;\n",
    "\n",
    "-- Primeiro dia de cada mês\n",
    "SELECT *\n",
    "FROM 's3://data/year=2024/**/day=01/*.parquet';\n",
    "\n",
    "-- Q1 2024\n",
    "SELECT *\n",
    "FROM 's3://data/year=2024/month=0[1-3]/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://logs/2024-01-15T10/app.parquet\n",
    "-- s3://logs/2024-01-15T11/app.parquet\n",
    "-- s3://logs/2024-01-15T12/app.parquet\n",
    "\n",
    "-- Logs de um dia específico\n",
    "SELECT *\n",
    "FROM 's3://logs-bucket/2024-01-15*/*.parquet'\n",
    "WHERE timestamp >= '2024-01-15 00:00:00'\n",
    "  AND timestamp < '2024-01-16 00:00:00';\n",
    "\n",
    "-- Logs de horário específico (10h-12h)\n",
    "SELECT *\n",
    "FROM 's3://logs-bucket/2024-01-15T1[0-2]/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://sales/region=us-east/2024/01/data.parquet\n",
    "-- s3://sales/region=us-west/2024/01/data.parquet\n",
    "-- s3://sales/region=eu-west/2024/01/data.parquet\n",
    "\n",
    "-- Apenas regiões US\n",
    "SELECT *\n",
    "FROM 's3://sales-bucket/region=us-*/**/*.parquet';\n",
    "\n",
    "-- Específicas regiões\n",
    "SELECT *\n",
    "FROM read_parquet('s3://sales-bucket/region={us-east,eu-west}/**/*.parquet');\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://data/v1/file.parquet\n",
    "-- s3://data/v2/file.parquet\n",
    "-- s3://data/v10/file.parquet\n",
    "\n",
    "-- Apenas versões de um dígito (v1-v9)\n",
    "SELECT * FROM 's3://data-bucket/v[0-9]/*.parquet';\n",
    "\n",
    "-- Versões específicas\n",
    "SELECT * FROM 's3://data-bucket/v{1,5,10}/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://processed/batch_001.parquet\n",
    "-- s3://processed/batch_002.parquet\n",
    "-- ...\n",
    "-- s3://processed/batch_100.parquet\n",
    "\n",
    "-- Apenas batches 1-99\n",
    "SELECT *\n",
    "FROM 's3://bucket/batch_0[0-9][0-9].parquet';\n",
    "\n",
    "-- Batches específicos (50-59)\n",
    "SELECT *\n",
    "FROM 's3://bucket/batch_05[0-9].parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ver origem dos dados\n",
    "SELECT *, filename\n",
    "FROM read_parquet('s3://my-bucket/**/*.parquet', filename = true);\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Filenames: s3://bucket/region-us/2024-01-15.parquet\n",
    "\n",
    "SELECT\n",
    "    filename,\n",
    "    split_part(filename, '/', -2) as region,  -- Extrai região do path\n",
    "    split_part(split_part(filename, '/', -1), '.', 1) as date,  -- Extrai data do nome\n",
    "    count(*) as records\n",
    "FROM read_parquet('s3://my-bucket/**/*.parquet', filename = true)\n",
    "GROUP BY filename;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Apenas arquivos de uma região específica\n",
    "SELECT *\n",
    "FROM read_parquet('s3://my-bucket/**/*.parquet', filename = true)\n",
    "WHERE filename LIKE '%region=us-east%';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- ❌ Menos eficiente: busca em toda a estrutura\n",
    "SELECT * FROM 's3://huge-bucket/**/*.parquet';\n",
    "\n",
    "-- ✅ Mais eficiente: limita scope\n",
    "SELECT * FROM 's3://huge-bucket/2024/01/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- ❌ Glob amplo + filtro na query\n",
    "SELECT *\n",
    "FROM 's3://data/**/*.parquet'\n",
    "WHERE year = 2024 AND month = 1;\n",
    "\n",
    "-- ✅ Glob específico (menos arquivos listados)\n",
    "SELECT *\n",
    "FROM 's3://data/year=2024/month=01/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura Hive otimizada\n",
    "SELECT *\n",
    "FROM read_parquet(\n",
    "    's3://data/year=2024/month=0[1-3]/**/*.parquet',\n",
    "    hive_partitioning = true\n",
    ")\n",
    "WHERE day <= 15;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Este comando faz:\n",
    "-- 1. ListObjectsV2('s3://bucket/data/', prefix='2024/')\n",
    "-- 2. Filtra resultados pelo padrão *.parquet\n",
    "-- 3. Lê apenas arquivos correspondentes\n",
    "SELECT * FROM 's3://bucket/data/2024/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- ❌ Lista TODO o bucket (lento)\n",
    "SELECT * FROM 's3://huge-bucket/**/*.parquet' LIMIT 10;\n",
    "\n",
    "-- ✅ Lista apenas subdiretório (rápido)\n",
    "SELECT * FROM 's3://huge-bucket/recent/**/*.parquet' LIMIT 10;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://cdc/table_name/YYYY-MM-DD/HH/batch_NNN.parquet\n",
    "\n",
    "-- Todas as mudanças de um dia\n",
    "SELECT *\n",
    "FROM 's3://cdc-bucket/users/2024-01-15/**/*.parquet';\n",
    "\n",
    "-- Mudanças de uma hora específica\n",
    "SELECT *\n",
    "FROM 's3://cdc-bucket/users/2024-01-15/14/*.parquet';\n",
    "\n",
    "-- Últimos batches de cada hora\n",
    "SELECT\n",
    "    split_part(filename, '/', -2) as hour,\n",
    "    max(filename) as latest_batch\n",
    "FROM read_parquet('s3://cdc-bucket/users/2024-01-15/**/*.parquet', filename = true)\n",
    "GROUP BY hour;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://data/tenant_001/2024/01/data.parquet\n",
    "-- s3://data/tenant_002/2024/01/data.parquet\n",
    "\n",
    "-- Todos os tenants, mês específico\n",
    "SELECT *\n",
    "FROM 's3://data-bucket/tenant_*/2024/01/**/*.parquet';\n",
    "\n",
    "-- Tenants específicos\n",
    "SELECT *\n",
    "FROM 's3://data-bucket/tenant_{001,002,005}/2024/**/*.parquet';\n",
    "\n",
    "-- Análise por tenant\n",
    "SELECT\n",
    "    split_part(filename, '/', -4) as tenant,\n",
    "    count(*) as records,\n",
    "    sum(amount) as total\n",
    "FROM read_parquet('s3://data-bucket/tenant_*/2024/01/**/*.parquet', filename = true)\n",
    "GROUP BY tenant;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura:\n",
    "-- s3://experiments/exp_001/variant_A/2024-01-15.parquet\n",
    "-- s3://experiments/exp_001/variant_B/2024-01-15.parquet\n",
    "\n",
    "-- Experimento específico, todas as variantes\n",
    "SELECT\n",
    "    split_part(filename, '/', -2) as variant,\n",
    "    count(*) as impressions,\n",
    "    sum(converted) as conversions,\n",
    "    sum(converted)::FLOAT / count(*) as conversion_rate\n",
    "FROM read_parquet('s3://experiments/exp_001/**/*.parquet', filename = true)\n",
    "GROUP BY variant;\n",
    "\n",
    "-- Múltiplos experimentos, comparação\n",
    "SELECT\n",
    "    split_part(filename, '/', -3) as experiment,\n",
    "    split_part(filename, '/', -2) as variant,\n",
    "    sum(revenue) as total_revenue\n",
    "FROM read_parquet('s3://experiments/exp_*/variant_{A,B}/**/*.parquet', filename = true)\n",
    "GROUP BY experiment, variant;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Estrutura por minuto:\n",
    "-- s3://metrics/2024/01/15/10/30/metrics.parquet\n",
    "\n",
    "-- Hora específica (10:00-10:59)\n",
    "SELECT *\n",
    "FROM 's3://metrics-bucket/2024/01/15/10/**/*.parquet';\n",
    "\n",
    "-- Minutos específicos (10:00, 10:15, 10:30, 10:45)\n",
    "SELECT *\n",
    "FROM 's3://metrics-bucket/2024/01/15/10/{00,15,30,45}/*.parquet';\n",
    "\n",
    "-- Agregação por hora\n",
    "SELECT\n",
    "    split_part(filename, '/', -3) as hour,\n",
    "    avg(cpu_usage) as avg_cpu,\n",
    "    max(memory_usage) as max_memory\n",
    "FROM read_parquet('s3://metrics-bucket/2024/01/15/**/*.parquet', filename = true)\n",
    "GROUP BY hour\n",
    "ORDER BY hour;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Combinar dados de múltiplas fontes\n",
    "SELECT * FROM 's3://bucket/2024/01/**/*.parquet'\n",
    "UNION ALL\n",
    "SELECT * FROM 's3://bucket/2024/02/**/*.parquet'\n",
    "UNION ALL\n",
    "SELECT * FROM 's3://bucket/2024/03/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Não suportado diretamente, mas pode usar:\n",
    "SELECT *\n",
    "FROM read_parquet([\n",
    "    's3://bucket/2024/01/**/*.parquet',\n",
    "    's3://bucket/2024/02/**/*.parquet',\n",
    "    's3://bucket/2024/03/**/*.parquet'\n",
    "]);\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ver quais arquivos correspondem ao padrão\n",
    "SELECT DISTINCT filename\n",
    "FROM read_parquet('s3://bucket/complex/pattern/**/*.parquet', filename = true)\n",
    "LIMIT 20;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ver distribuição de arquivos\n",
    "SELECT\n",
    "    split_part(filename, '/', -2) as directory,\n",
    "    count(*) as file_count\n",
    "FROM read_parquet('s3://bucket/**/*.parquet', filename = true)\n",
    "GROUP BY directory\n",
    "ORDER BY file_count DESC;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Verificar se padrão retorna arquivos esperados\n",
    "SELECT\n",
    "    count(DISTINCT filename) as total_files,\n",
    "    min(filename) as first_file,\n",
    "    max(filename) as last_file\n",
    "FROM read_parquet('s3://bucket/pattern/**/*.parquet', filename = true);\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- 1. Criar estrutura de teste\n",
    "COPY (SELECT range as id FROM range(100))\n",
    "  TO 's3://your-bucket/test/file_1.parquet';\n",
    "COPY (SELECT range as id FROM range(100))\n",
    "  TO 's3://your-bucket/test/file_2.parquet';\n",
    "COPY (SELECT range as id FROM range(100))\n",
    "  TO 's3://your-bucket/test/file_a.parquet';\n",
    "\n",
    "-- 2. Testar padrões\n",
    "SELECT count(*) FROM 's3://your-bucket/test/file_*.parquet';\n",
    "SELECT count(*) FROM 's3://your-bucket/test/file_[0-9].parquet';\n",
    "SELECT count(*) FROM 's3://your-bucket/test/file_?.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- 1. Criar estrutura de diretórios\n",
    "COPY (SELECT range as id, '2024-01-15' as date FROM range(100))\n",
    "  TO 's3://your-bucket/data/2024/01/15/data.parquet';\n",
    "COPY (SELECT range as id, '2024-01-16' as date FROM range(100))\n",
    "  TO 's3://your-bucket/data/2024/01/16/data.parquet';\n",
    "COPY (SELECT range as id, '2024-02-01' as date FROM range(100))\n",
    "  TO 's3://your-bucket/data/2024/02/01/data.parquet';\n",
    "\n",
    "-- 2. Testar padrões recursivos\n",
    "SELECT count(*) FROM 's3://your-bucket/data/**/*.parquet';\n",
    "SELECT count(*) FROM 's3://your-bucket/data/2024/01/**/*.parquet';\n",
    "SELECT count(*) FROM 's3://your-bucket/data/2024/*/15/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Análise de distribuição de arquivos\n",
    "SELECT\n",
    "    split_part(filename, '/', -3) as year,\n",
    "    split_part(filename, '/', -2) as month,\n",
    "    count(*) as total_records,\n",
    "    count(DISTINCT filename) as file_count\n",
    "FROM read_parquet('s3://your-bucket/data/**/*.parquet', filename = true)\n",
    "GROUP BY year, month\n",
    "ORDER BY year, month;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}