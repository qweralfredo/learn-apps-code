{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 1: Introdução ao DuckDB e S3\n",
    "\n",
    "Este notebook demonstra os conceitos básicos do DuckDB e sua integração com S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import duckdb\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Configuração para Windows (UTF-8)\n",
    "if os.name == 'nt':\n",
    "    os.system('chcp 65001 > nul')\n",
    "\n",
    "print(\"✓ Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. O que é DuckDB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar conexão com DuckDB (em memória)\n",
    "conn = duckdb.connect(':memory:')\n",
    "\n",
    "# Verificar versão\n",
    "version = conn.execute(\"SELECT version()\").fetchone()[0]\n",
    "print(f\"DuckDB Version: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Criando Dados de Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretório para dados\n",
    "data_dir = Path(\"./sample_data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Criar tabela de vendas\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE sales AS\n",
    "    SELECT\n",
    "        range as id,\n",
    "        'Product_' || (range % 10) as product,\n",
    "        (random() * 1000)::INTEGER as amount,\n",
    "        DATE '2024-01-01' + INTERVAL (range % 90) DAY as date\n",
    "    FROM range(1000)\n",
    "\"\"\")\n",
    "\n",
    "# Visualizar dados\n",
    "conn.execute(\"SELECT * FROM sales LIMIT 10\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Escrita de Arquivo Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrever para Parquet\n",
    "parquet_file = data_dir / \"sales.parquet\"\n",
    "conn.execute(f\"COPY sales TO '{parquet_file}' (FORMAT parquet)\")\n",
    "\n",
    "print(f\"✓ Arquivo criado: {parquet_file}\")\n",
    "print(f\"✓ Tamanho: {parquet_file.stat().st_size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Leitura Direta de Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler arquivo Parquet\n",
    "conn.execute(f\"SELECT * FROM '{parquet_file}' LIMIT 5\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise agregada\n",
    "conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        product,\n",
    "        count(*) as transactions,\n",
    "        sum(amount) as total_sales,\n",
    "        avg(amount)::INTEGER as avg_amount\n",
    "    FROM '{parquet_file}'\n",
    "    GROUP BY product\n",
    "    ORDER BY total_sales DESC\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Formatos Suportados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "csv_file = data_dir / \"sales.csv\"\n",
    "conn.execute(f\"\"\"\n",
    "    COPY (SELECT * FROM sales LIMIT 100)\n",
    "    TO '{csv_file}' (FORMAT csv, HEADER true)\n",
    "\"\"\")\n",
    "\n",
    "# JSON\n",
    "json_file = data_dir / \"sales.json\"\n",
    "conn.execute(f\"\"\"\n",
    "    COPY (SELECT * FROM sales LIMIT 100)\n",
    "    TO '{json_file}' (FORMAT json)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✓ CSV: {csv_file}\")\n",
    "print(f\"✓ JSON: {json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Globbing (Múltiplos Arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar múltiplos arquivos\n",
    "for i in range(3):\n",
    "    file_path = data_dir / f\"sales_part_{i}.parquet\"\n",
    "    conn.execute(f\"\"\"\n",
    "        COPY (\n",
    "            SELECT * FROM sales\n",
    "            WHERE id BETWEEN {i * 300} AND {(i + 1) * 300 - 1}\n",
    "        ) TO '{file_path}' (FORMAT parquet)\n",
    "    \"\"\")\n",
    "    print(f\"✓ Criado: sales_part_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler com glob pattern\n",
    "glob_pattern = str(data_dir / \"sales_part_*.parquet\").replace('\\\\', '/')\n",
    "conn.execute(f\"\"\"\n",
    "    SELECT count(*) as total_records\n",
    "    FROM '{glob_pattern}'\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Metadados de Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver schema\n",
    "conn.execute(f\"SELECT * FROM parquet_schema('{parquet_file}')\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver metadados\n",
    "conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        file_name,\n",
    "        row_group_id,\n",
    "        num_values,\n",
    "        total_compressed_size,\n",
    "        total_uncompressed_size\n",
    "    FROM parquet_metadata('{parquet_file}')\n",
    "    LIMIT 5\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análise de Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise temporal\n",
    "conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        date_trunc('week', date) as week,\n",
    "        count(*) as transactions,\n",
    "        sum(amount) as total_sales,\n",
    "        avg(amount)::INTEGER as avg_order_value\n",
    "    FROM '{parquet_file}'\n",
    "    GROUP BY week\n",
    "    ORDER BY week\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercícios Práticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercício 1: Criar dataset grande\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE large_dataset AS\n",
    "    SELECT\n",
    "        range as id,\n",
    "        'Category_' || (range % 5) as category,\n",
    "        (random() * 10000)::INTEGER as value,\n",
    "        current_timestamp() as created_at\n",
    "    FROM range(10000)\n",
    "\"\"\")\n",
    "\n",
    "exercise_file = data_dir / \"exercise_01.parquet\"\n",
    "conn.execute(f\"COPY large_dataset TO '{exercise_file}' (FORMAT parquet)\")\n",
    "\n",
    "print(f\"✓ Criado arquivo com 10.000 registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercício 2: Estatísticas\n",
    "conn.execute(f\"\"\"\n",
    "    SELECT\n",
    "        min(value) as min_value,\n",
    "        max(value) as max_value,\n",
    "        avg(value)::INTEGER as avg_value,\n",
    "        count(*) as total_records\n",
    "    FROM '{exercise_file}'\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Neste capítulo você aprendeu:\n",
    "- ✅ O que é DuckDB e suas vantagens\n",
    "- ✅ Criar e manipular dados localmente\n",
    "- ✅ Trabalhar com formatos Parquet, CSV e JSON\n",
    "- ✅ Usar globbing para múltiplos arquivos\n",
    "- ✅ Explorar metadados de Parquet\n",
    "\n",
    "**Próximo capítulo:** Instalação e configuração da extensão httpfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "conn.close()\n",
    "print(\"✓ Conexão fechada!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
