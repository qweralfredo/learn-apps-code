{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitulo 09 Integracao Outros Servicos Cloud\n",
    "\n",
    "Notebook gerado automaticamente a partir do código fonte python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "capitulo_09_integracao_outros_servicos_cloud\n",
    "\"\"\"\n",
    "\n",
    "# capitulo_09_integracao_outros_servicos_cloud\n",
    "import duckdb\n",
    "import os\n",
    "\n",
    "# Exemplo/Bloco 1\n",
    "import duckdb\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Criar secret para Cloudflare R2\n",
    "CREATE SECRET r2_secret (\n",
    "    TYPE r2,\n",
    "    KEY_ID 'AKIAIOSFODNN7EXAMPLE',\n",
    "    SECRET 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY',\n",
    "    ACCOUNT_ID 'my_account_id'\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Usar protocolo r2://\n",
    "SELECT * FROM 'r2://my-bucket/data.parquet';\n",
    "\n",
    "-- Ou read_parquet\n",
    "SELECT * FROM read_parquet('r2://my-bucket/data/*.parquet');\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Escrever para R2\n",
    "COPY my_table TO 'r2://my-bucket/output.parquet' (\n",
    "    FORMAT parquet,\n",
    "    COMPRESSION zstd\n",
    ");\n",
    "\n",
    "-- Particionar dados\n",
    "COPY sales TO 'r2://my-bucket/sales' (\n",
    "    FORMAT parquet,\n",
    "    PARTITION_BY (year, month)\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- 1. Configurar secret\n",
    "CREATE PERSISTENT SECRET r2_production (\n",
    "    TYPE r2,\n",
    "    KEY_ID 'your_r2_key_id',\n",
    "    SECRET 'your_r2_secret',\n",
    "    ACCOUNT_ID 'your_account_id',\n",
    "    SCOPE 'r2://production-data'\n",
    ");\n",
    "\n",
    "-- 2. Ler dados\n",
    "SELECT\n",
    "    product_id,\n",
    "    sum(amount) as total_sales\n",
    "FROM 'r2://production-data/transactions/**/*.parquet'\n",
    "WHERE date >= '2024-01-01'\n",
    "GROUP BY product_id;\n",
    "\n",
    "-- 3. Escrever resultado\n",
    "COPY (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        sum(amount) as total_sales\n",
    "    FROM 'r2://production-data/transactions/**/*.parquet'\n",
    "    WHERE date >= '2024-01-01'\n",
    "    GROUP BY product_id\n",
    ") TO 'r2://production-data/reports/monthly_sales.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Criar secret para GCS\n",
    "CREATE SECRET gcs_secret (\n",
    "    TYPE gcs,\n",
    "    KEY_ID 'my_hmac_access_id',\n",
    "    SECRET 'my_hmac_secret_key'\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Protocolo gs://\n",
    "SELECT * FROM 'gs://my-bucket/data.parquet';\n",
    "\n",
    "-- Ou gcs://\n",
    "SELECT * FROM 'gcs://my-bucket/data.parquet';\n",
    "\n",
    "-- Globbing\n",
    "SELECT * FROM 'gs://my-bucket/data/**/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Escrever para GCS\n",
    "COPY my_table TO 'gs://my-bucket/output.parquet' (\n",
    "    FORMAT parquet,\n",
    "    COMPRESSION zstd\n",
    ");\n",
    "\n",
    "-- Com particionamento\n",
    "COPY events TO 'gcs://my-bucket/events' (\n",
    "    FORMAT parquet,\n",
    "    PARTITION_BY (year, month, day)\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ler do S3, escrever para GCS\n",
    "COPY (\n",
    "    SELECT *\n",
    "    FROM 's3://aws-bucket/source-data/*.parquet'\n",
    "    WHERE processed = false\n",
    ") TO 'gs://gcs-bucket/processed-data/' (\n",
    "    FORMAT parquet,\n",
    "    PARTITION_BY (date)\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Secret para MinIO local\n",
    "CREATE SECRET minio_secret (\n",
    "    TYPE s3,\n",
    "    PROVIDER config,\n",
    "    KEY_ID 'minioadmin',\n",
    "    SECRET 'minioadmin',\n",
    "    ENDPOINT 'localhost:9000',\n",
    "    URL_STYLE 'path',\n",
    "    USE_SSL false\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Conectar ao MinIO\n",
    "CREATE SECRET minio_local (\n",
    "    TYPE s3,\n",
    "    PROVIDER config,\n",
    "    KEY_ID 'minioadmin',\n",
    "    SECRET 'minioadmin',\n",
    "    ENDPOINT 'localhost:9000',\n",
    "    URL_STYLE 'path',\n",
    "    USE_SSL false\n",
    ");\n",
    "\n",
    "-- Usar normalmente\n",
    "SELECT * FROM 's3://test-bucket/data.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Secret para lakeFS\n",
    "CREATE SECRET lakefs_secret (\n",
    "    TYPE s3,\n",
    "    PROVIDER config,\n",
    "    KEY_ID 'AKIAIOSFODNN7EXAMPLE',\n",
    "    SECRET 'your_lakefs_secret',\n",
    "    ENDPOINT 'lakefs.example.com',\n",
    "    URL_STYLE 'path',\n",
    "    USE_SSL true\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ler da branch main\n",
    "SELECT * FROM 's3://repo-name/main/data/*.parquet';\n",
    "\n",
    "-- Ler de uma branch de desenvolvimento\n",
    "SELECT * FROM 's3://repo-name/dev-branch/data/*.parquet';\n",
    "\n",
    "-- Comparar branches\n",
    "SELECT\n",
    "    'main' as branch,\n",
    "    count(*) as records\n",
    "FROM 's3://repo-name/main/data/*.parquet'\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'dev',\n",
    "    count(*)\n",
    "FROM 's3://repo-name/dev-branch/data/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- AWS S3\n",
    "CREATE PERSISTENT SECRET aws_production (\n",
    "    TYPE s3,\n",
    "    PROVIDER credential_chain,\n",
    "    SCOPE 's3://aws-production'\n",
    ");\n",
    "\n",
    "-- Cloudflare R2\n",
    "CREATE PERSISTENT SECRET r2_backup (\n",
    "    TYPE r2,\n",
    "    KEY_ID 'r2_key',\n",
    "    SECRET 'r2_secret',\n",
    "    ACCOUNT_ID 'account_id',\n",
    "    SCOPE 'r2://backup-bucket'\n",
    ");\n",
    "\n",
    "-- Google Cloud Storage\n",
    "CREATE PERSISTENT SECRET gcs_analytics (\n",
    "    TYPE gcs,\n",
    "    KEY_ID 'gcs_hmac_key',\n",
    "    SECRET 'gcs_hmac_secret',\n",
    "    SCOPE 'gs://analytics-bucket'\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ler de S3, processar, escrever para R2 e GCS\n",
    "WITH processed_data AS (\n",
    "    SELECT\n",
    "        date,\n",
    "        region,\n",
    "        sum(amount) as total_amount,\n",
    "        count(*) as transactions\n",
    "    FROM 's3://aws-production/raw-data/**/*.parquet'\n",
    "    WHERE date >= current_date() - INTERVAL '7 days'\n",
    "    GROUP BY date, region\n",
    ")\n",
    "-- Backup para R2\n",
    ", backup AS (\n",
    "    SELECT * FROM (\n",
    "        COPY processed_data TO 'r2://backup-bucket/processed/' || current_date() || '.parquet'\n",
    "    )\n",
    ")\n",
    "-- Analytics para GCS\n",
    "SELECT * FROM (\n",
    "    COPY processed_data TO 'gs://analytics-bucket/reports/' || current_date() || '.parquet'\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Arquivo Parquet público\n",
    "SELECT * FROM 'https://example.com/public/data.parquet';\n",
    "\n",
    "-- CSV público\n",
    "SELECT * FROM read_csv_auto('https://example.com/data.csv');\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Criar secret com Bearer token\n",
    "CREATE SECRET http_auth (\n",
    "    TYPE http,\n",
    "    BEARER_TOKEN 'your_bearer_token'\n",
    ");\n",
    "\n",
    "-- Acessar API protegida\n",
    "SELECT * FROM 'https://api.example.com/data.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Headers customizados\n",
    "CREATE SECRET http_custom (\n",
    "    TYPE http,\n",
    "    EXTRA_HTTP_HEADERS MAP {\n",
    "        'Authorization': 'Bearer token_value',\n",
    "        'X-API-Key': 'api_key_value',\n",
    "        'X-Custom-Header': 'custom_value'\n",
    "    }\n",
    ");\n",
    "\n",
    "-- Usar automaticamente\n",
    "SELECT * FROM 'https://api.example.com/protected/data.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Configurar autenticação\n",
    "CREATE SECRET api_secret (\n",
    "    TYPE http,\n",
    "    EXTRA_HTTP_HEADERS MAP {\n",
    "        'Authorization': 'Bearer eyJhbGc...',\n",
    "        'X-API-Version': 'v2'\n",
    "    }\n",
    ");\n",
    "\n",
    "-- Ler dados de API\n",
    "SELECT\n",
    "    user_id,\n",
    "    count(*) as events\n",
    "FROM 'https://analytics-api.example.com/exports/events.parquet'\n",
    "WHERE date >= '2024-01-01'\n",
    "GROUP BY user_id;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Configurar proxy com secret\n",
    "CREATE SECRET http_proxy (\n",
    "    TYPE http,\n",
    "    HTTP_PROXY 'http://proxy.company.com:8080',\n",
    "    HTTP_PROXY_USERNAME 'username',\n",
    "    HTTP_PROXY_PASSWORD 'password'\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "SET http_proxy = 'http://proxy.company.com:8080';\n",
    "SET http_proxy_username = 'username';\n",
    "SET http_proxy_password = 'password';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "LOAD httpfs;\n",
    "SET ca_cert_file = '/path/to/corporate-ca-bundle.crt';\n",
    "SET enable_server_cert_verification = true;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Backup automático de S3 para R2\n",
    "COPY (\n",
    "    SELECT *\n",
    "    FROM 's3://primary-bucket/data/**/*.parquet'\n",
    "    WHERE last_modified >= current_date()\n",
    ") TO 'r2://backup-bucket/daily/' || current_date() || '/' (\n",
    "    FORMAT parquet,\n",
    "    PARTITION_BY (region),\n",
    "    COMPRESSION zstd\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Ler de múltiplas fontes\n",
    "SELECT * FROM 's3://aws-datalake/orders/*.parquet'\n",
    "UNION ALL\n",
    "SELECT * FROM 'gs://gcp-datalake/orders/*.parquet'\n",
    "UNION ALL\n",
    "SELECT * FROM 'r2://r2-datalake/orders/*.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Hot data (acesso frequente) no S3\n",
    "-- Cold data (arquivo) no R2 (sem egress cost)\n",
    "\n",
    "-- Ler hot data\n",
    "SELECT * FROM 's3://hot-bucket/recent-data/*.parquet'\n",
    "WHERE date >= current_date() - INTERVAL '30 days'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Ler cold data (quando necessário)\n",
    "SELECT * FROM 'r2://cold-bucket/archive/**/*.parquet'\n",
    "WHERE date < current_date() - INTERVAL '30 days'\n",
    "  AND date >= '2023-01-01';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- S3\n",
    "SELECT which_secret('s3://my-bucket/file.parquet', 's3');\n",
    "\n",
    "-- R2\n",
    "SELECT which_secret('r2://my-bucket/file.parquet', 'r2');\n",
    "\n",
    "-- GCS\n",
    "SELECT which_secret('gs://my-bucket/file.parquet', 'gcs');\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Listar secrets por tipo\n",
    "SELECT * FROM duckdb_secrets() WHERE type = 's3';\n",
    "SELECT * FROM duckdb_secrets() WHERE type = 'r2';\n",
    "SELECT * FROM duckdb_secrets() WHERE type = 'gcs';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Para MinIO ou serviços customizados, verifique endpoint\n",
    "CREATE OR REPLACE SECRET test_secret (\n",
    "    TYPE s3,\n",
    "    PROVIDER config,\n",
    "    KEY_ID 'key',\n",
    "    SECRET 'secret',\n",
    "    ENDPOINT 'correct-endpoint.com',  -- Verifique URL correta\n",
    "    USE_SSL true\n",
    ");\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- 1. Instalar e iniciar MinIO (via Docker)\n",
    "-- docker run -p 9000:9000 -p 9001:9001 minio/minio server /data\n",
    "\n",
    "-- 2. Configurar secret\n",
    "CREATE SECRET minio_test (\n",
    "    TYPE s3,\n",
    "    PROVIDER config,\n",
    "    KEY_ID 'minioadmin',\n",
    "    SECRET 'minioadmin',\n",
    "    ENDPOINT 'localhost:9000',\n",
    "    URL_STYLE 'path',\n",
    "    USE_SSL false\n",
    ");\n",
    "\n",
    "-- 3. Criar bucket via console (localhost:9001)\n",
    "-- 4. Testar escrita\n",
    "CREATE TABLE test AS SELECT range as id FROM range(100);\n",
    "COPY test TO 's3://test-bucket/data.parquet';\n",
    "\n",
    "-- 5. Testar leitura\n",
    "SELECT count(*) FROM 's3://test-bucket/data.parquet';\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Simular leitura de múltiplas fontes\n",
    "WITH s3_data AS (\n",
    "    SELECT 's3' as source, * FROM 's3://bucket1/data.parquet'\n",
    "),\n",
    "r2_data AS (\n",
    "    SELECT 'r2' as source, * FROM 'r2://bucket2/data.parquet'\n",
    ")\n",
    "SELECT\n",
    "    source,\n",
    "    count(*) as records,\n",
    "    sum(amount) as total\n",
    "FROM (\n",
    "    SELECT * FROM s3_data\n",
    "    UNION ALL\n",
    "    SELECT * FROM r2_data\n",
    ")\n",
    "GROUP BY source;\n",
    "\"\"\")\n",
    "print(con.fetchall()) # Inspect result\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}